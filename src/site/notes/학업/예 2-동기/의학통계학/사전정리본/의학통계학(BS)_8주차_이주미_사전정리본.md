---
{"dg-publish":true,"permalink":"//2///bs-8/"}
---

<script>
MathJax = {
  tex: {
    inlineMath: [[',
    displayMath: [['$', '$'], ['\\[', '\\]'\|'$', '$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>


>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니당.
## Master Group 1: 상관분석의 기초와 Pearson 계수 (P. 1-11)

> [!NOTE] 1페이지 – Correlation (상관) 
> 
> 자, 여러분 반갑습니다. 오늘부터 우리는 통계학의 꽃이라 할 수 있는 변수 간의 관계를 배우게 됩니다. 
> 그 첫 번째 단추가 바로 **'상관(Correlation)'**입니다. 
> 
> 단순히 "상관이 있다"는 말을 넘어, 이를 어떻게 **수치화**하고 **해석**하는지 임상 사례를 통해 살펴봅시다.

---

> [!NOTE] 2페이지 – 상관분석의 실제 임상 예시: PI3K Signaling 
> 
> 우리가 통계를 배우는 이유는 결국 논문을 읽고 환자에게 적용하기 위해서죠. 
> **Glioblastoma(교모세포종)** 환자의 **PI3K pathway** 활성을 분석한 실제 Cancer Research 논문 사례를 봅시다. 
> 
> > [!IMPORTANT] 💡 핵심 연구 기전 (PI3K Pathway)
> > * **PTEN 단백질:** PI3K 활성을 **억제(antagonize)**하는 **Tumor suppressor**입니다. 
> > * **PTEN Loss:** 이 단백질이 결손되면 **Akt**와 같은 effector들이 **활성화(activation)**됩니다. 
> > * **연구 목적:** 생체 내(In vivo)에서 이들의 **상관관계**를 **Univariate analysis**로 증명하는 것입니다. 
> 
> 아래 표(Table 1)의 수치를 눈여겨보세요. 
> 
> > [!LIST] 📝 Pearson Correlation 결과 해석
> > * **PTEN vs pAkt:** 상관계수가 **-0.58**, P값이 **0.00007**로 매우 유의한 **음(-)의 상관관계**를 보입니다. 
> > * **pAkt vs p-FKHR:** 상관계수 **0.48**, P값 **0.002**로 유의한 **양(+)의 상관관계**입니다. 
> > * 즉, **"PTEN이 없어질수록 Akt 활성화는 강해진다"**는 것이 통계적으로 입증된 것이죠. 
> 
> 자, 임상적 의미를 확인했으니 이제 이론적인 정의로 들어가 봅시다.

---

> [!NOTE] 3페이지 – 상관분석의 정의 및 주의사항 
> 
> 상관분석이란 무엇일까요? 핵심은 **'연관성'**입니다. 
> 
> > [!INFO] 🧬 상관분석(Correlation Analysis)의 본질
> > * **정의:** 두 개 이상의 변수들 사이에 어떤 **연관성**이 존재하는지 파악하는 기법입니다. 
> > * **한계:** 변수들 간의 **원인과 결과(인과관계)를 밝히는 것이 아닙니다.**  단지 단순한 **상관성**만 보는 것이죠. 
> 
> 교수로서 여러분께 강조하고 싶은 **주의사항**이 세 가지 있습니다. 시험에도 자주 언급되는 포인트죠. 
> 
> > [!WARNING] ⚠️ 분석 시 반드시 기억할 것
> > 1. **수학적 관계일 뿐:** 상관계수가 높다고 해서 이를 변수의 **질적 관계**로 확대 해석해서는 안 됩니다. 
> > 2. **선형성(Linearity)의 한계:** 상관계수는 오직 **선형 연관성**만 나타냅니다.  값이 작아도 곡선 형태의 다른 관계가 숨어있을 수 있습니다. 
> > 3. **초기 단계 적용:** 상관분석은 결론을 내는 단계가 아니라, 자료 분석의 **초기 단계**에 적용하는 것입니다. 
> 
> 다음 장에서 가장 많이 쓰이는 계수를 직접 확인해봅시다.

---

> [!NOTE] 4페이지 – Pearson 상관계수 ($r$) 
> 
> 여러분이 가장 흔히 접하게 될 것이 바로 이 **Pearson 상관계수**입니다. 
> 
> > [!IMPORTANT] 🔑 Pearson 계수의 전제 조건과 특징
> > * **대상:** **양적인(연속형)** 변수 두 개 사이의 관계를 봅니다. 
> > * **가정:** 반드시 자료가 **정규분포**를 한다는 가정이 필요합니다. 
> > * **범위:** **$-1 \le r \le 1$** 사이의 값을 가집니다. 
> 
> > [!LIST] 📝 방향성에 따른 해석
> > * **$+1$에 가까울수록:** **양(+)의 상관관계**가 강해집니다 (X가 늘면 Y도 증가). 
> > * **$-1$에 가까울수록:** **음(-)의 상관관계**가 강해집니다 (X가 늘면 Y는 감소). 
> 
> 이 수식($r$)이 기하학적으로 어떻게 표현되는지 시각적으로 확인하는 게 중요합니다. 

---

> [!NOTE] 5페이지 – 산점도를 통한 상관계수의 시각적 이해 
> 
> 수치만 보지 말고 **산점도(Scatter plot)**를 보세요. 
> 
> > [!INFO] 📈 그래프 형태별 상관성
> > * **$r \approx 1$:** 점들이 우상향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx -1$:** 점들이 우하향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx 0$:** 점들이 흩어져 있어 **상관관계가 존재하지 않는** 경우입니다. 
> 
> 여기서 교수님의 **원포인트 레슨!** 
> 
> > [!WARNING] ⚠️ $r \approx 0$ 이지만 관계가 있는 경우
> > * 산점도가 **U자형(2차 선형관계)**을 그리는 경우, Pearson 계수는 **0에 가깝게** 나옵니다. 
> > * 이는 **"1차 선형관계"가 없다**는 뜻이지, 아무런 관계가 없다는 뜻이 아님을 명심하세요! 

---

> [!NOTE] 6페이지 – Pearson 상관계수 검정절차 
> 
> 이제 우리가 구한 $r$값이 통계적으로 유의한지 검정해야 합니다. 
> 
> > [!LIST] 📝 가설 설정 및 검정
> > 1. **가설 설정:** 귀무가설($H_0$)은 **"상관계수가 0이다($\rho=0$)"** 즉, 관계가 없다는 것입니다. 
> > 2. **검정통계량 ($t^*$):** 아래 식을 통해 t값을 구합니다. 
> >    $$t^* = r\sqrt{\frac{n-2}{1-r^2}}$$
> > 3. **의사결정:** 계산된 t값에 해당하는 **p-value가 0.05보다 작으면** 귀무가설을 기각하고 유의한 상관관계가 있다고 판단합니다. 

---

> [!NOTE] 7페이지 – 실습 예제: 에스트리올과 신생아 체중 
> 
> 자, 직접 해봅시다. 31명의 산모 데이터를 가져왔습니다. 
> 
> > [!quote] 🩺 증례 데이터
> > * **독립변수(X):** 산모의 **에스트리올(estriol)** 수치 
> > * **종속변수(Y):** 신생아의 **체중(birthweight)** 
> > * **질문:** "산모의 호르몬 수치와 아이의 체중 사이에 상관관계가 있는가?" 
> 
> 데이터 개수($N$)는 **31개**입니다.  이제 SPSS를 켜봅시다. 

---

> [!NOTE] 8~10페이지 – SPSS 실제 구현 방법 
> 
> 메뉴를 잘 따라오세요. 시험이나 실습 때 경로를 모르면 당황합니다. 
> 
> > [!LIST] 📝 SPSS 분석 경로
> > 1. **그래프 그리기:** `Graphs` → `Legacy Dialogs` → **`Scatter/Dot...`** (시각적 확인 필수) 
> > 2. **상관분석 실행:** `Analyze` → `Correlate` → **`Bivariate...`** (이변량 상관분석) 
> > 3. **변수 선택:** 분석할 변수(estriol, birthweight)를 넘기고 **Pearson**에 체크합니다. 
> 
> 다음 페이지에서 그 결과를 해석하는 법을 알려드리죠.

---

> [!NOTE] 11페이지 – 결과 해석: 유의성 판단 
> 
> 결과 표(Correlations table)를 볼까요? 
> 
> > [!IMPORTANT] 💡 분석 결과 해석 (중요!)
> > * **Pearson Correlation ($r$):** **.610** 
> > * **Sig. (2-tailed) (P값):** **.000** 
> > * **샘플 수 ($N$):** **31** 
> 
> > [!TIP] ⭐️ 족보 포인트
> > * P값이 **0.05(심지어 0.01)보다 작으므로**, 이 상관관계는 **통계적으로 매우 유의**합니다. 
> > * 즉, **"산모의 에스트리올 수치가 높을수록 신생아의 체중도 무거워지는 경향이 있다"**고 결론 내릴 수 있습니다. 
> 
> 이해되시죠? 하지만 모든 자료가 이렇게 예쁘게 정규분포를 따르지는 않습니다. 
> 그럴 땐 어떻게 해야 할까요? 바로 다음 장에서 배울 **Spearman 계수**가 답입니다.

---

<div style="page-break-after: always;"></div>

## Master Group 2: Spearman 계수와 상관분석의 완성 (P. 12-22)

> [!NOTE] 12~13페이지 – Spearman 순위상관계수 ($r_s$)
> 
> 자, 앞서 배운 Pearson은 데이터가 예쁘게 **정규분포**를 따를 때만 쓸 수 있었습니다. 
> 하지만 실제 임상 데이터는 그렇지 않은 경우가 태반이죠. 그럴 때 우리가 꺼내 드는 비장의 카드가 바로 **'Spearman'**입니다.
> 
> > [!INFO] 🧬 Spearman 순위상관계수의 특징
> > * **비모수적 방법:** 데이터가 **정규분포를 따른다는 가정을 하기 힘든 경우**에 사용합니다.
> > * **순위(Rank) 활용:** 값의 크기 자체가 아니라 데이터의 **'순위'**를 매겨서 상관성을 분석합니다.
> > * **범위:** Pearson과 마찬가지로 **$-1 \le r_s \le 1$** 사이의 값을 가집니다.
> 
> > [!LIST] 📝 검정 절차 (Pearson과 유사)
> > 1. **가설 설정:** $H_0: \rho=0$ (상관관계가 없다) vs $H_1: \rho \ne 0$ (상관관계가 있다).
> > 2. **검정통계량 ($t_s^*$):** 순위 상관계수를 이용한 t-검정을 수행합니다.
> > 3. **판단:** 마찬가지로 **p-value < 0.05**면 유의하다고 봅니다.
> 
> 

---

> [!NOTE] 14~16페이지 – Spearman 실습: 간 수치(AST/ALT) 분석
> 
> 실제 환자 20명의 데이터를 봅시다. 간 건강의 지표인 **AST와 ALT**의 상관관계를 볼까요? 
> 
> > [!quote] 🩺 임상 데이터 예시
> > * **환자 수:** 20명.
> > * **분석 변수:** 혈액검사 결과인 **AST** 수치와 **ALT** 수치.
> 
> SPSS 메뉴 경로는 이전과 거의 같습니다. 다만 체크박스 하나만 바꾸면 되죠.
> 
> > [!IMPORTANT] 💡 SPSS 조작 포인트
> > * `Analyze` → `Correlate` → `Bivariate` 경로에서 반드시 **`Spearman`** 항목에 체크해야 합니다!.
> 
> 결과 표를 보면 상관계수가 **.792**, P값이 **.000**으로 나오네요.
> **"AST가 높으면 ALT도 높다"**는 강한 상관관계가 입증된 셈입니다.

---

> [!NOTE] 17~18페이지 – 상관분석의 시각적 요약 및 결정계수
> 
> 이제 상관분석을 마무리하며 아주 중요한 개념인 **'결정계수'**를 짚고 넘어갑시다.
> 
> > [!IMPORTANT] 🔑 상관계수($r$)와 결정계수($r^2$)
> > * **결정계수 ($r^2$):** 상관계수를 제곱한 값으로, **회귀제곱합을 전체제곱합으로 나눈 비율**입니다.
> > * **의미:** 독립변수가 종속변수의 변동을 얼마나 **설명**해주는지를 나타냅니다.
> > * **관계식:** $r = \pm\sqrt{\text{설명되는 변동} / \text{전체 변동}}$.
> 
> 18페이지의 산점도들을 보면 **완전한 양의 상관($r=1$)**부터 **상관없음($r=0$)**까지 한눈에 들어올 겁니다.

---

> [!NOTE] 19페이지 – 상관계수 크기에 따른 판단 기준 (중요!)
> 
> "교수님, 상관계수가 몇 점이어야 높다고 하나요?"라는 질문에 대한 답이 여기 있습니다. 이 표는 꼭 머릿속에 넣어두세요.
> 
> > [!TIP] ⭐️ 상관계수 해석 가이드 (야마)
> > * **0.9 ~ 1.0:** **아주 높다**.
> > * **0.7 ~ 0.9:** **높다**.
> > * **0.4 ~ 0.7:** **다소 높다**.
> > * **0.2 ~ 0.4:** **낮다**.
> > * **0.0 ~ 0.2:** **거의 없다**.

---

> [!NOTE] 22페이지 – 가변수 (Dummy Variable) 설정
> 
> 자, 이제 다음 Master Group인 **'회귀분석'**으로 넘어가기 전, 반드시 알아야 할 기술적인 내용입니다.
> 만약 독립변수가 수치가 아니라 **'혈액형'**처럼 카테고리라면 어떻게 분석할까요? 
> 
> > [!WARNING] ⚠️ 범주형 변수의 처리 (가변수)
> > * **원칙:** 독립변수가 범주형이면 **가변수(Dummy variable)**를 생성해야 합니다.
> > * **개수 공식:** 범주의 수가 **$k$개**라면, 가변수는 **$k-1$개**가 필요합니다.
> 
> > [!LIST] 📝 혈액형 예시 (A, B, O, AB형)
> > * 범주가 4개이므로 가변수는 **3개**가 필요합니다.
> > * **참조 범주(Reference):** 기준이 되는 **A형**은 모든 가변수 값을 **0**으로 둡니다.
> > * **해석:** 나중에 회귀계수가 나오면 **"참조 범주(A형)에 비해 특정 범주가 얼마나 영향을 주는가"**로 해석합니다.
> 
> 
> 
> 자, 상관분석의 모든 기초를 닦았습니다. 이해되시죠? 그럼 이제 진짜 꽃인 **회귀분석**으로 넘어가 봅시다!

---

<div style="page-break-after: always;"></div>

## Master Group 3: 단순선형회귀분석의 정석 (P. 23-33)

> [!NOTE] 23~24페이지 – Regression (회귀)의 시작과 임상 사례
> 
> 자, 이제 이번 강의의 하이라이트인 **'회귀(Regression)'**로 들어갑니다. 앞서 배운 상관분석이 단순히 "둘이 친한가?"를 보는 것이었다면, 회귀분석은 **"원인과 결과"**의 관계를 수치로 규명하는 작업입니다.
> 
> 실제 논문 사례를 통해 왜 회귀분석이 필요한지 확인해봅시다.
> 
> > [!quote] 🩺 임상 연구: Enterovirus 71(EV71) 감염 후 발달 장애 
> > * **연구 대상:** **중추신경계(CNS)** 침범을 동반한 **EV71 감염** 어린이 142명.
> > * **연구 목적:** 감염 후의 지능(IQ), 언어 이해력 등에 영향을 미치는 **예측 인자(Predictors)**를 분석하는 것입니다.
> 
> 이 연구에서는 먼저 **Univariate analysis**로 후보 변수를 선정한 뒤, 여러 독립변수를 동시에 고려하는 **Multiple regression analysis**를 수행했습니다. 
> 
> > [!IMPORTANT] 💡 회귀분석의 핵심 가치
> > 단순히 상관성만 보는 것이 아니라, **독립변수(X)**가 **종속변수(Y)**에 미치는 **영향력의 크기**를 추정하여 미래의 값을 **예측**할 수 있게 해줍니다.

---

> [!NOTE] 25~26페이지 – 단순선형회귀모형의 정의와 파라미터
> 
> 본격적으로 모형의 생김새를 뜯어봅시다. 가장 기본이 되는 **'단순선형회귀분석'**입니다.
> 
> > [!INFO] 🧬 단순선형회귀모형의 수식
> > $$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$
> > * **$y_i$**: **종속변수** (우리가 알고 싶은 결과값).
> > * **$x_i$**: **독립변수** (원인이 되는 변수).
> > * **$\beta_0$**: **상수(Constant)** 또는 **절편(Intercept)**. $X=0$일 때의 예측값입니다.
> > * **$\beta_1$**: **기울기(Slope)**. **X가 한 단위 변화할 때 Y가 얼마나 변화하는지**를 나타내는 가장 중요한 값입니다.
> > * **$\epsilon_i$**: **오차항(Error)**. 모형으로 설명하지 못하는 확률적 변동을 의미하며, **평균 0, 분산 $\sigma^2$인 정규분포**를 따른다고 가정합니다.
> 
> 26페이지의 그래프(혈장의 양 vs 체중)를 보세요. 점들 사이를 가로지르는 **직선**이 보이죠? 이 직선을 가장 잘 그리는 방법이 바로 다음 장에서 배울 **최소제곱법**입니다.

---

> [!NOTE] 27~28페이지 – 최소제곱법(Method of Least Squares)
> 
> 우리가 가진 데이터 점들 사이로 '최적의 선'을 어떻게 그을 수 있을까요?
> 
> 
> 
> > [!IMPORTANT] 🔑 최소제곱법의 원리
> > * **잔차(Residual, $e$):** 실제 관측값과 회귀선이 예측한 값 사이의 **거리**입니다.
> > * **목표:** 이 **잔차의 제곱합(Sum of Squares)**을 **최소화**하는 $\beta_0$와 $\beta_1$을 찾아내는 것입니다.
> 
> > [!TIP] ⭐️ 족보 포인트
> > 회귀계수를 추정할 때 그냥 잔차를 더하지 않고 **'제곱'**해서 더하는 이유는, 양수와 음수의 잔차가 서로 상쇄되는 것을 막고 큰 오차에 더 큰 가중치를 두기 위해서입니다.

---

> [!NOTE] 29~30페이지 – 결정계수($R^2$)와 모형 적합도 검정
> 
> 회귀선을 그렸다면, 이 선이 데이터를 얼마나 잘 설명하는지 평가해야겠죠?
> 
> > [!INFO] 🧬 변동의 분할 (SS Decomposition)
> > **전체 제곱합(SST) = 설명 안 되는 제곱합(SSE) + 설명되는 제곱합(SSR)**.
> 
> > [!IMPORTANT] 💡 결정계수 ($R^2$, Coefficient of Determination)
> > $$R^2 = \frac{SSR}{SST}$$
> > * **의미:** 전체 변동 중 **회귀 모형에 의해 설명되는 비율**입니다.
> > * **범위:** **0에서 1 사이**이며, 1에 가까울수록 모형의 **설명력**이 높다고 판단합니다.
> 
> > [!LIST] 📝 가설검정 (ANOVA) 
> > * **귀무가설($H_0$):** **$\beta = 0$** (X는 Y를 설명하는 데 도움이 안 된다).
> > * **검정 도구:** **분산분석(ANOVA)** 표를 통해 **F값**과 **p-value**를 확인합니다.
> > * **결론:** **p-value < 0.05**면 이 회귀 모형은 통계적으로 **유의(적합)**하다고 결론 내립니다.

---

> [!NOTE] 31~32페이지 – 단순선형회귀의 5대 기본 가정 (매우 중요!)
> 
> 여러분, 회귀분석은 아무 데이터에나 막 돌리는 게 아닙니다. 이 **5가지 가정**이 깨지면 그 결과는 믿을 수 없습니다. 시험 단골 문제입니다.
> 
> > [!WARNING] ⚠️ 회귀 모형의 필수 가정 (Yama)
> > 1. **상수성:** 독립변수 **X는 확률변수가 아닌 주어진 상수**여야 합니다.
> > 2. **선형성(Linearity):** X와 Y의 관계는 반드시 **직선적**이어야 합니다.
> > 3. **정규성(Normality):** 잔차(오차항)들은 **정규분포**를 따라야 합니다.
> > 4. **등분산성(Homoscedasticity):** 오차항의 분산은 X값에 관계없이 **일정**해야 합니다.
> > 5. **독립성(Independence):** 관찰값들은 서로 **독립**적이어야 하며, 서로 영향을 주지 않아야 합니다.
> 
> 

---

> [!NOTE] 33페이지 – 마무리 및 실습 권고
> 
> 자, 이론은 여기까지입니다. 하지만 통계는 직접 해보지 않으면 절대 내 것이 되지 않습니다.
> 
> > [!TIP] ⭐️ 교수님의 마지막 당부
> > "운전을 책으로 배울 수 없듯이, 통계도 **직접 클릭**해봐야 합니다".
> > 오늘 배운 에스트리올 예제와 간 수치 예제를 **SPSS**를 활용해 반드시 직접 실습해보길 바랍니다.
> 
> 긴 시간 고생 많았습니다. 질문 있는 학생은 앞으로 나오세요.

, ',
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>


>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니당.
## Master Group 1: 상관분석의 기초와 Pearson 계수 (P. 1-11)

> [!NOTE] 1페이지 – Correlation (상관) 
> 
> 자, 여러분 반갑습니다. 오늘부터 우리는 통계학의 꽃이라 할 수 있는 변수 간의 관계를 배우게 됩니다. 
> 그 첫 번째 단추가 바로 **'상관(Correlation)'**입니다. 
> 
> 단순히 "상관이 있다"는 말을 넘어, 이를 어떻게 **수치화**하고 **해석**하는지 임상 사례를 통해 살펴봅시다.

---

> [!NOTE] 2페이지 – 상관분석의 실제 임상 예시: PI3K Signaling 
> 
> 우리가 통계를 배우는 이유는 결국 논문을 읽고 환자에게 적용하기 위해서죠. 
> **Glioblastoma(교모세포종)** 환자의 **PI3K pathway** 활성을 분석한 실제 Cancer Research 논문 사례를 봅시다. 
> 
> > [!IMPORTANT] 💡 핵심 연구 기전 (PI3K Pathway)
> > * **PTEN 단백질:** PI3K 활성을 **억제(antagonize)**하는 **Tumor suppressor**입니다. 
> > * **PTEN Loss:** 이 단백질이 결손되면 **Akt**와 같은 effector들이 **활성화(activation)**됩니다. 
> > * **연구 목적:** 생체 내(In vivo)에서 이들의 **상관관계**를 **Univariate analysis**로 증명하는 것입니다. 
> 
> 아래 표(Table 1)의 수치를 눈여겨보세요. 
> 
> > [!LIST] 📝 Pearson Correlation 결과 해석
> > * **PTEN vs pAkt:** 상관계수가 **-0.58**, P값이 **0.00007**로 매우 유의한 **음(-)의 상관관계**를 보입니다. 
> > * **pAkt vs p-FKHR:** 상관계수 **0.48**, P값 **0.002**로 유의한 **양(+)의 상관관계**입니다. 
> > * 즉, **"PTEN이 없어질수록 Akt 활성화는 강해진다"**는 것이 통계적으로 입증된 것이죠. 
> 
> 자, 임상적 의미를 확인했으니 이제 이론적인 정의로 들어가 봅시다.

---

> [!NOTE] 3페이지 – 상관분석의 정의 및 주의사항 
> 
> 상관분석이란 무엇일까요? 핵심은 **'연관성'**입니다. 
> 
> > [!INFO] 🧬 상관분석(Correlation Analysis)의 본질
> > * **정의:** 두 개 이상의 변수들 사이에 어떤 **연관성**이 존재하는지 파악하는 기법입니다. 
> > * **한계:** 변수들 간의 **원인과 결과(인과관계)를 밝히는 것이 아닙니다.**  단지 단순한 **상관성**만 보는 것이죠. 
> 
> 교수로서 여러분께 강조하고 싶은 **주의사항**이 세 가지 있습니다. 시험에도 자주 언급되는 포인트죠. 
> 
> > [!WARNING] ⚠️ 분석 시 반드시 기억할 것
> > 1. **수학적 관계일 뿐:** 상관계수가 높다고 해서 이를 변수의 **질적 관계**로 확대 해석해서는 안 됩니다. 
> > 2. **선형성(Linearity)의 한계:** 상관계수는 오직 **선형 연관성**만 나타냅니다.  값이 작아도 곡선 형태의 다른 관계가 숨어있을 수 있습니다. 
> > 3. **초기 단계 적용:** 상관분석은 결론을 내는 단계가 아니라, 자료 분석의 **초기 단계**에 적용하는 것입니다. 
> 
> 다음 장에서 가장 많이 쓰이는 계수를 직접 확인해봅시다.

---

> [!NOTE] 4페이지 – Pearson 상관계수 ($r$) 
> 
> 여러분이 가장 흔히 접하게 될 것이 바로 이 **Pearson 상관계수**입니다. 
> 
> > [!IMPORTANT] 🔑 Pearson 계수의 전제 조건과 특징
> > * **대상:** **양적인(연속형)** 변수 두 개 사이의 관계를 봅니다. 
> > * **가정:** 반드시 자료가 **정규분포**를 한다는 가정이 필요합니다. 
> > * **범위:** **$-1 \le r \le 1$** 사이의 값을 가집니다. 
> 
> > [!LIST] 📝 방향성에 따른 해석
> > * **$+1$에 가까울수록:** **양(+)의 상관관계**가 강해집니다 (X가 늘면 Y도 증가). 
> > * **$-1$에 가까울수록:** **음(-)의 상관관계**가 강해집니다 (X가 늘면 Y는 감소). 
> 
> 이 수식($r$)이 기하학적으로 어떻게 표현되는지 시각적으로 확인하는 게 중요합니다. 

---

> [!NOTE] 5페이지 – 산점도를 통한 상관계수의 시각적 이해 
> 
> 수치만 보지 말고 **산점도(Scatter plot)**를 보세요. 
> 
> > [!INFO] 📈 그래프 형태별 상관성
> > * **$r \approx 1$:** 점들이 우상향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx -1$:** 점들이 우하향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx 0$:** 점들이 흩어져 있어 **상관관계가 존재하지 않는** 경우입니다. 
> 
> 여기서 교수님의 **원포인트 레슨!** 
> 
> > [!WARNING] ⚠️ $r \approx 0$ 이지만 관계가 있는 경우
> > * 산점도가 **U자형(2차 선형관계)**을 그리는 경우, Pearson 계수는 **0에 가깝게** 나옵니다. 
> > * 이는 **"1차 선형관계"가 없다**는 뜻이지, 아무런 관계가 없다는 뜻이 아님을 명심하세요! 

---

> [!NOTE] 6페이지 – Pearson 상관계수 검정절차 
> 
> 이제 우리가 구한 $r$값이 통계적으로 유의한지 검정해야 합니다. 
> 
> > [!LIST] 📝 가설 설정 및 검정
> > 1. **가설 설정:** 귀무가설($H_0$)은 **"상관계수가 0이다($\rho=0$)"** 즉, 관계가 없다는 것입니다. 
> > 2. **검정통계량 ($t^*$):** 아래 식을 통해 t값을 구합니다. 
> >    $$t^* = r\sqrt{\frac{n-2}{1-r^2}}$$
> > 3. **의사결정:** 계산된 t값에 해당하는 **p-value가 0.05보다 작으면** 귀무가설을 기각하고 유의한 상관관계가 있다고 판단합니다. 

---

> [!NOTE] 7페이지 – 실습 예제: 에스트리올과 신생아 체중 
> 
> 자, 직접 해봅시다. 31명의 산모 데이터를 가져왔습니다. 
> 
> > [!quote] 🩺 증례 데이터
> > * **독립변수(X):** 산모의 **에스트리올(estriol)** 수치 
> > * **종속변수(Y):** 신생아의 **체중(birthweight)** 
> > * **질문:** "산모의 호르몬 수치와 아이의 체중 사이에 상관관계가 있는가?" 
> 
> 데이터 개수($N$)는 **31개**입니다.  이제 SPSS를 켜봅시다. 

---

> [!NOTE] 8~10페이지 – SPSS 실제 구현 방법 
> 
> 메뉴를 잘 따라오세요. 시험이나 실습 때 경로를 모르면 당황합니다. 
> 
> > [!LIST] 📝 SPSS 분석 경로
> > 1. **그래프 그리기:** `Graphs` → `Legacy Dialogs` → **`Scatter/Dot...`** (시각적 확인 필수) 
> > 2. **상관분석 실행:** `Analyze` → `Correlate` → **`Bivariate...`** (이변량 상관분석) 
> > 3. **변수 선택:** 분석할 변수(estriol, birthweight)를 넘기고 **Pearson**에 체크합니다. 
> 
> 다음 페이지에서 그 결과를 해석하는 법을 알려드리죠.

---

> [!NOTE] 11페이지 – 결과 해석: 유의성 판단 
> 
> 결과 표(Correlations table)를 볼까요? 
> 
> > [!IMPORTANT] 💡 분석 결과 해석 (중요!)
> > * **Pearson Correlation ($r$):** **.610** 
> > * **Sig. (2-tailed) (P값):** **.000** 
> > * **샘플 수 ($N$):** **31** 
> 
> > [!TIP] ⭐️ 족보 포인트
> > * P값이 **0.05(심지어 0.01)보다 작으므로**, 이 상관관계는 **통계적으로 매우 유의**합니다. 
> > * 즉, **"산모의 에스트리올 수치가 높을수록 신생아의 체중도 무거워지는 경향이 있다"**고 결론 내릴 수 있습니다. 
> 
> 이해되시죠? 하지만 모든 자료가 이렇게 예쁘게 정규분포를 따르지는 않습니다. 
> 그럴 땐 어떻게 해야 할까요? 바로 다음 장에서 배울 **Spearman 계수**가 답입니다.

---

<div style="page-break-after: always;"></div>

## Master Group 2: Spearman 계수와 상관분석의 완성 (P. 12-22)

> [!NOTE] 12~13페이지 – Spearman 순위상관계수 ($r_s$)
> 
> 자, 앞서 배운 Pearson은 데이터가 예쁘게 **정규분포**를 따를 때만 쓸 수 있었습니다. 
> 하지만 실제 임상 데이터는 그렇지 않은 경우가 태반이죠. 그럴 때 우리가 꺼내 드는 비장의 카드가 바로 **'Spearman'**입니다.
> 
> > [!INFO] 🧬 Spearman 순위상관계수의 특징
> > * **비모수적 방법:** 데이터가 **정규분포를 따른다는 가정을 하기 힘든 경우**에 사용합니다.
> > * **순위(Rank) 활용:** 값의 크기 자체가 아니라 데이터의 **'순위'**를 매겨서 상관성을 분석합니다.
> > * **범위:** Pearson과 마찬가지로 **$-1 \le r_s \le 1$** 사이의 값을 가집니다.
> 
> > [!LIST] 📝 검정 절차 (Pearson과 유사)
> > 1. **가설 설정:** $H_0: \rho=0$ (상관관계가 없다) vs $H_1: \rho \ne 0$ (상관관계가 있다).
> > 2. **검정통계량 ($t_s^*$):** 순위 상관계수를 이용한 t-검정을 수행합니다.
> > 3. **판단:** 마찬가지로 **p-value < 0.05**면 유의하다고 봅니다.
> 
> 

---

> [!NOTE] 14~16페이지 – Spearman 실습: 간 수치(AST/ALT) 분석
> 
> 실제 환자 20명의 데이터를 봅시다. 간 건강의 지표인 **AST와 ALT**의 상관관계를 볼까요? 
> 
> > [!quote] 🩺 임상 데이터 예시
> > * **환자 수:** 20명.
> > * **분석 변수:** 혈액검사 결과인 **AST** 수치와 **ALT** 수치.
> 
> SPSS 메뉴 경로는 이전과 거의 같습니다. 다만 체크박스 하나만 바꾸면 되죠.
> 
> > [!IMPORTANT] 💡 SPSS 조작 포인트
> > * `Analyze` → `Correlate` → `Bivariate` 경로에서 반드시 **`Spearman`** 항목에 체크해야 합니다!.
> 
> 결과 표를 보면 상관계수가 **.792**, P값이 **.000**으로 나오네요.
> **"AST가 높으면 ALT도 높다"**는 강한 상관관계가 입증된 셈입니다.

---

> [!NOTE] 17~18페이지 – 상관분석의 시각적 요약 및 결정계수
> 
> 이제 상관분석을 마무리하며 아주 중요한 개념인 **'결정계수'**를 짚고 넘어갑시다.
> 
> > [!IMPORTANT] 🔑 상관계수($r$)와 결정계수($r^2$)
> > * **결정계수 ($r^2$):** 상관계수를 제곱한 값으로, **회귀제곱합을 전체제곱합으로 나눈 비율**입니다.
> > * **의미:** 독립변수가 종속변수의 변동을 얼마나 **설명**해주는지를 나타냅니다.
> > * **관계식:** $r = \pm\sqrt{\text{설명되는 변동} / \text{전체 변동}}$.
> 
> 18페이지의 산점도들을 보면 **완전한 양의 상관($r=1$)**부터 **상관없음($r=0$)**까지 한눈에 들어올 겁니다.

---

> [!NOTE] 19페이지 – 상관계수 크기에 따른 판단 기준 (중요!)
> 
> "교수님, 상관계수가 몇 점이어야 높다고 하나요?"라는 질문에 대한 답이 여기 있습니다. 이 표는 꼭 머릿속에 넣어두세요.
> 
> > [!TIP] ⭐️ 상관계수 해석 가이드 (야마)
> > * **0.9 ~ 1.0:** **아주 높다**.
> > * **0.7 ~ 0.9:** **높다**.
> > * **0.4 ~ 0.7:** **다소 높다**.
> > * **0.2 ~ 0.4:** **낮다**.
> > * **0.0 ~ 0.2:** **거의 없다**.

---

> [!NOTE] 22페이지 – 가변수 (Dummy Variable) 설정
> 
> 자, 이제 다음 Master Group인 **'회귀분석'**으로 넘어가기 전, 반드시 알아야 할 기술적인 내용입니다.
> 만약 독립변수가 수치가 아니라 **'혈액형'**처럼 카테고리라면 어떻게 분석할까요? 
> 
> > [!WARNING] ⚠️ 범주형 변수의 처리 (가변수)
> > * **원칙:** 독립변수가 범주형이면 **가변수(Dummy variable)**를 생성해야 합니다.
> > * **개수 공식:** 범주의 수가 **$k$개**라면, 가변수는 **$k-1$개**가 필요합니다.
> 
> > [!LIST] 📝 혈액형 예시 (A, B, O, AB형)
> > * 범주가 4개이므로 가변수는 **3개**가 필요합니다.
> > * **참조 범주(Reference):** 기준이 되는 **A형**은 모든 가변수 값을 **0**으로 둡니다.
> > * **해석:** 나중에 회귀계수가 나오면 **"참조 범주(A형)에 비해 특정 범주가 얼마나 영향을 주는가"**로 해석합니다.
> 
> 
> 
> 자, 상관분석의 모든 기초를 닦았습니다. 이해되시죠? 그럼 이제 진짜 꽃인 **회귀분석**으로 넘어가 봅시다!

---

<div style="page-break-after: always;"></div>

## Master Group 3: 단순선형회귀분석의 정석 (P. 23-33)

> [!NOTE] 23~24페이지 – Regression (회귀)의 시작과 임상 사례
> 
> 자, 이제 이번 강의의 하이라이트인 **'회귀(Regression)'**로 들어갑니다. 앞서 배운 상관분석이 단순히 "둘이 친한가?"를 보는 것이었다면, 회귀분석은 **"원인과 결과"**의 관계를 수치로 규명하는 작업입니다.
> 
> 실제 논문 사례를 통해 왜 회귀분석이 필요한지 확인해봅시다.
> 
> > [!quote] 🩺 임상 연구: Enterovirus 71(EV71) 감염 후 발달 장애 
> > * **연구 대상:** **중추신경계(CNS)** 침범을 동반한 **EV71 감염** 어린이 142명.
> > * **연구 목적:** 감염 후의 지능(IQ), 언어 이해력 등에 영향을 미치는 **예측 인자(Predictors)**를 분석하는 것입니다.
> 
> 이 연구에서는 먼저 **Univariate analysis**로 후보 변수를 선정한 뒤, 여러 독립변수를 동시에 고려하는 **Multiple regression analysis**를 수행했습니다. 
> 
> > [!IMPORTANT] 💡 회귀분석의 핵심 가치
> > 단순히 상관성만 보는 것이 아니라, **독립변수(X)**가 **종속변수(Y)**에 미치는 **영향력의 크기**를 추정하여 미래의 값을 **예측**할 수 있게 해줍니다.

---

> [!NOTE] 25~26페이지 – 단순선형회귀모형의 정의와 파라미터
> 
> 본격적으로 모형의 생김새를 뜯어봅시다. 가장 기본이 되는 **'단순선형회귀분석'**입니다.
> 
> > [!INFO] 🧬 단순선형회귀모형의 수식
> > $$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$
> > * **$y_i$**: **종속변수** (우리가 알고 싶은 결과값).
> > * **$x_i$**: **독립변수** (원인이 되는 변수).
> > * **$\beta_0$**: **상수(Constant)** 또는 **절편(Intercept)**. $X=0$일 때의 예측값입니다.
> > * **$\beta_1$**: **기울기(Slope)**. **X가 한 단위 변화할 때 Y가 얼마나 변화하는지**를 나타내는 가장 중요한 값입니다.
> > * **$\epsilon_i$**: **오차항(Error)**. 모형으로 설명하지 못하는 확률적 변동을 의미하며, **평균 0, 분산 $\sigma^2$인 정규분포**를 따른다고 가정합니다.
> 
> 26페이지의 그래프(혈장의 양 vs 체중)를 보세요. 점들 사이를 가로지르는 **직선**이 보이죠? 이 직선을 가장 잘 그리는 방법이 바로 다음 장에서 배울 **최소제곱법**입니다.

---

> [!NOTE] 27~28페이지 – 최소제곱법(Method of Least Squares)
> 
> 우리가 가진 데이터 점들 사이로 '최적의 선'을 어떻게 그을 수 있을까요?
> 
> 
> 
> > [!IMPORTANT] 🔑 최소제곱법의 원리
> > * **잔차(Residual, $e$):** 실제 관측값과 회귀선이 예측한 값 사이의 **거리**입니다.
> > * **목표:** 이 **잔차의 제곱합(Sum of Squares)**을 **최소화**하는 $\beta_0$와 $\beta_1$을 찾아내는 것입니다.
> 
> > [!TIP] ⭐️ 족보 포인트
> > 회귀계수를 추정할 때 그냥 잔차를 더하지 않고 **'제곱'**해서 더하는 이유는, 양수와 음수의 잔차가 서로 상쇄되는 것을 막고 큰 오차에 더 큰 가중치를 두기 위해서입니다.

---

> [!NOTE] 29~30페이지 – 결정계수($R^2$)와 모형 적합도 검정
> 
> 회귀선을 그렸다면, 이 선이 데이터를 얼마나 잘 설명하는지 평가해야겠죠?
> 
> > [!INFO] 🧬 변동의 분할 (SS Decomposition)
> > **전체 제곱합(SST) = 설명 안 되는 제곱합(SSE) + 설명되는 제곱합(SSR)**.
> 
> > [!IMPORTANT] 💡 결정계수 ($R^2$, Coefficient of Determination)
> > $$R^2 = \frac{SSR}{SST}$$
> > * **의미:** 전체 변동 중 **회귀 모형에 의해 설명되는 비율**입니다.
> > * **범위:** **0에서 1 사이**이며, 1에 가까울수록 모형의 **설명력**이 높다고 판단합니다.
> 
> > [!LIST] 📝 가설검정 (ANOVA) 
> > * **귀무가설($H_0$):** **$\beta = 0$** (X는 Y를 설명하는 데 도움이 안 된다).
> > * **검정 도구:** **분산분석(ANOVA)** 표를 통해 **F값**과 **p-value**를 확인합니다.
> > * **결론:** **p-value < 0.05**면 이 회귀 모형은 통계적으로 **유의(적합)**하다고 결론 내립니다.

---

> [!NOTE] 31~32페이지 – 단순선형회귀의 5대 기본 가정 (매우 중요!)
> 
> 여러분, 회귀분석은 아무 데이터에나 막 돌리는 게 아닙니다. 이 **5가지 가정**이 깨지면 그 결과는 믿을 수 없습니다. 시험 단골 문제입니다.
> 
> > [!WARNING] ⚠️ 회귀 모형의 필수 가정 (Yama)
> > 1. **상수성:** 독립변수 **X는 확률변수가 아닌 주어진 상수**여야 합니다.
> > 2. **선형성(Linearity):** X와 Y의 관계는 반드시 **직선적**이어야 합니다.
> > 3. **정규성(Normality):** 잔차(오차항)들은 **정규분포**를 따라야 합니다.
> > 4. **등분산성(Homoscedasticity):** 오차항의 분산은 X값에 관계없이 **일정**해야 합니다.
> > 5. **독립성(Independence):** 관찰값들은 서로 **독립**적이어야 하며, 서로 영향을 주지 않아야 합니다.
> 
> 

---

> [!NOTE] 33페이지 – 마무리 및 실습 권고
> 
> 자, 이론은 여기까지입니다. 하지만 통계는 직접 해보지 않으면 절대 내 것이 되지 않습니다.
> 
> > [!TIP] ⭐️ 교수님의 마지막 당부
> > "운전을 책으로 배울 수 없듯이, 통계도 **직접 클릭**해봐야 합니다".
> > 오늘 배운 에스트리올 예제와 간 수치 예제를 **SPSS**를 활용해 반드시 직접 실습해보길 바랍니다.
> 
> 긴 시간 고생 많았습니다. 질문 있는 학생은 앞으로 나오세요.

], ['\\(', '\\)'\|',
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>


>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니당.
## Master Group 1: 상관분석의 기초와 Pearson 계수 (P. 1-11)

> [!NOTE] 1페이지 – Correlation (상관) 
> 
> 자, 여러분 반갑습니다. 오늘부터 우리는 통계학의 꽃이라 할 수 있는 변수 간의 관계를 배우게 됩니다. 
> 그 첫 번째 단추가 바로 **'상관(Correlation)'**입니다. 
> 
> 단순히 "상관이 있다"는 말을 넘어, 이를 어떻게 **수치화**하고 **해석**하는지 임상 사례를 통해 살펴봅시다.

---

> [!NOTE] 2페이지 – 상관분석의 실제 임상 예시: PI3K Signaling 
> 
> 우리가 통계를 배우는 이유는 결국 논문을 읽고 환자에게 적용하기 위해서죠. 
> **Glioblastoma(교모세포종)** 환자의 **PI3K pathway** 활성을 분석한 실제 Cancer Research 논문 사례를 봅시다. 
> 
> > [!IMPORTANT] 💡 핵심 연구 기전 (PI3K Pathway)
> > * **PTEN 단백질:** PI3K 활성을 **억제(antagonize)**하는 **Tumor suppressor**입니다. 
> > * **PTEN Loss:** 이 단백질이 결손되면 **Akt**와 같은 effector들이 **활성화(activation)**됩니다. 
> > * **연구 목적:** 생체 내(In vivo)에서 이들의 **상관관계**를 **Univariate analysis**로 증명하는 것입니다. 
> 
> 아래 표(Table 1)의 수치를 눈여겨보세요. 
> 
> > [!LIST] 📝 Pearson Correlation 결과 해석
> > * **PTEN vs pAkt:** 상관계수가 **-0.58**, P값이 **0.00007**로 매우 유의한 **음(-)의 상관관계**를 보입니다. 
> > * **pAkt vs p-FKHR:** 상관계수 **0.48**, P값 **0.002**로 유의한 **양(+)의 상관관계**입니다. 
> > * 즉, **"PTEN이 없어질수록 Akt 활성화는 강해진다"**는 것이 통계적으로 입증된 것이죠. 
> 
> 자, 임상적 의미를 확인했으니 이제 이론적인 정의로 들어가 봅시다.

---

> [!NOTE] 3페이지 – 상관분석의 정의 및 주의사항 
> 
> 상관분석이란 무엇일까요? 핵심은 **'연관성'**입니다. 
> 
> > [!INFO] 🧬 상관분석(Correlation Analysis)의 본질
> > * **정의:** 두 개 이상의 변수들 사이에 어떤 **연관성**이 존재하는지 파악하는 기법입니다. 
> > * **한계:** 변수들 간의 **원인과 결과(인과관계)를 밝히는 것이 아닙니다.**  단지 단순한 **상관성**만 보는 것이죠. 
> 
> 교수로서 여러분께 강조하고 싶은 **주의사항**이 세 가지 있습니다. 시험에도 자주 언급되는 포인트죠. 
> 
> > [!WARNING] ⚠️ 분석 시 반드시 기억할 것
> > 1. **수학적 관계일 뿐:** 상관계수가 높다고 해서 이를 변수의 **질적 관계**로 확대 해석해서는 안 됩니다. 
> > 2. **선형성(Linearity)의 한계:** 상관계수는 오직 **선형 연관성**만 나타냅니다.  값이 작아도 곡선 형태의 다른 관계가 숨어있을 수 있습니다. 
> > 3. **초기 단계 적용:** 상관분석은 결론을 내는 단계가 아니라, 자료 분석의 **초기 단계**에 적용하는 것입니다. 
> 
> 다음 장에서 가장 많이 쓰이는 계수를 직접 확인해봅시다.

---

> [!NOTE] 4페이지 – Pearson 상관계수 ($r$) 
> 
> 여러분이 가장 흔히 접하게 될 것이 바로 이 **Pearson 상관계수**입니다. 
> 
> > [!IMPORTANT] 🔑 Pearson 계수의 전제 조건과 특징
> > * **대상:** **양적인(연속형)** 변수 두 개 사이의 관계를 봅니다. 
> > * **가정:** 반드시 자료가 **정규분포**를 한다는 가정이 필요합니다. 
> > * **범위:** **$-1 \le r \le 1$** 사이의 값을 가집니다. 
> 
> > [!LIST] 📝 방향성에 따른 해석
> > * **$+1$에 가까울수록:** **양(+)의 상관관계**가 강해집니다 (X가 늘면 Y도 증가). 
> > * **$-1$에 가까울수록:** **음(-)의 상관관계**가 강해집니다 (X가 늘면 Y는 감소). 
> 
> 이 수식($r$)이 기하학적으로 어떻게 표현되는지 시각적으로 확인하는 게 중요합니다. 

---

> [!NOTE] 5페이지 – 산점도를 통한 상관계수의 시각적 이해 
> 
> 수치만 보지 말고 **산점도(Scatter plot)**를 보세요. 
> 
> > [!INFO] 📈 그래프 형태별 상관성
> > * **$r \approx 1$:** 점들이 우상향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx -1$:** 점들이 우하향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx 0$:** 점들이 흩어져 있어 **상관관계가 존재하지 않는** 경우입니다. 
> 
> 여기서 교수님의 **원포인트 레슨!** 
> 
> > [!WARNING] ⚠️ $r \approx 0$ 이지만 관계가 있는 경우
> > * 산점도가 **U자형(2차 선형관계)**을 그리는 경우, Pearson 계수는 **0에 가깝게** 나옵니다. 
> > * 이는 **"1차 선형관계"가 없다**는 뜻이지, 아무런 관계가 없다는 뜻이 아님을 명심하세요! 

---

> [!NOTE] 6페이지 – Pearson 상관계수 검정절차 
> 
> 이제 우리가 구한 $r$값이 통계적으로 유의한지 검정해야 합니다. 
> 
> > [!LIST] 📝 가설 설정 및 검정
> > 1. **가설 설정:** 귀무가설($H_0$)은 **"상관계수가 0이다($\rho=0$)"** 즉, 관계가 없다는 것입니다. 
> > 2. **검정통계량 ($t^*$):** 아래 식을 통해 t값을 구합니다. 
> >    $$t^* = r\sqrt{\frac{n-2}{1-r^2}}$$
> > 3. **의사결정:** 계산된 t값에 해당하는 **p-value가 0.05보다 작으면** 귀무가설을 기각하고 유의한 상관관계가 있다고 판단합니다. 

---

> [!NOTE] 7페이지 – 실습 예제: 에스트리올과 신생아 체중 
> 
> 자, 직접 해봅시다. 31명의 산모 데이터를 가져왔습니다. 
> 
> > [!quote] 🩺 증례 데이터
> > * **독립변수(X):** 산모의 **에스트리올(estriol)** 수치 
> > * **종속변수(Y):** 신생아의 **체중(birthweight)** 
> > * **질문:** "산모의 호르몬 수치와 아이의 체중 사이에 상관관계가 있는가?" 
> 
> 데이터 개수($N$)는 **31개**입니다.  이제 SPSS를 켜봅시다. 

---

> [!NOTE] 8~10페이지 – SPSS 실제 구현 방법 
> 
> 메뉴를 잘 따라오세요. 시험이나 실습 때 경로를 모르면 당황합니다. 
> 
> > [!LIST] 📝 SPSS 분석 경로
> > 1. **그래프 그리기:** `Graphs` → `Legacy Dialogs` → **`Scatter/Dot...`** (시각적 확인 필수) 
> > 2. **상관분석 실행:** `Analyze` → `Correlate` → **`Bivariate...`** (이변량 상관분석) 
> > 3. **변수 선택:** 분석할 변수(estriol, birthweight)를 넘기고 **Pearson**에 체크합니다. 
> 
> 다음 페이지에서 그 결과를 해석하는 법을 알려드리죠.

---

> [!NOTE] 11페이지 – 결과 해석: 유의성 판단 
> 
> 결과 표(Correlations table)를 볼까요? 
> 
> > [!IMPORTANT] 💡 분석 결과 해석 (중요!)
> > * **Pearson Correlation ($r$):** **.610** 
> > * **Sig. (2-tailed) (P값):** **.000** 
> > * **샘플 수 ($N$):** **31** 
> 
> > [!TIP] ⭐️ 족보 포인트
> > * P값이 **0.05(심지어 0.01)보다 작으므로**, 이 상관관계는 **통계적으로 매우 유의**합니다. 
> > * 즉, **"산모의 에스트리올 수치가 높을수록 신생아의 체중도 무거워지는 경향이 있다"**고 결론 내릴 수 있습니다. 
> 
> 이해되시죠? 하지만 모든 자료가 이렇게 예쁘게 정규분포를 따르지는 않습니다. 
> 그럴 땐 어떻게 해야 할까요? 바로 다음 장에서 배울 **Spearman 계수**가 답입니다.

---

<div style="page-break-after: always;"></div>

## Master Group 2: Spearman 계수와 상관분석의 완성 (P. 12-22)

> [!NOTE] 12~13페이지 – Spearman 순위상관계수 ($r_s$)
> 
> 자, 앞서 배운 Pearson은 데이터가 예쁘게 **정규분포**를 따를 때만 쓸 수 있었습니다. 
> 하지만 실제 임상 데이터는 그렇지 않은 경우가 태반이죠. 그럴 때 우리가 꺼내 드는 비장의 카드가 바로 **'Spearman'**입니다.
> 
> > [!INFO] 🧬 Spearman 순위상관계수의 특징
> > * **비모수적 방법:** 데이터가 **정규분포를 따른다는 가정을 하기 힘든 경우**에 사용합니다.
> > * **순위(Rank) 활용:** 값의 크기 자체가 아니라 데이터의 **'순위'**를 매겨서 상관성을 분석합니다.
> > * **범위:** Pearson과 마찬가지로 **$-1 \le r_s \le 1$** 사이의 값을 가집니다.
> 
> > [!LIST] 📝 검정 절차 (Pearson과 유사)
> > 1. **가설 설정:** $H_0: \rho=0$ (상관관계가 없다) vs $H_1: \rho \ne 0$ (상관관계가 있다).
> > 2. **검정통계량 ($t_s^*$):** 순위 상관계수를 이용한 t-검정을 수행합니다.
> > 3. **판단:** 마찬가지로 **p-value < 0.05**면 유의하다고 봅니다.
> 
> 

---

> [!NOTE] 14~16페이지 – Spearman 실습: 간 수치(AST/ALT) 분석
> 
> 실제 환자 20명의 데이터를 봅시다. 간 건강의 지표인 **AST와 ALT**의 상관관계를 볼까요? 
> 
> > [!quote] 🩺 임상 데이터 예시
> > * **환자 수:** 20명.
> > * **분석 변수:** 혈액검사 결과인 **AST** 수치와 **ALT** 수치.
> 
> SPSS 메뉴 경로는 이전과 거의 같습니다. 다만 체크박스 하나만 바꾸면 되죠.
> 
> > [!IMPORTANT] 💡 SPSS 조작 포인트
> > * `Analyze` → `Correlate` → `Bivariate` 경로에서 반드시 **`Spearman`** 항목에 체크해야 합니다!.
> 
> 결과 표를 보면 상관계수가 **.792**, P값이 **.000**으로 나오네요.
> **"AST가 높으면 ALT도 높다"**는 강한 상관관계가 입증된 셈입니다.

---

> [!NOTE] 17~18페이지 – 상관분석의 시각적 요약 및 결정계수
> 
> 이제 상관분석을 마무리하며 아주 중요한 개념인 **'결정계수'**를 짚고 넘어갑시다.
> 
> > [!IMPORTANT] 🔑 상관계수($r$)와 결정계수($r^2$)
> > * **결정계수 ($r^2$):** 상관계수를 제곱한 값으로, **회귀제곱합을 전체제곱합으로 나눈 비율**입니다.
> > * **의미:** 독립변수가 종속변수의 변동을 얼마나 **설명**해주는지를 나타냅니다.
> > * **관계식:** $r = \pm\sqrt{\text{설명되는 변동} / \text{전체 변동}}$.
> 
> 18페이지의 산점도들을 보면 **완전한 양의 상관($r=1$)**부터 **상관없음($r=0$)**까지 한눈에 들어올 겁니다.

---

> [!NOTE] 19페이지 – 상관계수 크기에 따른 판단 기준 (중요!)
> 
> "교수님, 상관계수가 몇 점이어야 높다고 하나요?"라는 질문에 대한 답이 여기 있습니다. 이 표는 꼭 머릿속에 넣어두세요.
> 
> > [!TIP] ⭐️ 상관계수 해석 가이드 (야마)
> > * **0.9 ~ 1.0:** **아주 높다**.
> > * **0.7 ~ 0.9:** **높다**.
> > * **0.4 ~ 0.7:** **다소 높다**.
> > * **0.2 ~ 0.4:** **낮다**.
> > * **0.0 ~ 0.2:** **거의 없다**.

---

> [!NOTE] 22페이지 – 가변수 (Dummy Variable) 설정
> 
> 자, 이제 다음 Master Group인 **'회귀분석'**으로 넘어가기 전, 반드시 알아야 할 기술적인 내용입니다.
> 만약 독립변수가 수치가 아니라 **'혈액형'**처럼 카테고리라면 어떻게 분석할까요? 
> 
> > [!WARNING] ⚠️ 범주형 변수의 처리 (가변수)
> > * **원칙:** 독립변수가 범주형이면 **가변수(Dummy variable)**를 생성해야 합니다.
> > * **개수 공식:** 범주의 수가 **$k$개**라면, 가변수는 **$k-1$개**가 필요합니다.
> 
> > [!LIST] 📝 혈액형 예시 (A, B, O, AB형)
> > * 범주가 4개이므로 가변수는 **3개**가 필요합니다.
> > * **참조 범주(Reference):** 기준이 되는 **A형**은 모든 가변수 값을 **0**으로 둡니다.
> > * **해석:** 나중에 회귀계수가 나오면 **"참조 범주(A형)에 비해 특정 범주가 얼마나 영향을 주는가"**로 해석합니다.
> 
> 
> 
> 자, 상관분석의 모든 기초를 닦았습니다. 이해되시죠? 그럼 이제 진짜 꽃인 **회귀분석**으로 넘어가 봅시다!

---

<div style="page-break-after: always;"></div>

## Master Group 3: 단순선형회귀분석의 정석 (P. 23-33)

> [!NOTE] 23~24페이지 – Regression (회귀)의 시작과 임상 사례
> 
> 자, 이제 이번 강의의 하이라이트인 **'회귀(Regression)'**로 들어갑니다. 앞서 배운 상관분석이 단순히 "둘이 친한가?"를 보는 것이었다면, 회귀분석은 **"원인과 결과"**의 관계를 수치로 규명하는 작업입니다.
> 
> 실제 논문 사례를 통해 왜 회귀분석이 필요한지 확인해봅시다.
> 
> > [!quote] 🩺 임상 연구: Enterovirus 71(EV71) 감염 후 발달 장애 
> > * **연구 대상:** **중추신경계(CNS)** 침범을 동반한 **EV71 감염** 어린이 142명.
> > * **연구 목적:** 감염 후의 지능(IQ), 언어 이해력 등에 영향을 미치는 **예측 인자(Predictors)**를 분석하는 것입니다.
> 
> 이 연구에서는 먼저 **Univariate analysis**로 후보 변수를 선정한 뒤, 여러 독립변수를 동시에 고려하는 **Multiple regression analysis**를 수행했습니다. 
> 
> > [!IMPORTANT] 💡 회귀분석의 핵심 가치
> > 단순히 상관성만 보는 것이 아니라, **독립변수(X)**가 **종속변수(Y)**에 미치는 **영향력의 크기**를 추정하여 미래의 값을 **예측**할 수 있게 해줍니다.

---

> [!NOTE] 25~26페이지 – 단순선형회귀모형의 정의와 파라미터
> 
> 본격적으로 모형의 생김새를 뜯어봅시다. 가장 기본이 되는 **'단순선형회귀분석'**입니다.
> 
> > [!INFO] 🧬 단순선형회귀모형의 수식
> > $$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$
> > * **$y_i$**: **종속변수** (우리가 알고 싶은 결과값).
> > * **$x_i$**: **독립변수** (원인이 되는 변수).
> > * **$\beta_0$**: **상수(Constant)** 또는 **절편(Intercept)**. $X=0$일 때의 예측값입니다.
> > * **$\beta_1$**: **기울기(Slope)**. **X가 한 단위 변화할 때 Y가 얼마나 변화하는지**를 나타내는 가장 중요한 값입니다.
> > * **$\epsilon_i$**: **오차항(Error)**. 모형으로 설명하지 못하는 확률적 변동을 의미하며, **평균 0, 분산 $\sigma^2$인 정규분포**를 따른다고 가정합니다.
> 
> 26페이지의 그래프(혈장의 양 vs 체중)를 보세요. 점들 사이를 가로지르는 **직선**이 보이죠? 이 직선을 가장 잘 그리는 방법이 바로 다음 장에서 배울 **최소제곱법**입니다.

---

> [!NOTE] 27~28페이지 – 최소제곱법(Method of Least Squares)
> 
> 우리가 가진 데이터 점들 사이로 '최적의 선'을 어떻게 그을 수 있을까요?
> 
> 
> 
> > [!IMPORTANT] 🔑 최소제곱법의 원리
> > * **잔차(Residual, $e$):** 실제 관측값과 회귀선이 예측한 값 사이의 **거리**입니다.
> > * **목표:** 이 **잔차의 제곱합(Sum of Squares)**을 **최소화**하는 $\beta_0$와 $\beta_1$을 찾아내는 것입니다.
> 
> > [!TIP] ⭐️ 족보 포인트
> > 회귀계수를 추정할 때 그냥 잔차를 더하지 않고 **'제곱'**해서 더하는 이유는, 양수와 음수의 잔차가 서로 상쇄되는 것을 막고 큰 오차에 더 큰 가중치를 두기 위해서입니다.

---

> [!NOTE] 29~30페이지 – 결정계수($R^2$)와 모형 적합도 검정
> 
> 회귀선을 그렸다면, 이 선이 데이터를 얼마나 잘 설명하는지 평가해야겠죠?
> 
> > [!INFO] 🧬 변동의 분할 (SS Decomposition)
> > **전체 제곱합(SST) = 설명 안 되는 제곱합(SSE) + 설명되는 제곱합(SSR)**.
> 
> > [!IMPORTANT] 💡 결정계수 ($R^2$, Coefficient of Determination)
> > $$R^2 = \frac{SSR}{SST}$$
> > * **의미:** 전체 변동 중 **회귀 모형에 의해 설명되는 비율**입니다.
> > * **범위:** **0에서 1 사이**이며, 1에 가까울수록 모형의 **설명력**이 높다고 판단합니다.
> 
> > [!LIST] 📝 가설검정 (ANOVA) 
> > * **귀무가설($H_0$):** **$\beta = 0$** (X는 Y를 설명하는 데 도움이 안 된다).
> > * **검정 도구:** **분산분석(ANOVA)** 표를 통해 **F값**과 **p-value**를 확인합니다.
> > * **결론:** **p-value < 0.05**면 이 회귀 모형은 통계적으로 **유의(적합)**하다고 결론 내립니다.

---

> [!NOTE] 31~32페이지 – 단순선형회귀의 5대 기본 가정 (매우 중요!)
> 
> 여러분, 회귀분석은 아무 데이터에나 막 돌리는 게 아닙니다. 이 **5가지 가정**이 깨지면 그 결과는 믿을 수 없습니다. 시험 단골 문제입니다.
> 
> > [!WARNING] ⚠️ 회귀 모형의 필수 가정 (Yama)
> > 1. **상수성:** 독립변수 **X는 확률변수가 아닌 주어진 상수**여야 합니다.
> > 2. **선형성(Linearity):** X와 Y의 관계는 반드시 **직선적**이어야 합니다.
> > 3. **정규성(Normality):** 잔차(오차항)들은 **정규분포**를 따라야 합니다.
> > 4. **등분산성(Homoscedasticity):** 오차항의 분산은 X값에 관계없이 **일정**해야 합니다.
> > 5. **독립성(Independence):** 관찰값들은 서로 **독립**적이어야 하며, 서로 영향을 주지 않아야 합니다.
> 
> 

---

> [!NOTE] 33페이지 – 마무리 및 실습 권고
> 
> 자, 이론은 여기까지입니다. 하지만 통계는 직접 해보지 않으면 절대 내 것이 되지 않습니다.
> 
> > [!TIP] ⭐️ 교수님의 마지막 당부
> > "운전을 책으로 배울 수 없듯이, 통계도 **직접 클릭**해봐야 합니다".
> > 오늘 배운 에스트리올 예제와 간 수치 예제를 **SPSS**를 활용해 반드시 직접 실습해보길 바랍니다.
> 
> 긴 시간 고생 많았습니다. 질문 있는 학생은 앞으로 나오세요.

, ',
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>


>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니당.
## Master Group 1: 상관분석의 기초와 Pearson 계수 (P. 1-11)

> [!NOTE] 1페이지 – Correlation (상관) 
> 
> 자, 여러분 반갑습니다. 오늘부터 우리는 통계학의 꽃이라 할 수 있는 변수 간의 관계를 배우게 됩니다. 
> 그 첫 번째 단추가 바로 **'상관(Correlation)'**입니다. 
> 
> 단순히 "상관이 있다"는 말을 넘어, 이를 어떻게 **수치화**하고 **해석**하는지 임상 사례를 통해 살펴봅시다.

---

> [!NOTE] 2페이지 – 상관분석의 실제 임상 예시: PI3K Signaling 
> 
> 우리가 통계를 배우는 이유는 결국 논문을 읽고 환자에게 적용하기 위해서죠. 
> **Glioblastoma(교모세포종)** 환자의 **PI3K pathway** 활성을 분석한 실제 Cancer Research 논문 사례를 봅시다. 
> 
> > [!IMPORTANT] 💡 핵심 연구 기전 (PI3K Pathway)
> > * **PTEN 단백질:** PI3K 활성을 **억제(antagonize)**하는 **Tumor suppressor**입니다. 
> > * **PTEN Loss:** 이 단백질이 결손되면 **Akt**와 같은 effector들이 **활성화(activation)**됩니다. 
> > * **연구 목적:** 생체 내(In vivo)에서 이들의 **상관관계**를 **Univariate analysis**로 증명하는 것입니다. 
> 
> 아래 표(Table 1)의 수치를 눈여겨보세요. 
> 
> > [!LIST] 📝 Pearson Correlation 결과 해석
> > * **PTEN vs pAkt:** 상관계수가 **-0.58**, P값이 **0.00007**로 매우 유의한 **음(-)의 상관관계**를 보입니다. 
> > * **pAkt vs p-FKHR:** 상관계수 **0.48**, P값 **0.002**로 유의한 **양(+)의 상관관계**입니다. 
> > * 즉, **"PTEN이 없어질수록 Akt 활성화는 강해진다"**는 것이 통계적으로 입증된 것이죠. 
> 
> 자, 임상적 의미를 확인했으니 이제 이론적인 정의로 들어가 봅시다.

---

> [!NOTE] 3페이지 – 상관분석의 정의 및 주의사항 
> 
> 상관분석이란 무엇일까요? 핵심은 **'연관성'**입니다. 
> 
> > [!INFO] 🧬 상관분석(Correlation Analysis)의 본질
> > * **정의:** 두 개 이상의 변수들 사이에 어떤 **연관성**이 존재하는지 파악하는 기법입니다. 
> > * **한계:** 변수들 간의 **원인과 결과(인과관계)를 밝히는 것이 아닙니다.**  단지 단순한 **상관성**만 보는 것이죠. 
> 
> 교수로서 여러분께 강조하고 싶은 **주의사항**이 세 가지 있습니다. 시험에도 자주 언급되는 포인트죠. 
> 
> > [!WARNING] ⚠️ 분석 시 반드시 기억할 것
> > 1. **수학적 관계일 뿐:** 상관계수가 높다고 해서 이를 변수의 **질적 관계**로 확대 해석해서는 안 됩니다. 
> > 2. **선형성(Linearity)의 한계:** 상관계수는 오직 **선형 연관성**만 나타냅니다.  값이 작아도 곡선 형태의 다른 관계가 숨어있을 수 있습니다. 
> > 3. **초기 단계 적용:** 상관분석은 결론을 내는 단계가 아니라, 자료 분석의 **초기 단계**에 적용하는 것입니다. 
> 
> 다음 장에서 가장 많이 쓰이는 계수를 직접 확인해봅시다.

---

> [!NOTE] 4페이지 – Pearson 상관계수 ($r$) 
> 
> 여러분이 가장 흔히 접하게 될 것이 바로 이 **Pearson 상관계수**입니다. 
> 
> > [!IMPORTANT] 🔑 Pearson 계수의 전제 조건과 특징
> > * **대상:** **양적인(연속형)** 변수 두 개 사이의 관계를 봅니다. 
> > * **가정:** 반드시 자료가 **정규분포**를 한다는 가정이 필요합니다. 
> > * **범위:** **$-1 \le r \le 1$** 사이의 값을 가집니다. 
> 
> > [!LIST] 📝 방향성에 따른 해석
> > * **$+1$에 가까울수록:** **양(+)의 상관관계**가 강해집니다 (X가 늘면 Y도 증가). 
> > * **$-1$에 가까울수록:** **음(-)의 상관관계**가 강해집니다 (X가 늘면 Y는 감소). 
> 
> 이 수식($r$)이 기하학적으로 어떻게 표현되는지 시각적으로 확인하는 게 중요합니다. 

---

> [!NOTE] 5페이지 – 산점도를 통한 상관계수의 시각적 이해 
> 
> 수치만 보지 말고 **산점도(Scatter plot)**를 보세요. 
> 
> > [!INFO] 📈 그래프 형태별 상관성
> > * **$r \approx 1$:** 점들이 우상향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx -1$:** 점들이 우하향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx 0$:** 점들이 흩어져 있어 **상관관계가 존재하지 않는** 경우입니다. 
> 
> 여기서 교수님의 **원포인트 레슨!** 
> 
> > [!WARNING] ⚠️ $r \approx 0$ 이지만 관계가 있는 경우
> > * 산점도가 **U자형(2차 선형관계)**을 그리는 경우, Pearson 계수는 **0에 가깝게** 나옵니다. 
> > * 이는 **"1차 선형관계"가 없다**는 뜻이지, 아무런 관계가 없다는 뜻이 아님을 명심하세요! 

---

> [!NOTE] 6페이지 – Pearson 상관계수 검정절차 
> 
> 이제 우리가 구한 $r$값이 통계적으로 유의한지 검정해야 합니다. 
> 
> > [!LIST] 📝 가설 설정 및 검정
> > 1. **가설 설정:** 귀무가설($H_0$)은 **"상관계수가 0이다($\rho=0$)"** 즉, 관계가 없다는 것입니다. 
> > 2. **검정통계량 ($t^*$):** 아래 식을 통해 t값을 구합니다. 
> >    $$t^* = r\sqrt{\frac{n-2}{1-r^2}}$$
> > 3. **의사결정:** 계산된 t값에 해당하는 **p-value가 0.05보다 작으면** 귀무가설을 기각하고 유의한 상관관계가 있다고 판단합니다. 

---

> [!NOTE] 7페이지 – 실습 예제: 에스트리올과 신생아 체중 
> 
> 자, 직접 해봅시다. 31명의 산모 데이터를 가져왔습니다. 
> 
> > [!quote] 🩺 증례 데이터
> > * **독립변수(X):** 산모의 **에스트리올(estriol)** 수치 
> > * **종속변수(Y):** 신생아의 **체중(birthweight)** 
> > * **질문:** "산모의 호르몬 수치와 아이의 체중 사이에 상관관계가 있는가?" 
> 
> 데이터 개수($N$)는 **31개**입니다.  이제 SPSS를 켜봅시다. 

---

> [!NOTE] 8~10페이지 – SPSS 실제 구현 방법 
> 
> 메뉴를 잘 따라오세요. 시험이나 실습 때 경로를 모르면 당황합니다. 
> 
> > [!LIST] 📝 SPSS 분석 경로
> > 1. **그래프 그리기:** `Graphs` → `Legacy Dialogs` → **`Scatter/Dot...`** (시각적 확인 필수) 
> > 2. **상관분석 실행:** `Analyze` → `Correlate` → **`Bivariate...`** (이변량 상관분석) 
> > 3. **변수 선택:** 분석할 변수(estriol, birthweight)를 넘기고 **Pearson**에 체크합니다. 
> 
> 다음 페이지에서 그 결과를 해석하는 법을 알려드리죠.

---

> [!NOTE] 11페이지 – 결과 해석: 유의성 판단 
> 
> 결과 표(Correlations table)를 볼까요? 
> 
> > [!IMPORTANT] 💡 분석 결과 해석 (중요!)
> > * **Pearson Correlation ($r$):** **.610** 
> > * **Sig. (2-tailed) (P값):** **.000** 
> > * **샘플 수 ($N$):** **31** 
> 
> > [!TIP] ⭐️ 족보 포인트
> > * P값이 **0.05(심지어 0.01)보다 작으므로**, 이 상관관계는 **통계적으로 매우 유의**합니다. 
> > * 즉, **"산모의 에스트리올 수치가 높을수록 신생아의 체중도 무거워지는 경향이 있다"**고 결론 내릴 수 있습니다. 
> 
> 이해되시죠? 하지만 모든 자료가 이렇게 예쁘게 정규분포를 따르지는 않습니다. 
> 그럴 땐 어떻게 해야 할까요? 바로 다음 장에서 배울 **Spearman 계수**가 답입니다.

---

<div style="page-break-after: always;"></div>

## Master Group 2: Spearman 계수와 상관분석의 완성 (P. 12-22)

> [!NOTE] 12~13페이지 – Spearman 순위상관계수 ($r_s$)
> 
> 자, 앞서 배운 Pearson은 데이터가 예쁘게 **정규분포**를 따를 때만 쓸 수 있었습니다. 
> 하지만 실제 임상 데이터는 그렇지 않은 경우가 태반이죠. 그럴 때 우리가 꺼내 드는 비장의 카드가 바로 **'Spearman'**입니다.
> 
> > [!INFO] 🧬 Spearman 순위상관계수의 특징
> > * **비모수적 방법:** 데이터가 **정규분포를 따른다는 가정을 하기 힘든 경우**에 사용합니다.
> > * **순위(Rank) 활용:** 값의 크기 자체가 아니라 데이터의 **'순위'**를 매겨서 상관성을 분석합니다.
> > * **범위:** Pearson과 마찬가지로 **$-1 \le r_s \le 1$** 사이의 값을 가집니다.
> 
> > [!LIST] 📝 검정 절차 (Pearson과 유사)
> > 1. **가설 설정:** $H_0: \rho=0$ (상관관계가 없다) vs $H_1: \rho \ne 0$ (상관관계가 있다).
> > 2. **검정통계량 ($t_s^*$):** 순위 상관계수를 이용한 t-검정을 수행합니다.
> > 3. **판단:** 마찬가지로 **p-value < 0.05**면 유의하다고 봅니다.
> 
> 

---

> [!NOTE] 14~16페이지 – Spearman 실습: 간 수치(AST/ALT) 분석
> 
> 실제 환자 20명의 데이터를 봅시다. 간 건강의 지표인 **AST와 ALT**의 상관관계를 볼까요? 
> 
> > [!quote] 🩺 임상 데이터 예시
> > * **환자 수:** 20명.
> > * **분석 변수:** 혈액검사 결과인 **AST** 수치와 **ALT** 수치.
> 
> SPSS 메뉴 경로는 이전과 거의 같습니다. 다만 체크박스 하나만 바꾸면 되죠.
> 
> > [!IMPORTANT] 💡 SPSS 조작 포인트
> > * `Analyze` → `Correlate` → `Bivariate` 경로에서 반드시 **`Spearman`** 항목에 체크해야 합니다!.
> 
> 결과 표를 보면 상관계수가 **.792**, P값이 **.000**으로 나오네요.
> **"AST가 높으면 ALT도 높다"**는 강한 상관관계가 입증된 셈입니다.

---

> [!NOTE] 17~18페이지 – 상관분석의 시각적 요약 및 결정계수
> 
> 이제 상관분석을 마무리하며 아주 중요한 개념인 **'결정계수'**를 짚고 넘어갑시다.
> 
> > [!IMPORTANT] 🔑 상관계수($r$)와 결정계수($r^2$)
> > * **결정계수 ($r^2$):** 상관계수를 제곱한 값으로, **회귀제곱합을 전체제곱합으로 나눈 비율**입니다.
> > * **의미:** 독립변수가 종속변수의 변동을 얼마나 **설명**해주는지를 나타냅니다.
> > * **관계식:** $r = \pm\sqrt{\text{설명되는 변동} / \text{전체 변동}}$.
> 
> 18페이지의 산점도들을 보면 **완전한 양의 상관($r=1$)**부터 **상관없음($r=0$)**까지 한눈에 들어올 겁니다.

---

> [!NOTE] 19페이지 – 상관계수 크기에 따른 판단 기준 (중요!)
> 
> "교수님, 상관계수가 몇 점이어야 높다고 하나요?"라는 질문에 대한 답이 여기 있습니다. 이 표는 꼭 머릿속에 넣어두세요.
> 
> > [!TIP] ⭐️ 상관계수 해석 가이드 (야마)
> > * **0.9 ~ 1.0:** **아주 높다**.
> > * **0.7 ~ 0.9:** **높다**.
> > * **0.4 ~ 0.7:** **다소 높다**.
> > * **0.2 ~ 0.4:** **낮다**.
> > * **0.0 ~ 0.2:** **거의 없다**.

---

> [!NOTE] 22페이지 – 가변수 (Dummy Variable) 설정
> 
> 자, 이제 다음 Master Group인 **'회귀분석'**으로 넘어가기 전, 반드시 알아야 할 기술적인 내용입니다.
> 만약 독립변수가 수치가 아니라 **'혈액형'**처럼 카테고리라면 어떻게 분석할까요? 
> 
> > [!WARNING] ⚠️ 범주형 변수의 처리 (가변수)
> > * **원칙:** 독립변수가 범주형이면 **가변수(Dummy variable)**를 생성해야 합니다.
> > * **개수 공식:** 범주의 수가 **$k$개**라면, 가변수는 **$k-1$개**가 필요합니다.
> 
> > [!LIST] 📝 혈액형 예시 (A, B, O, AB형)
> > * 범주가 4개이므로 가변수는 **3개**가 필요합니다.
> > * **참조 범주(Reference):** 기준이 되는 **A형**은 모든 가변수 값을 **0**으로 둡니다.
> > * **해석:** 나중에 회귀계수가 나오면 **"참조 범주(A형)에 비해 특정 범주가 얼마나 영향을 주는가"**로 해석합니다.
> 
> 
> 
> 자, 상관분석의 모든 기초를 닦았습니다. 이해되시죠? 그럼 이제 진짜 꽃인 **회귀분석**으로 넘어가 봅시다!

---

<div style="page-break-after: always;"></div>

## Master Group 3: 단순선형회귀분석의 정석 (P. 23-33)

> [!NOTE] 23~24페이지 – Regression (회귀)의 시작과 임상 사례
> 
> 자, 이제 이번 강의의 하이라이트인 **'회귀(Regression)'**로 들어갑니다. 앞서 배운 상관분석이 단순히 "둘이 친한가?"를 보는 것이었다면, 회귀분석은 **"원인과 결과"**의 관계를 수치로 규명하는 작업입니다.
> 
> 실제 논문 사례를 통해 왜 회귀분석이 필요한지 확인해봅시다.
> 
> > [!quote] 🩺 임상 연구: Enterovirus 71(EV71) 감염 후 발달 장애 
> > * **연구 대상:** **중추신경계(CNS)** 침범을 동반한 **EV71 감염** 어린이 142명.
> > * **연구 목적:** 감염 후의 지능(IQ), 언어 이해력 등에 영향을 미치는 **예측 인자(Predictors)**를 분석하는 것입니다.
> 
> 이 연구에서는 먼저 **Univariate analysis**로 후보 변수를 선정한 뒤, 여러 독립변수를 동시에 고려하는 **Multiple regression analysis**를 수행했습니다. 
> 
> > [!IMPORTANT] 💡 회귀분석의 핵심 가치
> > 단순히 상관성만 보는 것이 아니라, **독립변수(X)**가 **종속변수(Y)**에 미치는 **영향력의 크기**를 추정하여 미래의 값을 **예측**할 수 있게 해줍니다.

---

> [!NOTE] 25~26페이지 – 단순선형회귀모형의 정의와 파라미터
> 
> 본격적으로 모형의 생김새를 뜯어봅시다. 가장 기본이 되는 **'단순선형회귀분석'**입니다.
> 
> > [!INFO] 🧬 단순선형회귀모형의 수식
> > $$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$
> > * **$y_i$**: **종속변수** (우리가 알고 싶은 결과값).
> > * **$x_i$**: **독립변수** (원인이 되는 변수).
> > * **$\beta_0$**: **상수(Constant)** 또는 **절편(Intercept)**. $X=0$일 때의 예측값입니다.
> > * **$\beta_1$**: **기울기(Slope)**. **X가 한 단위 변화할 때 Y가 얼마나 변화하는지**를 나타내는 가장 중요한 값입니다.
> > * **$\epsilon_i$**: **오차항(Error)**. 모형으로 설명하지 못하는 확률적 변동을 의미하며, **평균 0, 분산 $\sigma^2$인 정규분포**를 따른다고 가정합니다.
> 
> 26페이지의 그래프(혈장의 양 vs 체중)를 보세요. 점들 사이를 가로지르는 **직선**이 보이죠? 이 직선을 가장 잘 그리는 방법이 바로 다음 장에서 배울 **최소제곱법**입니다.

---

> [!NOTE] 27~28페이지 – 최소제곱법(Method of Least Squares)
> 
> 우리가 가진 데이터 점들 사이로 '최적의 선'을 어떻게 그을 수 있을까요?
> 
> 
> 
> > [!IMPORTANT] 🔑 최소제곱법의 원리
> > * **잔차(Residual, $e$):** 실제 관측값과 회귀선이 예측한 값 사이의 **거리**입니다.
> > * **목표:** 이 **잔차의 제곱합(Sum of Squares)**을 **최소화**하는 $\beta_0$와 $\beta_1$을 찾아내는 것입니다.
> 
> > [!TIP] ⭐️ 족보 포인트
> > 회귀계수를 추정할 때 그냥 잔차를 더하지 않고 **'제곱'**해서 더하는 이유는, 양수와 음수의 잔차가 서로 상쇄되는 것을 막고 큰 오차에 더 큰 가중치를 두기 위해서입니다.

---

> [!NOTE] 29~30페이지 – 결정계수($R^2$)와 모형 적합도 검정
> 
> 회귀선을 그렸다면, 이 선이 데이터를 얼마나 잘 설명하는지 평가해야겠죠?
> 
> > [!INFO] 🧬 변동의 분할 (SS Decomposition)
> > **전체 제곱합(SST) = 설명 안 되는 제곱합(SSE) + 설명되는 제곱합(SSR)**.
> 
> > [!IMPORTANT] 💡 결정계수 ($R^2$, Coefficient of Determination)
> > $$R^2 = \frac{SSR}{SST}$$
> > * **의미:** 전체 변동 중 **회귀 모형에 의해 설명되는 비율**입니다.
> > * **범위:** **0에서 1 사이**이며, 1에 가까울수록 모형의 **설명력**이 높다고 판단합니다.
> 
> > [!LIST] 📝 가설검정 (ANOVA) 
> > * **귀무가설($H_0$):** **$\beta = 0$** (X는 Y를 설명하는 데 도움이 안 된다).
> > * **검정 도구:** **분산분석(ANOVA)** 표를 통해 **F값**과 **p-value**를 확인합니다.
> > * **결론:** **p-value < 0.05**면 이 회귀 모형은 통계적으로 **유의(적합)**하다고 결론 내립니다.

---

> [!NOTE] 31~32페이지 – 단순선형회귀의 5대 기본 가정 (매우 중요!)
> 
> 여러분, 회귀분석은 아무 데이터에나 막 돌리는 게 아닙니다. 이 **5가지 가정**이 깨지면 그 결과는 믿을 수 없습니다. 시험 단골 문제입니다.
> 
> > [!WARNING] ⚠️ 회귀 모형의 필수 가정 (Yama)
> > 1. **상수성:** 독립변수 **X는 확률변수가 아닌 주어진 상수**여야 합니다.
> > 2. **선형성(Linearity):** X와 Y의 관계는 반드시 **직선적**이어야 합니다.
> > 3. **정규성(Normality):** 잔차(오차항)들은 **정규분포**를 따라야 합니다.
> > 4. **등분산성(Homoscedasticity):** 오차항의 분산은 X값에 관계없이 **일정**해야 합니다.
> > 5. **독립성(Independence):** 관찰값들은 서로 **독립**적이어야 하며, 서로 영향을 주지 않아야 합니다.
> 
> 

---

> [!NOTE] 33페이지 – 마무리 및 실습 권고
> 
> 자, 이론은 여기까지입니다. 하지만 통계는 직접 해보지 않으면 절대 내 것이 되지 않습니다.
> 
> > [!TIP] ⭐️ 교수님의 마지막 당부
> > "운전을 책으로 배울 수 없듯이, 통계도 **직접 클릭**해봐야 합니다".
> > 오늘 배운 에스트리올 예제와 간 수치 예제를 **SPSS**를 활용해 반드시 직접 실습해보길 바랍니다.
> 
> 긴 시간 고생 많았습니다. 질문 있는 학생은 앞으로 나오세요.

], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>


>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니당.
## Master Group 1: 상관분석의 기초와 Pearson 계수 (P. 1-11)

> [!NOTE] 1페이지 – Correlation (상관) 
> 
> 자, 여러분 반갑습니다. 오늘부터 우리는 통계학의 꽃이라 할 수 있는 변수 간의 관계를 배우게 됩니다. 
> 그 첫 번째 단추가 바로 **'상관(Correlation)'**입니다. 
> 
> 단순히 "상관이 있다"는 말을 넘어, 이를 어떻게 **수치화**하고 **해석**하는지 임상 사례를 통해 살펴봅시다.

---

> [!NOTE] 2페이지 – 상관분석의 실제 임상 예시: PI3K Signaling 
> 
> 우리가 통계를 배우는 이유는 결국 논문을 읽고 환자에게 적용하기 위해서죠. 
> **Glioblastoma(교모세포종)** 환자의 **PI3K pathway** 활성을 분석한 실제 Cancer Research 논문 사례를 봅시다. 
> 
> > [!IMPORTANT] 💡 핵심 연구 기전 (PI3K Pathway)
> > * **PTEN 단백질:** PI3K 활성을 **억제(antagonize)**하는 **Tumor suppressor**입니다. 
> > * **PTEN Loss:** 이 단백질이 결손되면 **Akt**와 같은 effector들이 **활성화(activation)**됩니다. 
> > * **연구 목적:** 생체 내(In vivo)에서 이들의 **상관관계**를 **Univariate analysis**로 증명하는 것입니다. 
> 
> 아래 표(Table 1)의 수치를 눈여겨보세요. 
> 
> > [!LIST] 📝 Pearson Correlation 결과 해석
> > * **PTEN vs pAkt:** 상관계수가 **-0.58**, P값이 **0.00007**로 매우 유의한 **음(-)의 상관관계**를 보입니다. 
> > * **pAkt vs p-FKHR:** 상관계수 **0.48**, P값 **0.002**로 유의한 **양(+)의 상관관계**입니다. 
> > * 즉, **"PTEN이 없어질수록 Akt 활성화는 강해진다"**는 것이 통계적으로 입증된 것이죠. 
> 
> 자, 임상적 의미를 확인했으니 이제 이론적인 정의로 들어가 봅시다.

---

> [!NOTE] 3페이지 – 상관분석의 정의 및 주의사항 
> 
> 상관분석이란 무엇일까요? 핵심은 **'연관성'**입니다. 
> 
> > [!INFO] 🧬 상관분석(Correlation Analysis)의 본질
> > * **정의:** 두 개 이상의 변수들 사이에 어떤 **연관성**이 존재하는지 파악하는 기법입니다. 
> > * **한계:** 변수들 간의 **원인과 결과(인과관계)를 밝히는 것이 아닙니다.**  단지 단순한 **상관성**만 보는 것이죠. 
> 
> 교수로서 여러분께 강조하고 싶은 **주의사항**이 세 가지 있습니다. 시험에도 자주 언급되는 포인트죠. 
> 
> > [!WARNING] ⚠️ 분석 시 반드시 기억할 것
> > 1. **수학적 관계일 뿐:** 상관계수가 높다고 해서 이를 변수의 **질적 관계**로 확대 해석해서는 안 됩니다. 
> > 2. **선형성(Linearity)의 한계:** 상관계수는 오직 **선형 연관성**만 나타냅니다.  값이 작아도 곡선 형태의 다른 관계가 숨어있을 수 있습니다. 
> > 3. **초기 단계 적용:** 상관분석은 결론을 내는 단계가 아니라, 자료 분석의 **초기 단계**에 적용하는 것입니다. 
> 
> 다음 장에서 가장 많이 쓰이는 계수를 직접 확인해봅시다.

---

> [!NOTE] 4페이지 – Pearson 상관계수 ($r$) 
> 
> 여러분이 가장 흔히 접하게 될 것이 바로 이 **Pearson 상관계수**입니다. 
> 
> > [!IMPORTANT] 🔑 Pearson 계수의 전제 조건과 특징
> > * **대상:** **양적인(연속형)** 변수 두 개 사이의 관계를 봅니다. 
> > * **가정:** 반드시 자료가 **정규분포**를 한다는 가정이 필요합니다. 
> > * **범위:** **$-1 \le r \le 1$** 사이의 값을 가집니다. 
> 
> > [!LIST] 📝 방향성에 따른 해석
> > * **$+1$에 가까울수록:** **양(+)의 상관관계**가 강해집니다 (X가 늘면 Y도 증가). 
> > * **$-1$에 가까울수록:** **음(-)의 상관관계**가 강해집니다 (X가 늘면 Y는 감소). 
> 
> 이 수식($r$)이 기하학적으로 어떻게 표현되는지 시각적으로 확인하는 게 중요합니다. 

---

> [!NOTE] 5페이지 – 산점도를 통한 상관계수의 시각적 이해 
> 
> 수치만 보지 말고 **산점도(Scatter plot)**를 보세요. 
> 
> > [!INFO] 📈 그래프 형태별 상관성
> > * **$r \approx 1$:** 점들이 우상향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx -1$:** 점들이 우하향 직선에 가깝게 모여 있습니다. 
> > * **$r \approx 0$:** 점들이 흩어져 있어 **상관관계가 존재하지 않는** 경우입니다. 
> 
> 여기서 교수님의 **원포인트 레슨!** 
> 
> > [!WARNING] ⚠️ $r \approx 0$ 이지만 관계가 있는 경우
> > * 산점도가 **U자형(2차 선형관계)**을 그리는 경우, Pearson 계수는 **0에 가깝게** 나옵니다. 
> > * 이는 **"1차 선형관계"가 없다**는 뜻이지, 아무런 관계가 없다는 뜻이 아님을 명심하세요! 

---

> [!NOTE] 6페이지 – Pearson 상관계수 검정절차 
> 
> 이제 우리가 구한 $r$값이 통계적으로 유의한지 검정해야 합니다. 
> 
> > [!LIST] 📝 가설 설정 및 검정
> > 1. **가설 설정:** 귀무가설($H_0$)은 **"상관계수가 0이다($\rho=0$)"** 즉, 관계가 없다는 것입니다. 
> > 2. **검정통계량 ($t^*$):** 아래 식을 통해 t값을 구합니다. 
> >    $$t^* = r\sqrt{\frac{n-2}{1-r^2}}$$
> > 3. **의사결정:** 계산된 t값에 해당하는 **p-value가 0.05보다 작으면** 귀무가설을 기각하고 유의한 상관관계가 있다고 판단합니다. 

---

> [!NOTE] 7페이지 – 실습 예제: 에스트리올과 신생아 체중 
> 
> 자, 직접 해봅시다. 31명의 산모 데이터를 가져왔습니다. 
> 
> > [!quote] 🩺 증례 데이터
> > * **독립변수(X):** 산모의 **에스트리올(estriol)** 수치 
> > * **종속변수(Y):** 신생아의 **체중(birthweight)** 
> > * **질문:** "산모의 호르몬 수치와 아이의 체중 사이에 상관관계가 있는가?" 
> 
> 데이터 개수($N$)는 **31개**입니다.  이제 SPSS를 켜봅시다. 

---

> [!NOTE] 8~10페이지 – SPSS 실제 구현 방법 
> 
> 메뉴를 잘 따라오세요. 시험이나 실습 때 경로를 모르면 당황합니다. 
> 
> > [!LIST] 📝 SPSS 분석 경로
> > 1. **그래프 그리기:** `Graphs` → `Legacy Dialogs` → **`Scatter/Dot...`** (시각적 확인 필수) 
> > 2. **상관분석 실행:** `Analyze` → `Correlate` → **`Bivariate...`** (이변량 상관분석) 
> > 3. **변수 선택:** 분석할 변수(estriol, birthweight)를 넘기고 **Pearson**에 체크합니다. 
> 
> 다음 페이지에서 그 결과를 해석하는 법을 알려드리죠.

---

> [!NOTE] 11페이지 – 결과 해석: 유의성 판단 
> 
> 결과 표(Correlations table)를 볼까요? 
> 
> > [!IMPORTANT] 💡 분석 결과 해석 (중요!)
> > * **Pearson Correlation ($r$):** **.610** 
> > * **Sig. (2-tailed) (P값):** **.000** 
> > * **샘플 수 ($N$):** **31** 
> 
> > [!TIP] ⭐️ 족보 포인트
> > * P값이 **0.05(심지어 0.01)보다 작으므로**, 이 상관관계는 **통계적으로 매우 유의**합니다. 
> > * 즉, **"산모의 에스트리올 수치가 높을수록 신생아의 체중도 무거워지는 경향이 있다"**고 결론 내릴 수 있습니다. 
> 
> 이해되시죠? 하지만 모든 자료가 이렇게 예쁘게 정규분포를 따르지는 않습니다. 
> 그럴 땐 어떻게 해야 할까요? 바로 다음 장에서 배울 **Spearman 계수**가 답입니다.

---

<div style="page-break-after: always;"></div>

## Master Group 2: Spearman 계수와 상관분석의 완성 (P. 12-22)

> [!NOTE] 12~13페이지 – Spearman 순위상관계수 ($r_s$)
> 
> 자, 앞서 배운 Pearson은 데이터가 예쁘게 **정규분포**를 따를 때만 쓸 수 있었습니다. 
> 하지만 실제 임상 데이터는 그렇지 않은 경우가 태반이죠. 그럴 때 우리가 꺼내 드는 비장의 카드가 바로 **'Spearman'**입니다.
> 
> > [!INFO] 🧬 Spearman 순위상관계수의 특징
> > * **비모수적 방법:** 데이터가 **정규분포를 따른다는 가정을 하기 힘든 경우**에 사용합니다.
> > * **순위(Rank) 활용:** 값의 크기 자체가 아니라 데이터의 **'순위'**를 매겨서 상관성을 분석합니다.
> > * **범위:** Pearson과 마찬가지로 **$-1 \le r_s \le 1$** 사이의 값을 가집니다.
> 
> > [!LIST] 📝 검정 절차 (Pearson과 유사)
> > 1. **가설 설정:** $H_0: \rho=0$ (상관관계가 없다) vs $H_1: \rho \ne 0$ (상관관계가 있다).
> > 2. **검정통계량 ($t_s^*$):** 순위 상관계수를 이용한 t-검정을 수행합니다.
> > 3. **판단:** 마찬가지로 **p-value < 0.05**면 유의하다고 봅니다.
> 
> 

---

> [!NOTE] 14~16페이지 – Spearman 실습: 간 수치(AST/ALT) 분석
> 
> 실제 환자 20명의 데이터를 봅시다. 간 건강의 지표인 **AST와 ALT**의 상관관계를 볼까요? 
> 
> > [!quote] 🩺 임상 데이터 예시
> > * **환자 수:** 20명.
> > * **분석 변수:** 혈액검사 결과인 **AST** 수치와 **ALT** 수치.
> 
> SPSS 메뉴 경로는 이전과 거의 같습니다. 다만 체크박스 하나만 바꾸면 되죠.
> 
> > [!IMPORTANT] 💡 SPSS 조작 포인트
> > * `Analyze` → `Correlate` → `Bivariate` 경로에서 반드시 **`Spearman`** 항목에 체크해야 합니다!.
> 
> 결과 표를 보면 상관계수가 **.792**, P값이 **.000**으로 나오네요.
> **"AST가 높으면 ALT도 높다"**는 강한 상관관계가 입증된 셈입니다.

---

> [!NOTE] 17~18페이지 – 상관분석의 시각적 요약 및 결정계수
> 
> 이제 상관분석을 마무리하며 아주 중요한 개념인 **'결정계수'**를 짚고 넘어갑시다.
> 
> > [!IMPORTANT] 🔑 상관계수($r$)와 결정계수($r^2$)
> > * **결정계수 ($r^2$):** 상관계수를 제곱한 값으로, **회귀제곱합을 전체제곱합으로 나눈 비율**입니다.
> > * **의미:** 독립변수가 종속변수의 변동을 얼마나 **설명**해주는지를 나타냅니다.
> > * **관계식:** $r = \pm\sqrt{\text{설명되는 변동} / \text{전체 변동}}$.
> 
> 18페이지의 산점도들을 보면 **완전한 양의 상관($r=1$)**부터 **상관없음($r=0$)**까지 한눈에 들어올 겁니다.

---

> [!NOTE] 19페이지 – 상관계수 크기에 따른 판단 기준 (중요!)
> 
> "교수님, 상관계수가 몇 점이어야 높다고 하나요?"라는 질문에 대한 답이 여기 있습니다. 이 표는 꼭 머릿속에 넣어두세요.
> 
> > [!TIP] ⭐️ 상관계수 해석 가이드 (야마)
> > * **0.9 ~ 1.0:** **아주 높다**.
> > * **0.7 ~ 0.9:** **높다**.
> > * **0.4 ~ 0.7:** **다소 높다**.
> > * **0.2 ~ 0.4:** **낮다**.
> > * **0.0 ~ 0.2:** **거의 없다**.

---

> [!NOTE] 22페이지 – 가변수 (Dummy Variable) 설정
> 
> 자, 이제 다음 Master Group인 **'회귀분석'**으로 넘어가기 전, 반드시 알아야 할 기술적인 내용입니다.
> 만약 독립변수가 수치가 아니라 **'혈액형'**처럼 카테고리라면 어떻게 분석할까요? 
> 
> > [!WARNING] ⚠️ 범주형 변수의 처리 (가변수)
> > * **원칙:** 독립변수가 범주형이면 **가변수(Dummy variable)**를 생성해야 합니다.
> > * **개수 공식:** 범주의 수가 **$k$개**라면, 가변수는 **$k-1$개**가 필요합니다.
> 
> > [!LIST] 📝 혈액형 예시 (A, B, O, AB형)
> > * 범주가 4개이므로 가변수는 **3개**가 필요합니다.
> > * **참조 범주(Reference):** 기준이 되는 **A형**은 모든 가변수 값을 **0**으로 둡니다.
> > * **해석:** 나중에 회귀계수가 나오면 **"참조 범주(A형)에 비해 특정 범주가 얼마나 영향을 주는가"**로 해석합니다.
> 
> 
> 
> 자, 상관분석의 모든 기초를 닦았습니다. 이해되시죠? 그럼 이제 진짜 꽃인 **회귀분석**으로 넘어가 봅시다!

---

<div style="page-break-after: always;"></div>

## Master Group 3: 단순선형회귀분석의 정석 (P. 23-33)

> [!NOTE] 23~24페이지 – Regression (회귀)의 시작과 임상 사례
> 
> 자, 이제 이번 강의의 하이라이트인 **'회귀(Regression)'**로 들어갑니다. 앞서 배운 상관분석이 단순히 "둘이 친한가?"를 보는 것이었다면, 회귀분석은 **"원인과 결과"**의 관계를 수치로 규명하는 작업입니다.
> 
> 실제 논문 사례를 통해 왜 회귀분석이 필요한지 확인해봅시다.
> 
> > [!quote] 🩺 임상 연구: Enterovirus 71(EV71) 감염 후 발달 장애 
> > * **연구 대상:** **중추신경계(CNS)** 침범을 동반한 **EV71 감염** 어린이 142명.
> > * **연구 목적:** 감염 후의 지능(IQ), 언어 이해력 등에 영향을 미치는 **예측 인자(Predictors)**를 분석하는 것입니다.
> 
> 이 연구에서는 먼저 **Univariate analysis**로 후보 변수를 선정한 뒤, 여러 독립변수를 동시에 고려하는 **Multiple regression analysis**를 수행했습니다. 
> 
> > [!IMPORTANT] 💡 회귀분석의 핵심 가치
> > 단순히 상관성만 보는 것이 아니라, **독립변수(X)**가 **종속변수(Y)**에 미치는 **영향력의 크기**를 추정하여 미래의 값을 **예측**할 수 있게 해줍니다.

---

> [!NOTE] 25~26페이지 – 단순선형회귀모형의 정의와 파라미터
> 
> 본격적으로 모형의 생김새를 뜯어봅시다. 가장 기본이 되는 **'단순선형회귀분석'**입니다.
> 
> > [!INFO] 🧬 단순선형회귀모형의 수식
> > $$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$
> > * **$y_i$**: **종속변수** (우리가 알고 싶은 결과값).
> > * **$x_i$**: **독립변수** (원인이 되는 변수).
> > * **$\beta_0$**: **상수(Constant)** 또는 **절편(Intercept)**. $X=0$일 때의 예측값입니다.
> > * **$\beta_1$**: **기울기(Slope)**. **X가 한 단위 변화할 때 Y가 얼마나 변화하는지**를 나타내는 가장 중요한 값입니다.
> > * **$\epsilon_i$**: **오차항(Error)**. 모형으로 설명하지 못하는 확률적 변동을 의미하며, **평균 0, 분산 $\sigma^2$인 정규분포**를 따른다고 가정합니다.
> 
> 26페이지의 그래프(혈장의 양 vs 체중)를 보세요. 점들 사이를 가로지르는 **직선**이 보이죠? 이 직선을 가장 잘 그리는 방법이 바로 다음 장에서 배울 **최소제곱법**입니다.

---

> [!NOTE] 27~28페이지 – 최소제곱법(Method of Least Squares)
> 
> 우리가 가진 데이터 점들 사이로 '최적의 선'을 어떻게 그을 수 있을까요?
> 
> 
> 
> > [!IMPORTANT] 🔑 최소제곱법의 원리
> > * **잔차(Residual, $e$):** 실제 관측값과 회귀선이 예측한 값 사이의 **거리**입니다.
> > * **목표:** 이 **잔차의 제곱합(Sum of Squares)**을 **최소화**하는 $\beta_0$와 $\beta_1$을 찾아내는 것입니다.
> 
> > [!TIP] ⭐️ 족보 포인트
> > 회귀계수를 추정할 때 그냥 잔차를 더하지 않고 **'제곱'**해서 더하는 이유는, 양수와 음수의 잔차가 서로 상쇄되는 것을 막고 큰 오차에 더 큰 가중치를 두기 위해서입니다.

---

> [!NOTE] 29~30페이지 – 결정계수($R^2$)와 모형 적합도 검정
> 
> 회귀선을 그렸다면, 이 선이 데이터를 얼마나 잘 설명하는지 평가해야겠죠?
> 
> > [!INFO] 🧬 변동의 분할 (SS Decomposition)
> > **전체 제곱합(SST) = 설명 안 되는 제곱합(SSE) + 설명되는 제곱합(SSR)**.
> 
> > [!IMPORTANT] 💡 결정계수 ($R^2$, Coefficient of Determination)
> > $$R^2 = \frac{SSR}{SST}$$
> > * **의미:** 전체 변동 중 **회귀 모형에 의해 설명되는 비율**입니다.
> > * **범위:** **0에서 1 사이**이며, 1에 가까울수록 모형의 **설명력**이 높다고 판단합니다.
> 
> > [!LIST] 📝 가설검정 (ANOVA) 
> > * **귀무가설($H_0$):** **$\beta = 0$** (X는 Y를 설명하는 데 도움이 안 된다).
> > * **검정 도구:** **분산분석(ANOVA)** 표를 통해 **F값**과 **p-value**를 확인합니다.
> > * **결론:** **p-value < 0.05**면 이 회귀 모형은 통계적으로 **유의(적합)**하다고 결론 내립니다.

---

> [!NOTE] 31~32페이지 – 단순선형회귀의 5대 기본 가정 (매우 중요!)
> 
> 여러분, 회귀분석은 아무 데이터에나 막 돌리는 게 아닙니다. 이 **5가지 가정**이 깨지면 그 결과는 믿을 수 없습니다. 시험 단골 문제입니다.
> 
> > [!WARNING] ⚠️ 회귀 모형의 필수 가정 (Yama)
> > 1. **상수성:** 독립변수 **X는 확률변수가 아닌 주어진 상수**여야 합니다.
> > 2. **선형성(Linearity):** X와 Y의 관계는 반드시 **직선적**이어야 합니다.
> > 3. **정규성(Normality):** 잔차(오차항)들은 **정규분포**를 따라야 합니다.
> > 4. **등분산성(Homoscedasticity):** 오차항의 분산은 X값에 관계없이 **일정**해야 합니다.
> > 5. **독립성(Independence):** 관찰값들은 서로 **독립**적이어야 하며, 서로 영향을 주지 않아야 합니다.
> 
> 

---

> [!NOTE] 33페이지 – 마무리 및 실습 권고
> 
> 자, 이론은 여기까지입니다. 하지만 통계는 직접 해보지 않으면 절대 내 것이 되지 않습니다.
> 
> > [!TIP] ⭐️ 교수님의 마지막 당부
> > "운전을 책으로 배울 수 없듯이, 통계도 **직접 클릭**해봐야 합니다".
> > 오늘 배운 에스트리올 예제와 간 수치 예제를 **SPSS**를 활용해 반드시 직접 실습해보길 바랍니다.
> 
> 긴 시간 고생 많았습니다. 질문 있는 학생은 앞으로 나오세요.

