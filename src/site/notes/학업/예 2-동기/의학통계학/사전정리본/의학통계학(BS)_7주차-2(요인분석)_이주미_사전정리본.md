---
{"dg-publish":true,"permalink":"//2///bs-7-2/"}
---

<script>
MathJax = {
  tex: {
    inlineMath: [[',
    displayMath: [['$', '$'], ['\\[', '\\]'\|'$', '$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니다.

# 요인 분석

> [!NOTE] 1~2페이지 – 강의 서두: 요인분석(Factor Analysis)의 문을 열며
> 
> 자, 여러분 반갑습니다. 오늘은 다변량 분석의 꽃이라 불리는 **요인분석(Factor Analysis)**에 대해 심도 있게 다뤄보겠습니다.  
> 
> > [!INFO] 🧬 요인분석의 핵심 정의
> > 요인분석은 수많은 변수 간의 **상관관계**를 이용하여, 공통된 특성을 가진 것끼리 묶어주는 기법입니다.  
> > 즉, 데이터의 **복잡성을 압축**하여 소수의 **핵심 요인(Factor)**으로 정보를 요약하는 **다변량 분석**의 핵심이라 할 수 있죠. 
> 
> 왜 우리가 이 복잡한 계산을 해야 할까요? 단순히 숫자를 줄이는 것 이상의 임상적 의미가 있기 때문입니다.

> [!NOTE] 3~4페이지 – 왜 '요인'으로 묶어야 하는가? (데이터의 압축)
> 
> 우리가 수십 개의 설문 문항을 분석한다고 가정해 봅시다. 이걸 하나하나 다루면 머리가 아프겠죠? 
> 
> > [!IMPORTANT] 💡 요인분석을 사용하는 두 가지 이유 (Yama)
> > * **변수 집단화:** 어떤 변수들이 서로 유기적으로 연결되어 있는지 **관찰**하고 묶기 위함입니다. 
> > * **차원 축소:** 유사한 변수를 하나의 요인으로 합쳐서, 나중에 **종속변수와의 관련성**을 더 명확하게 분석하기 위해 사용합니다. 
> 
> > [!LIST] 📝 분석의 흐름
> > * **Input:** 다양하고 해석하기 어려운 **상관성 있는 변수**들의 뭉치 
> > * **Process:** 요인분석을 통한 데이터 다이어트
> > * **Output:** 개념적으로 명확하고 **독립적인 소수 변수**로의 변환 
> 
> 
>
> 자, 그림을 보시면 아시겠지만, 흩어져 있던 변수들이 의미 있는 큰 덩어리로 합쳐지는 과정입니다.  이제 이 기법이 실제 연구에서 어떻게 적용되는지 봅시다.

> [!NOTE] 5~6페이지 – 탐색적 요인분석(EFA)과 분산의 구조
> 
> 실제 연구에서는 최종 분석 전에 변수들을 정리하기 위해 이 단계를 꼭 거칩니다.  특히 **숨겨진 공통요인**을 찾아내는 것이 주된 목적이죠. 
> 
> > [!IMPORTANT] 🔑 탐색적 요인분석(EFA)의 핵심 원리
> > * 측정 변수 간의 상관관계를 통해 **소수의 요인**을 도출합니다. 
> > * **총 분산의 구성:** $$총 분산 = 공통 요인 분산(잠재변수) + 고유 요인 분산(Error)$$ 
> 
> > [!INFO] 🧬 공통분(Communality)이란?
> > 특정 변수가 가진 전체 분산 중에서, 추출된 **공통 요인**에 의해 설명되는 양을 의미합니다.  
> > 이 값이 높을수록 해당 변수가 요인에 잘 반영되었다는 뜻이겠죠?
> 
> 하지만 요인을 추출할 때 주의해야 할 점이 있습니다. 너무 많이 나눠도, 너무 적게 나눠도 문제입니다.

> [!NOTE] 7~8페이지 – 요인 추출의 실패 사례와 메커니즘
> 
> 요인분석도 과유불급입니다. 연구자가 판단을 잘못하면 분석 결과가 산으로 갈 수 있어요. 
> 
> > [!WARNING] ⚠️ 분석 실패의 두 가지 유형
> > * **Overfactoring:** 실제로는 하나로 묶여야 할 요인을 **너무 잘게 쪼개어** 도출한 경우입니다. 
> > * **Underfactoring:** 더 상세히 나눌 수 있음에도 불구하고 **너무 적은 요인**만 뽑아낸 경우입니다. 
> 
> > [!IMPORTANT] 💡 이론 구조 개발의 핵심
> > 요인분석은 **고유 요인(Error)**을 제거하고 오직 **공통 요인**만 추출하려 노력합니다.  
> > 이를 위해 통계적으로는 **축소 상관행렬(Reduced correlation matrix)**이라는 도구를 사용하게 되죠. 
> 
> 자, 이제 요인분석이 무엇을 하려는 기법인지 감이 오시죠? 다음 장(Group 2)에서는 이 과정을 수학적으로 어떻게 표현하는지, 그리고 많은 분이 헷갈려 하는 주성분 분석과의 차이점을 명확히 짚어드리겠습니다.

---

> [!NOTE] 9~10페이지 – 요인분석의 수학적 뼈대: 직교 요인 모형 (Orthogonal Factor Model)
> 
> 자, 이제 요인분석이 내부적으로 어떤 계산 과정을 거치는지 그 뼈대를 살펴봅시다. 통계학적으로 요인분석은 변수들을 선형 결합으로 표현하는 **직교 요인 모형**을 따릅니다.
> 
> > [!INFO] 🧬 기본적인 선형 모형 (Matrix Form)
> > $$X = LF + \epsilon$$
> > * **$X$**: 관측된 $p$개의 변수 벡터입니다.
> > * **$L$**: **요인 부하량(Factor Loading)** 행렬로, 각 변수와 요인 간의 관계 강도를 나타냅니다.
> > * **$F$**: 우리가 찾고자 하는 잠재적인 **공통 요인**입니다.
> > * **$\epsilon$**: 각 변수만이 가진 **고유 요인(Error)**입니다.
> 
> 이 수식을 통해 우리는 개별 변수의 전체 분산을 두 가지 성분으로 쪼갤 수 있습니다.
> 
> > [!IMPORTANT] 💡 분산의 구성: 커뮤날리티 vs 특수 분산
> > $$var(x_i) = h_i^2 (Communality) + \Psi_i (Specific Variance)$$ 
> > * **커뮤날리티($h_i^2$):** $m$개의 공통 요인에 의해 설명되는 부분입니다.
> > * **특수 분산($\Psi_i$):** 공통 요인으로 설명되지 않는 그 변수만의 고유한 변동입니다.
> 
> 앞서 배운 '공통 요인'을 추출한다는 것은 결국 이 **커뮤날리티**를 극대화하는 과정이라고 이해하시면 됩니다.

> [!NOTE] 11페이지 – 요인 추출의 방법론: 주축분해법 vs 최대우도법
> 
> 수학적 모델을 세웠으니 이제 실제 값을 추정해야겠죠? SPSS에서 주로 사용하는 두 가지 핵심 방법을 비교해 봅시다.
> 
> > [!LIST] 📝 주요 추정 방법 비교
> > * **주축분해법(Principal Axis Factoring):** 
> > 	 - **SPSS** 사용 시 가장 권장되는 방법입니다.
> >     - **SMC(Squared Multiple Correlation)**를 초기 커뮤날리티로 사용하여 반복 계산을 통해 최적값을 찾습니다.
> > * **최대우도법(Maximum Likelihood, ML):** 
> > 	- 표본의 상관행렬과 모형의 상관행렬이 최대한 유사해지도록 추정합니다.
> > 	- **정상성 가정**에 민감하고 **많은 표본**이 필요하지만, 적합도 검증($\chi^2$)이 가능하다는 장점이 있습니다.
> 
> 어떤 방법을 선택하느냐에 따라 결과가 달라질 수 있으니 데이터의 특성을 먼저 파악해야 합니다.

> [!NOTE] 12페이지 – SPSS의 함정: 주성분 분석(PCA)과 요인분석의 차이
> 
> 여기서 아주 중요한 주의사항이 하나 나옵니다. SPSS의 기본 설정(Default)에 속지 마세요.
> 
> > [!WARNING] ⚠️ 주성분 분석(PCA)을 지양해야 하는 이유 (Yama)
> > * **오차 무시:** PCA는 데이터에 **에러(Error)가 없다**고 가정합니다. 
> > * **분산 설명 최대화:** 단순히 많은 변수를 소수로 축소하는 데 초점을 맞춥니다.
> > * **행동과학에서의 한계:** 사람의 심리나 행동 데이터는 오차를 무시할 수 없으므로, 엄밀한 의미의 **요인분석**에서는 PCA 사용을 지양해야 합니다.
> 
> 교수님들이 흔히 **"PCA는 불필요한 분석이다"**라고 말씀하시는 이유가 바로 이 **오차 항의 부재** 때문입니다.

> [!NOTE] 13~14페이지 – 주성분 방법의 논리: 분산 설명력의 극대화
> 
> 그럼에도 불구하고 PCA의 논리를 이해하는 것은 기초 체력을 기르는 데 도움이 됩니다.
> 
> > [!INFO] 🧬 주성분(PC) 도출 원리
> > * **총 분산:** 모든 변수의 표본분산의 합입니다.
> > * **제1주성분 [PC(1)]:** 자료의 총 분산을 **가장 많이 설명**할 수 있도록 변수들을 가중 결합한 것입니다.
> > * **제2주성분 [PC(2)]:** 첫 번째 주성분이 설명하지 못한 나머지 분산을 최대한 설명하며, **PC(1)과는 상관성이 없는(직교하는)** 결합입니다.
> 
> > [!IMPORTANT] 💡 가중치 결정의 목적
> > 가능한 한 **적은 수의 요인**으로 전체 데이터의 불확실성(Uncertainty)을 가장 잘 설명하는 것이 핵심입니다.
> 
> 자, 이제 수학적 기초와 분석 도구들의 특징을 정리했습니다. 이제 추출된 요인을 어떻게 더 명확하게 해석할 것인지, **요인 회전**과 **확인적 요인분석**의 세계로 넘어가 봅시다 (Group 3).

---

> [!NOTE] 15~16페이지 – 요인 회전(Rotation): 해석의 마법
> 
> 요인을 추출한 직후의 결과는 보통 해석하기가 매우 난해합니다. 이때 필요한 것이 바로 **요인 회전**입니다.
> 
> > [!INFO] 🧬 단순구조(Simple Structure)
> > 회전의 목적은 수학적으로는 동일한 모델을 유지하면서, 각 변수가 특정 요인에만 강하게 걸리도록 **단순구조**를 만들어 **해석을 용이**하게 하는 데 있습니다.
> 
> > [!IMPORTANT] 💡 회전 방법의 선택 (Yama)
> > 1. **직각회전(Orthogonal):** 요인 간의 **상관관계가 0**이라고 가정합니다. (예: **Varimax**)
> >    - 단, 사회과학이나 의학 데이터에서 요인 간 상관이 전혀 없다는 것은 **논리적으로 무리(Logic nonsense)**가 있을 수 있습니다.
> > 2. **사각회전(Oblique):** 요인 간의 **상관을 인정**합니다. (예: **Promax**, **Direct Oblimin**)
> >    - 현실적인 데이터 분석에서는 사각회전이 훨씬 더 권장됩니다.
> 
> > [!LIST] 📝 행렬의 종류
> > * **패턴행렬(Pattern Matrix):** 요인이 변수에 미치는 영향력(회귀계수)을 나타내며, 사각회전 시 주로 해석합니다.
> > * **구조행렬(Structure Matrix):** 요인과 변수 사이의 단순 상관계수입니다.
> 
> 자, 이 회전된 축을 통해 비로소 우리는 요인에 '이름'을 붙여줄 수 있게 됩니다.

> [!NOTE] 17페이지 – 분석 도구별 권장 절차
> 
> 여러분이 어떤 프로그램을 쓰느냐에 따라 권장되는 분석 루틴이 조금 다릅니다. 이 루틴을 외워두면 실무에서 큰 도움이 됩니다.
> 
> > [!TIP] ⭐️ 프로그램별 Standard (족보)
> > * **SPSS 사용 시:** **주축분해법** 추출 → 스크리 도표/평행분석으로 요인 수 결정 → **사각회전** 적용.
> > * **구조방정식(SEM) 모델링 시:** **최대우도법(ML)** 추출 → 적합도 지수 확인 → **사각회전** 적용.
> 
> 이제 우리가 지금까지 한 '탐색'을 넘어, 이미 알고 있는 이론을 '확인'하는 단계로 가봅시다.

> [!NOTE] 18~19페이지 – 확인적 요인분석(CFA)의 논리
> 
> 탐색적 요인분석(EFA)이 "뭐가 나올지 모르는 상태에서 묶어보는 것"이라면, **확인적 요인분석(CFA)**은 "내가 세운 가설이 맞는지 검증하는 것"입니다.
> 
> > [!IMPORTANT] 🔑 CFA의 핵심 차이점
> > * **제약(Constraint):** 특정 변수는 특정 요인에만 영향을 받는다고 미리 식을 고정합니다.
> > * **오차 상관:** 이론적 근거가 있다면 문항 간 **오차 공분산**을 허용할 수 있습니다.
> > * **주의사항 (Critical):** **동일한 자료**에 대해 EFA를 하고 그 결과로 다시 CFA를 수행하는 것은 통계적으로 **지양**해야 합니다.
> 
> > [!INFO] 🧬 식별을 위한 고정(Scaling)
> > 모델이 돌아가려면 기준이 필요합니다. 보통 **요인계수가 가장 높은 변수**의 계수를 **1**로 고정(Reference variable)하거나, 잠재변수의 분산을 1로 고정합니다.

> [!NOTE] 20페이지 – 모델이 얼마나 잘 맞는가? 적합도 지수(Fit Indices)
> 
> CFA를 돌리고 나면 반드시 이 모델이 실제 데이터를 얼마나 잘 설명하는지 수치로 보여줘야 합니다.
> 
> > [!IMPORTANT] 💡 권장 적합도 판단 기준 (Hu & Bentler, 1999)
> > * **TLI / CFI:** **0.90 이상**이면 괜찮고, **0.95 이상**이면 매우 좋은 모델입니다.
> > * **RMSEA:** **0.05 미만**이면 Close fit(최상), **0.08 미만**이면 양호(Reasonable)한 것으로 봅니다. **0.10**을 넘어가면 수용 불가능합니다.
> > * **SRMR:** **0.08 미만**을 기준으로 삼습니다.
> 
> $\chi^2$(카이제곱) 검정은 너무 엄격해서 표본이 조금만 커도 기각되기 쉽기 때문에, 보통 위 지수들을 종합적으로 보고 모델의 우수성을 판단합니다.

> [!NOTE] 21페이지 – 새로운 변수의 탄생: 요인 점수(Factor Score)
> 
> 자, 요인분석의 마지막 단계입니다. 우리는 수많은 문항을 몇 개의 요인으로 묶었습니다. 이제 이 요인들을 **하나의 숫자**로 만들어서 다음 분석에 써먹어야겠죠?
> 
> > [!INFO] 🧬 요인 점수란?
> > 공통 요인의 추정값으로, 추출된 요인을 새로운 **독립변수**나 **종속변수**로 활용할 수 있게 해주는 값입니다.
> 
> > [!LIST] 📝 점수 산출 방법
> > 1. **가중 최소제곱법 (Bartlett):** 측정 오차를 고려한 가중치를 부여합니다.
> > 2. **회귀 방법 (Regression):** 가장 보편적으로 사용되는 방식입니다.
> 
> 이제 이론은 완벽하게 정리되었습니다. 백문이 불여일견이죠. 다음 장(Group 4)부터는 실제 **피로 척도 데이터**를 가지고 SPSS를 직접 돌려보겠습니다.

---

> [!NOTE] 22~23페이지 – SPSS 실습 예제: 다차원 피로 척도(MFS) 분석
> 
> 자, 이론은 여기까지 하고 이제 직접 데이터를 만져봅시다. 오늘 사용할 데이터는 **피로.sav** 파일입니다. 
> 
> > [!quote] 🩺 실습 케이스: 다차원 피로 척도(MFS)
> > * **목적**: 주관적 피로 증상을 측정하기 위해 개발된 **19문항**의 척도가 과연 몇 개의 요인으로 구분되는지 파악하는 것입니다.
> > * **활용**: 추출된 요인을 새로운 변수로 만들어 추후 분석에 사용하고자 합니다.
> 
> 먼저 메뉴부터 찾아 들어가야겠죠? **분석(A) > 차원 감소 > 요인분석(F)** 순서로 클릭하세요.
> 
> 

> [!NOTE] 24~25페이지 – 변수 선택 및 투입
> 
> 창이 뜨면 왼쪽 변수 목록에서 우리가 분석할 문항들을 골라야 합니다.
> 
> > [!LIST] 📝 변수 선택 단계
> > 1. 성별, 연령 같은 인구학적 변수는 일단 제외합니다.
> > 2. 분석하고자 하는 설문 문항인 **피로1부터 피로19**까지를 모두 선택합니다.
> > 3. 오른쪽의 **변수(V)** 박스로 모든 문항을 이동시킵니다.
> 
> 
> 
> 문항을 다 옮겼다면, 이제 우측의 버튼들을 하나씩 눌러 세부 설정을 해줄 차례입니다.

> [!NOTE] 26~27페이지 – 요인 추출(Extraction)과 회전(Rotation) 설정
> 
> 여기가 가장 중요합니다. 제가 이론 강의 때 강조했던 내용들을 적용하는 단계예요.
> 
> > [!IMPORTANT] 💡 요인 추출(Extraction) 설정
> > * **방법**: 기본값은 **주성분(PCA)** 분석으로 되어 있습니다. (학술적 목적에 따라 주축분해법 등으로 변경 가능합니다.)
> > * **추출 기준**: 보통 **고유값(Eigenvalue) 1**을 기준으로 삼지만, 연구자가 특정 요인 수를 직접 지정할 수도 있습니다.
> > * **출력**: 흐름을 파악하기 위해 **스크리 도표(Scree Plot)**를 체크하는 습관을 들이세요.
> 
> > [!IMPORTANT] 💡 요인 회전(Rotation) 설정
> > * **방법**: 여기서는 직각회전 방식인 **베리맥스(Varimax)**를 선택하겠습니다. 
> > * **목적**: 요인 적재량을 재배치하여 어떤 문항이 어떤 요인에 속하는지 명확히 보기 위함입니다.
> 
> 

> [!NOTE] 28~29페이지 – 요인 점수 저장 및 출력 옵션
> 
> 분석 결과만 보고 끝낼 게 아니라, 이 요인들을 나중에 회귀분석 등에 써먹으려면 점수로 저장해야 합니다.
> 
> > [!LIST] 📝 추가 옵션 설정
> > * **요인 점수**: **'변수로 저장(S)'**을 체크하고 방법은 **'회귀분석'**을 선택합니다. 이렇게 하면 데이터 파일 끝에 새로운 변수가 생깁니다.
> > * **옵션(Options)**: 결과표를 보기 좋게 만들기 위해 **'크기순 정렬'**을 체크하세요. 적재량이 큰 순서대로 문항이 나열되어 훨씬 읽기 편해집니다.
> 
> 

> [!NOTE] 30~31페이지 – 명령문(Syntax) 생성 및 실행
> 
> 확인 버튼을 바로 누르지 말고, **'붙여넣기'**를 눌러보세요. 고수들은 항상 이렇게 합니다.
> 
> > [!TIP] ⭐️ 명령문(Syntax) 활용의 장점 (Yama)
> > * **FACTOR** 명령어로 시작하는 구문이 나타납니다. 
> > * 어떤 변수를 썼는지(/VARIABLES), 회전 방식은 무엇인지(/ROTATION VARIMAX) 한눈에 확인할 수 있고, 나중에 똑같은 분석을 재현할 때 매우 유용합니다.
> 
> > [!LIST] 📝 실행 방법
> > 생성된 명령문 창에서 전체를 드래그한 뒤 상단의 **'실행(녹색 화살표)'** 버튼을 누르면 분석이 시작됩니다.
> 
> 자, 이제 프로그램이 계산을 마쳤을 겁니다. 다음 장(Group 5)으로 넘어가서 쏟아져 나온 표들을 어떻게 해석하고 족보로 만드는지 알아봅시다.

---

> [!NOTE] 32페이지 – 설명된 총분산: 요인 수 결정의 근거
> 
> 자, 분석 결과가 나왔습니다. 가장 먼저 확인해야 할 표는 **'설명된 총분산'**입니다. 우리가 투입한 19개 문항이 몇 개의 요인으로 압축되었는지 보여주죠.
> 
> > [!IMPORTANT] 💡 고유값(Eigenvalue) 기준 결과 (Yama)
> > * **추출된 요인 수:** 고유값 **1**을 기준으로 했을 때, 최종적으로 **3개**의 성분이 도출되었습니다.
> > * **분산 설명력:** 
> > 	* 성분 1: **25.963%** 
> >     * 성분 2: **18.167%** 
> >     * 성분 3: **16.907%** 
> > * **누적 설명력:** 이 3개의 요인이 전체 데이터 분산의 **약 61%**를 설명하고 있습니다. 
> 
> 19개의 문항을 단 3개로 줄였음에도 정보의 **61%**를 유지하고 있다는 건, 아주 효율적인 압축이 일어났다는 뜻입니다. 이제 이 요인들이 구체적으로 어떤 문항들로 구성되었는지 볼까요? 

> [!NOTE] 33페이지 – 성분행렬: 회전 전의 가공되지 않은 상태
> 
> 회전을 하기 전의 **'성분행렬'** 표입니다. 여기서는 각 문항이 어떤 성분에 얼마나 큰 비중(적재값)을 가지는지 보여줍니다.
> 
> > [!WARNING] ⚠️ 회전 전 해석의 난해함
> > * 표를 보면 **피로14, 16, 11** 등이 성분 1에 매우 높은 **요인 적재값(0.7 이상)**을 보이고 있습니다.
> > * 하지만 대부분의 문항이 **성분 1**에 몰려 있거나 여러 성분에 걸쳐 있어, 이 상태로는 요인의 이름을 정하기가 매우 어렵습니다.
> 
> 그래서 우리가 아까 **베리멕스(Varimax)** 회전을 설정한 겁니다. 축을 돌려서 문항들을 각 요인으로 명확히 흩뿌려보겠습니다.

> [!NOTE] 34~35페이지 – 회전된 성분행렬: 변수의 완벽한 재분류
> 
> 드디어 우리가 기다리던 **'회전된 성분행렬'** 결과입니다. 아까 옵션에서 **'크기순 정렬'**을 했기 때문에 해석이 아주 쉽습니다.
> 
> > [!IMPORTANT] 🔑 요인별 문항 구성 결과 (핵심 족보)
> > * **성분 1 (9개 항목):** **피로11~19** 문항들이 묶였습니다. 이 문항들의 내용을 보고 요인의 이름을 정하면 됩니다.
> > * **성분 2 (4개 항목):** **피로1~4** 문항들이 강력하게 결합되었습니다.
> > * **성분 3 (6개 항목):** **피로5~10** 문항들이 하나의 그룹이 되었습니다.
> 
> > [!TIP] ⭐️ 요인 명명(Naming)
> > 이렇게 묶인 문항들의 공통점을 찾아 **'신체적 피로'**, **'정신적 피로'** 등과 같은 이름을 붙여주는 것이 연구자의 다음 과제입니다.
> 
> 이제 이 3개의 요인을 개별 데이터로 저장해서 다음 통계 분석에 활용할 수 있게 되었습니다.

> [!NOTE] 36페이지 – 요인 점수의 생성과 데이터 확인
> 
> 마지막으로 데이터 보기 창을 확인해 봅시다. 우리가 명령했던 대로 새로운 변수들이 생성되어 있을 겁니다.
> 
> > [!LIST] 📝 생성된 요인 점수 변수
> > * **FAC1_1**: 첫 번째 요인에 대한 각 개인별 추정 점수입니다.
> > * **FAC2_1**: 두 번째 요인 점수입니다.
> > * **FAC3_1**: 세 번째 요인 점수입니다.
> 
> > [!INFO] 🧬 요인 점수의 활용
> > 이제 19개의 설문 문항 대신, 이 **3개의 요인 점수** 변수만 가지고 **회귀분석**이나 **분산분석**을 돌리면 됩니다. 데이터가 훨씬 깔끔해졌죠? 
> 
> 고생 많으셨습니다. 요인분석은 처음엔 복잡해 보이지만, **'압축'**과 **'회전'**이라는 두 키워드만 기억하면 여러분도 완벽하게 수행할 수 있습니다.


, ',
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니다.

# 요인 분석

> [!NOTE] 1~2페이지 – 강의 서두: 요인분석(Factor Analysis)의 문을 열며
> 
> 자, 여러분 반갑습니다. 오늘은 다변량 분석의 꽃이라 불리는 **요인분석(Factor Analysis)**에 대해 심도 있게 다뤄보겠습니다.  
> 
> > [!INFO] 🧬 요인분석의 핵심 정의
> > 요인분석은 수많은 변수 간의 **상관관계**를 이용하여, 공통된 특성을 가진 것끼리 묶어주는 기법입니다.  
> > 즉, 데이터의 **복잡성을 압축**하여 소수의 **핵심 요인(Factor)**으로 정보를 요약하는 **다변량 분석**의 핵심이라 할 수 있죠. 
> 
> 왜 우리가 이 복잡한 계산을 해야 할까요? 단순히 숫자를 줄이는 것 이상의 임상적 의미가 있기 때문입니다.

> [!NOTE] 3~4페이지 – 왜 '요인'으로 묶어야 하는가? (데이터의 압축)
> 
> 우리가 수십 개의 설문 문항을 분석한다고 가정해 봅시다. 이걸 하나하나 다루면 머리가 아프겠죠? 
> 
> > [!IMPORTANT] 💡 요인분석을 사용하는 두 가지 이유 (Yama)
> > * **변수 집단화:** 어떤 변수들이 서로 유기적으로 연결되어 있는지 **관찰**하고 묶기 위함입니다. 
> > * **차원 축소:** 유사한 변수를 하나의 요인으로 합쳐서, 나중에 **종속변수와의 관련성**을 더 명확하게 분석하기 위해 사용합니다. 
> 
> > [!LIST] 📝 분석의 흐름
> > * **Input:** 다양하고 해석하기 어려운 **상관성 있는 변수**들의 뭉치 
> > * **Process:** 요인분석을 통한 데이터 다이어트
> > * **Output:** 개념적으로 명확하고 **독립적인 소수 변수**로의 변환 
> 
> 
>
> 자, 그림을 보시면 아시겠지만, 흩어져 있던 변수들이 의미 있는 큰 덩어리로 합쳐지는 과정입니다.  이제 이 기법이 실제 연구에서 어떻게 적용되는지 봅시다.

> [!NOTE] 5~6페이지 – 탐색적 요인분석(EFA)과 분산의 구조
> 
> 실제 연구에서는 최종 분석 전에 변수들을 정리하기 위해 이 단계를 꼭 거칩니다.  특히 **숨겨진 공통요인**을 찾아내는 것이 주된 목적이죠. 
> 
> > [!IMPORTANT] 🔑 탐색적 요인분석(EFA)의 핵심 원리
> > * 측정 변수 간의 상관관계를 통해 **소수의 요인**을 도출합니다. 
> > * **총 분산의 구성:** $$총 분산 = 공통 요인 분산(잠재변수) + 고유 요인 분산(Error)$$ 
> 
> > [!INFO] 🧬 공통분(Communality)이란?
> > 특정 변수가 가진 전체 분산 중에서, 추출된 **공통 요인**에 의해 설명되는 양을 의미합니다.  
> > 이 값이 높을수록 해당 변수가 요인에 잘 반영되었다는 뜻이겠죠?
> 
> 하지만 요인을 추출할 때 주의해야 할 점이 있습니다. 너무 많이 나눠도, 너무 적게 나눠도 문제입니다.

> [!NOTE] 7~8페이지 – 요인 추출의 실패 사례와 메커니즘
> 
> 요인분석도 과유불급입니다. 연구자가 판단을 잘못하면 분석 결과가 산으로 갈 수 있어요. 
> 
> > [!WARNING] ⚠️ 분석 실패의 두 가지 유형
> > * **Overfactoring:** 실제로는 하나로 묶여야 할 요인을 **너무 잘게 쪼개어** 도출한 경우입니다. 
> > * **Underfactoring:** 더 상세히 나눌 수 있음에도 불구하고 **너무 적은 요인**만 뽑아낸 경우입니다. 
> 
> > [!IMPORTANT] 💡 이론 구조 개발의 핵심
> > 요인분석은 **고유 요인(Error)**을 제거하고 오직 **공통 요인**만 추출하려 노력합니다.  
> > 이를 위해 통계적으로는 **축소 상관행렬(Reduced correlation matrix)**이라는 도구를 사용하게 되죠. 
> 
> 자, 이제 요인분석이 무엇을 하려는 기법인지 감이 오시죠? 다음 장(Group 2)에서는 이 과정을 수학적으로 어떻게 표현하는지, 그리고 많은 분이 헷갈려 하는 주성분 분석과의 차이점을 명확히 짚어드리겠습니다.

---

> [!NOTE] 9~10페이지 – 요인분석의 수학적 뼈대: 직교 요인 모형 (Orthogonal Factor Model)
> 
> 자, 이제 요인분석이 내부적으로 어떤 계산 과정을 거치는지 그 뼈대를 살펴봅시다. 통계학적으로 요인분석은 변수들을 선형 결합으로 표현하는 **직교 요인 모형**을 따릅니다.
> 
> > [!INFO] 🧬 기본적인 선형 모형 (Matrix Form)
> > $$X = LF + \epsilon$$
> > * **$X$**: 관측된 $p$개의 변수 벡터입니다.
> > * **$L$**: **요인 부하량(Factor Loading)** 행렬로, 각 변수와 요인 간의 관계 강도를 나타냅니다.
> > * **$F$**: 우리가 찾고자 하는 잠재적인 **공통 요인**입니다.
> > * **$\epsilon$**: 각 변수만이 가진 **고유 요인(Error)**입니다.
> 
> 이 수식을 통해 우리는 개별 변수의 전체 분산을 두 가지 성분으로 쪼갤 수 있습니다.
> 
> > [!IMPORTANT] 💡 분산의 구성: 커뮤날리티 vs 특수 분산
> > $$var(x_i) = h_i^2 (Communality) + \Psi_i (Specific Variance)$$ 
> > * **커뮤날리티($h_i^2$):** $m$개의 공통 요인에 의해 설명되는 부분입니다.
> > * **특수 분산($\Psi_i$):** 공통 요인으로 설명되지 않는 그 변수만의 고유한 변동입니다.
> 
> 앞서 배운 '공통 요인'을 추출한다는 것은 결국 이 **커뮤날리티**를 극대화하는 과정이라고 이해하시면 됩니다.

> [!NOTE] 11페이지 – 요인 추출의 방법론: 주축분해법 vs 최대우도법
> 
> 수학적 모델을 세웠으니 이제 실제 값을 추정해야겠죠? SPSS에서 주로 사용하는 두 가지 핵심 방법을 비교해 봅시다.
> 
> > [!LIST] 📝 주요 추정 방법 비교
> > * **주축분해법(Principal Axis Factoring):** 
> > 	 - **SPSS** 사용 시 가장 권장되는 방법입니다.
> >     - **SMC(Squared Multiple Correlation)**를 초기 커뮤날리티로 사용하여 반복 계산을 통해 최적값을 찾습니다.
> > * **최대우도법(Maximum Likelihood, ML):** 
> > 	- 표본의 상관행렬과 모형의 상관행렬이 최대한 유사해지도록 추정합니다.
> > 	- **정상성 가정**에 민감하고 **많은 표본**이 필요하지만, 적합도 검증($\chi^2$)이 가능하다는 장점이 있습니다.
> 
> 어떤 방법을 선택하느냐에 따라 결과가 달라질 수 있으니 데이터의 특성을 먼저 파악해야 합니다.

> [!NOTE] 12페이지 – SPSS의 함정: 주성분 분석(PCA)과 요인분석의 차이
> 
> 여기서 아주 중요한 주의사항이 하나 나옵니다. SPSS의 기본 설정(Default)에 속지 마세요.
> 
> > [!WARNING] ⚠️ 주성분 분석(PCA)을 지양해야 하는 이유 (Yama)
> > * **오차 무시:** PCA는 데이터에 **에러(Error)가 없다**고 가정합니다. 
> > * **분산 설명 최대화:** 단순히 많은 변수를 소수로 축소하는 데 초점을 맞춥니다.
> > * **행동과학에서의 한계:** 사람의 심리나 행동 데이터는 오차를 무시할 수 없으므로, 엄밀한 의미의 **요인분석**에서는 PCA 사용을 지양해야 합니다.
> 
> 교수님들이 흔히 **"PCA는 불필요한 분석이다"**라고 말씀하시는 이유가 바로 이 **오차 항의 부재** 때문입니다.

> [!NOTE] 13~14페이지 – 주성분 방법의 논리: 분산 설명력의 극대화
> 
> 그럼에도 불구하고 PCA의 논리를 이해하는 것은 기초 체력을 기르는 데 도움이 됩니다.
> 
> > [!INFO] 🧬 주성분(PC) 도출 원리
> > * **총 분산:** 모든 변수의 표본분산의 합입니다.
> > * **제1주성분 [PC(1)]:** 자료의 총 분산을 **가장 많이 설명**할 수 있도록 변수들을 가중 결합한 것입니다.
> > * **제2주성분 [PC(2)]:** 첫 번째 주성분이 설명하지 못한 나머지 분산을 최대한 설명하며, **PC(1)과는 상관성이 없는(직교하는)** 결합입니다.
> 
> > [!IMPORTANT] 💡 가중치 결정의 목적
> > 가능한 한 **적은 수의 요인**으로 전체 데이터의 불확실성(Uncertainty)을 가장 잘 설명하는 것이 핵심입니다.
> 
> 자, 이제 수학적 기초와 분석 도구들의 특징을 정리했습니다. 이제 추출된 요인을 어떻게 더 명확하게 해석할 것인지, **요인 회전**과 **확인적 요인분석**의 세계로 넘어가 봅시다 (Group 3).

---

> [!NOTE] 15~16페이지 – 요인 회전(Rotation): 해석의 마법
> 
> 요인을 추출한 직후의 결과는 보통 해석하기가 매우 난해합니다. 이때 필요한 것이 바로 **요인 회전**입니다.
> 
> > [!INFO] 🧬 단순구조(Simple Structure)
> > 회전의 목적은 수학적으로는 동일한 모델을 유지하면서, 각 변수가 특정 요인에만 강하게 걸리도록 **단순구조**를 만들어 **해석을 용이**하게 하는 데 있습니다.
> 
> > [!IMPORTANT] 💡 회전 방법의 선택 (Yama)
> > 1. **직각회전(Orthogonal):** 요인 간의 **상관관계가 0**이라고 가정합니다. (예: **Varimax**)
> >    - 단, 사회과학이나 의학 데이터에서 요인 간 상관이 전혀 없다는 것은 **논리적으로 무리(Logic nonsense)**가 있을 수 있습니다.
> > 2. **사각회전(Oblique):** 요인 간의 **상관을 인정**합니다. (예: **Promax**, **Direct Oblimin**)
> >    - 현실적인 데이터 분석에서는 사각회전이 훨씬 더 권장됩니다.
> 
> > [!LIST] 📝 행렬의 종류
> > * **패턴행렬(Pattern Matrix):** 요인이 변수에 미치는 영향력(회귀계수)을 나타내며, 사각회전 시 주로 해석합니다.
> > * **구조행렬(Structure Matrix):** 요인과 변수 사이의 단순 상관계수입니다.
> 
> 자, 이 회전된 축을 통해 비로소 우리는 요인에 '이름'을 붙여줄 수 있게 됩니다.

> [!NOTE] 17페이지 – 분석 도구별 권장 절차
> 
> 여러분이 어떤 프로그램을 쓰느냐에 따라 권장되는 분석 루틴이 조금 다릅니다. 이 루틴을 외워두면 실무에서 큰 도움이 됩니다.
> 
> > [!TIP] ⭐️ 프로그램별 Standard (족보)
> > * **SPSS 사용 시:** **주축분해법** 추출 → 스크리 도표/평행분석으로 요인 수 결정 → **사각회전** 적용.
> > * **구조방정식(SEM) 모델링 시:** **최대우도법(ML)** 추출 → 적합도 지수 확인 → **사각회전** 적용.
> 
> 이제 우리가 지금까지 한 '탐색'을 넘어, 이미 알고 있는 이론을 '확인'하는 단계로 가봅시다.

> [!NOTE] 18~19페이지 – 확인적 요인분석(CFA)의 논리
> 
> 탐색적 요인분석(EFA)이 "뭐가 나올지 모르는 상태에서 묶어보는 것"이라면, **확인적 요인분석(CFA)**은 "내가 세운 가설이 맞는지 검증하는 것"입니다.
> 
> > [!IMPORTANT] 🔑 CFA의 핵심 차이점
> > * **제약(Constraint):** 특정 변수는 특정 요인에만 영향을 받는다고 미리 식을 고정합니다.
> > * **오차 상관:** 이론적 근거가 있다면 문항 간 **오차 공분산**을 허용할 수 있습니다.
> > * **주의사항 (Critical):** **동일한 자료**에 대해 EFA를 하고 그 결과로 다시 CFA를 수행하는 것은 통계적으로 **지양**해야 합니다.
> 
> > [!INFO] 🧬 식별을 위한 고정(Scaling)
> > 모델이 돌아가려면 기준이 필요합니다. 보통 **요인계수가 가장 높은 변수**의 계수를 **1**로 고정(Reference variable)하거나, 잠재변수의 분산을 1로 고정합니다.

> [!NOTE] 20페이지 – 모델이 얼마나 잘 맞는가? 적합도 지수(Fit Indices)
> 
> CFA를 돌리고 나면 반드시 이 모델이 실제 데이터를 얼마나 잘 설명하는지 수치로 보여줘야 합니다.
> 
> > [!IMPORTANT] 💡 권장 적합도 판단 기준 (Hu & Bentler, 1999)
> > * **TLI / CFI:** **0.90 이상**이면 괜찮고, **0.95 이상**이면 매우 좋은 모델입니다.
> > * **RMSEA:** **0.05 미만**이면 Close fit(최상), **0.08 미만**이면 양호(Reasonable)한 것으로 봅니다. **0.10**을 넘어가면 수용 불가능합니다.
> > * **SRMR:** **0.08 미만**을 기준으로 삼습니다.
> 
> $\chi^2$(카이제곱) 검정은 너무 엄격해서 표본이 조금만 커도 기각되기 쉽기 때문에, 보통 위 지수들을 종합적으로 보고 모델의 우수성을 판단합니다.

> [!NOTE] 21페이지 – 새로운 변수의 탄생: 요인 점수(Factor Score)
> 
> 자, 요인분석의 마지막 단계입니다. 우리는 수많은 문항을 몇 개의 요인으로 묶었습니다. 이제 이 요인들을 **하나의 숫자**로 만들어서 다음 분석에 써먹어야겠죠?
> 
> > [!INFO] 🧬 요인 점수란?
> > 공통 요인의 추정값으로, 추출된 요인을 새로운 **독립변수**나 **종속변수**로 활용할 수 있게 해주는 값입니다.
> 
> > [!LIST] 📝 점수 산출 방법
> > 1. **가중 최소제곱법 (Bartlett):** 측정 오차를 고려한 가중치를 부여합니다.
> > 2. **회귀 방법 (Regression):** 가장 보편적으로 사용되는 방식입니다.
> 
> 이제 이론은 완벽하게 정리되었습니다. 백문이 불여일견이죠. 다음 장(Group 4)부터는 실제 **피로 척도 데이터**를 가지고 SPSS를 직접 돌려보겠습니다.

---

> [!NOTE] 22~23페이지 – SPSS 실습 예제: 다차원 피로 척도(MFS) 분석
> 
> 자, 이론은 여기까지 하고 이제 직접 데이터를 만져봅시다. 오늘 사용할 데이터는 **피로.sav** 파일입니다. 
> 
> > [!quote] 🩺 실습 케이스: 다차원 피로 척도(MFS)
> > * **목적**: 주관적 피로 증상을 측정하기 위해 개발된 **19문항**의 척도가 과연 몇 개의 요인으로 구분되는지 파악하는 것입니다.
> > * **활용**: 추출된 요인을 새로운 변수로 만들어 추후 분석에 사용하고자 합니다.
> 
> 먼저 메뉴부터 찾아 들어가야겠죠? **분석(A) > 차원 감소 > 요인분석(F)** 순서로 클릭하세요.
> 
> 

> [!NOTE] 24~25페이지 – 변수 선택 및 투입
> 
> 창이 뜨면 왼쪽 변수 목록에서 우리가 분석할 문항들을 골라야 합니다.
> 
> > [!LIST] 📝 변수 선택 단계
> > 1. 성별, 연령 같은 인구학적 변수는 일단 제외합니다.
> > 2. 분석하고자 하는 설문 문항인 **피로1부터 피로19**까지를 모두 선택합니다.
> > 3. 오른쪽의 **변수(V)** 박스로 모든 문항을 이동시킵니다.
> 
> 
> 
> 문항을 다 옮겼다면, 이제 우측의 버튼들을 하나씩 눌러 세부 설정을 해줄 차례입니다.

> [!NOTE] 26~27페이지 – 요인 추출(Extraction)과 회전(Rotation) 설정
> 
> 여기가 가장 중요합니다. 제가 이론 강의 때 강조했던 내용들을 적용하는 단계예요.
> 
> > [!IMPORTANT] 💡 요인 추출(Extraction) 설정
> > * **방법**: 기본값은 **주성분(PCA)** 분석으로 되어 있습니다. (학술적 목적에 따라 주축분해법 등으로 변경 가능합니다.)
> > * **추출 기준**: 보통 **고유값(Eigenvalue) 1**을 기준으로 삼지만, 연구자가 특정 요인 수를 직접 지정할 수도 있습니다.
> > * **출력**: 흐름을 파악하기 위해 **스크리 도표(Scree Plot)**를 체크하는 습관을 들이세요.
> 
> > [!IMPORTANT] 💡 요인 회전(Rotation) 설정
> > * **방법**: 여기서는 직각회전 방식인 **베리맥스(Varimax)**를 선택하겠습니다. 
> > * **목적**: 요인 적재량을 재배치하여 어떤 문항이 어떤 요인에 속하는지 명확히 보기 위함입니다.
> 
> 

> [!NOTE] 28~29페이지 – 요인 점수 저장 및 출력 옵션
> 
> 분석 결과만 보고 끝낼 게 아니라, 이 요인들을 나중에 회귀분석 등에 써먹으려면 점수로 저장해야 합니다.
> 
> > [!LIST] 📝 추가 옵션 설정
> > * **요인 점수**: **'변수로 저장(S)'**을 체크하고 방법은 **'회귀분석'**을 선택합니다. 이렇게 하면 데이터 파일 끝에 새로운 변수가 생깁니다.
> > * **옵션(Options)**: 결과표를 보기 좋게 만들기 위해 **'크기순 정렬'**을 체크하세요. 적재량이 큰 순서대로 문항이 나열되어 훨씬 읽기 편해집니다.
> 
> 

> [!NOTE] 30~31페이지 – 명령문(Syntax) 생성 및 실행
> 
> 확인 버튼을 바로 누르지 말고, **'붙여넣기'**를 눌러보세요. 고수들은 항상 이렇게 합니다.
> 
> > [!TIP] ⭐️ 명령문(Syntax) 활용의 장점 (Yama)
> > * **FACTOR** 명령어로 시작하는 구문이 나타납니다. 
> > * 어떤 변수를 썼는지(/VARIABLES), 회전 방식은 무엇인지(/ROTATION VARIMAX) 한눈에 확인할 수 있고, 나중에 똑같은 분석을 재현할 때 매우 유용합니다.
> 
> > [!LIST] 📝 실행 방법
> > 생성된 명령문 창에서 전체를 드래그한 뒤 상단의 **'실행(녹색 화살표)'** 버튼을 누르면 분석이 시작됩니다.
> 
> 자, 이제 프로그램이 계산을 마쳤을 겁니다. 다음 장(Group 5)으로 넘어가서 쏟아져 나온 표들을 어떻게 해석하고 족보로 만드는지 알아봅시다.

---

> [!NOTE] 32페이지 – 설명된 총분산: 요인 수 결정의 근거
> 
> 자, 분석 결과가 나왔습니다. 가장 먼저 확인해야 할 표는 **'설명된 총분산'**입니다. 우리가 투입한 19개 문항이 몇 개의 요인으로 압축되었는지 보여주죠.
> 
> > [!IMPORTANT] 💡 고유값(Eigenvalue) 기준 결과 (Yama)
> > * **추출된 요인 수:** 고유값 **1**을 기준으로 했을 때, 최종적으로 **3개**의 성분이 도출되었습니다.
> > * **분산 설명력:** 
> > 	* 성분 1: **25.963%** 
> >     * 성분 2: **18.167%** 
> >     * 성분 3: **16.907%** 
> > * **누적 설명력:** 이 3개의 요인이 전체 데이터 분산의 **약 61%**를 설명하고 있습니다. 
> 
> 19개의 문항을 단 3개로 줄였음에도 정보의 **61%**를 유지하고 있다는 건, 아주 효율적인 압축이 일어났다는 뜻입니다. 이제 이 요인들이 구체적으로 어떤 문항들로 구성되었는지 볼까요? 

> [!NOTE] 33페이지 – 성분행렬: 회전 전의 가공되지 않은 상태
> 
> 회전을 하기 전의 **'성분행렬'** 표입니다. 여기서는 각 문항이 어떤 성분에 얼마나 큰 비중(적재값)을 가지는지 보여줍니다.
> 
> > [!WARNING] ⚠️ 회전 전 해석의 난해함
> > * 표를 보면 **피로14, 16, 11** 등이 성분 1에 매우 높은 **요인 적재값(0.7 이상)**을 보이고 있습니다.
> > * 하지만 대부분의 문항이 **성분 1**에 몰려 있거나 여러 성분에 걸쳐 있어, 이 상태로는 요인의 이름을 정하기가 매우 어렵습니다.
> 
> 그래서 우리가 아까 **베리멕스(Varimax)** 회전을 설정한 겁니다. 축을 돌려서 문항들을 각 요인으로 명확히 흩뿌려보겠습니다.

> [!NOTE] 34~35페이지 – 회전된 성분행렬: 변수의 완벽한 재분류
> 
> 드디어 우리가 기다리던 **'회전된 성분행렬'** 결과입니다. 아까 옵션에서 **'크기순 정렬'**을 했기 때문에 해석이 아주 쉽습니다.
> 
> > [!IMPORTANT] 🔑 요인별 문항 구성 결과 (핵심 족보)
> > * **성분 1 (9개 항목):** **피로11~19** 문항들이 묶였습니다. 이 문항들의 내용을 보고 요인의 이름을 정하면 됩니다.
> > * **성분 2 (4개 항목):** **피로1~4** 문항들이 강력하게 결합되었습니다.
> > * **성분 3 (6개 항목):** **피로5~10** 문항들이 하나의 그룹이 되었습니다.
> 
> > [!TIP] ⭐️ 요인 명명(Naming)
> > 이렇게 묶인 문항들의 공통점을 찾아 **'신체적 피로'**, **'정신적 피로'** 등과 같은 이름을 붙여주는 것이 연구자의 다음 과제입니다.
> 
> 이제 이 3개의 요인을 개별 데이터로 저장해서 다음 통계 분석에 활용할 수 있게 되었습니다.

> [!NOTE] 36페이지 – 요인 점수의 생성과 데이터 확인
> 
> 마지막으로 데이터 보기 창을 확인해 봅시다. 우리가 명령했던 대로 새로운 변수들이 생성되어 있을 겁니다.
> 
> > [!LIST] 📝 생성된 요인 점수 변수
> > * **FAC1_1**: 첫 번째 요인에 대한 각 개인별 추정 점수입니다.
> > * **FAC2_1**: 두 번째 요인 점수입니다.
> > * **FAC3_1**: 세 번째 요인 점수입니다.
> 
> > [!INFO] 🧬 요인 점수의 활용
> > 이제 19개의 설문 문항 대신, 이 **3개의 요인 점수** 변수만 가지고 **회귀분석**이나 **분산분석**을 돌리면 됩니다. 데이터가 훨씬 깔끔해졌죠? 
> 
> 고생 많으셨습니다. 요인분석은 처음엔 복잡해 보이지만, **'압축'**과 **'회전'**이라는 두 키워드만 기억하면 여러분도 완벽하게 수행할 수 있습니다.


], ['\\(', '\\)'\|',
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니다.

# 요인 분석

> [!NOTE] 1~2페이지 – 강의 서두: 요인분석(Factor Analysis)의 문을 열며
> 
> 자, 여러분 반갑습니다. 오늘은 다변량 분석의 꽃이라 불리는 **요인분석(Factor Analysis)**에 대해 심도 있게 다뤄보겠습니다.  
> 
> > [!INFO] 🧬 요인분석의 핵심 정의
> > 요인분석은 수많은 변수 간의 **상관관계**를 이용하여, 공통된 특성을 가진 것끼리 묶어주는 기법입니다.  
> > 즉, 데이터의 **복잡성을 압축**하여 소수의 **핵심 요인(Factor)**으로 정보를 요약하는 **다변량 분석**의 핵심이라 할 수 있죠. 
> 
> 왜 우리가 이 복잡한 계산을 해야 할까요? 단순히 숫자를 줄이는 것 이상의 임상적 의미가 있기 때문입니다.

> [!NOTE] 3~4페이지 – 왜 '요인'으로 묶어야 하는가? (데이터의 압축)
> 
> 우리가 수십 개의 설문 문항을 분석한다고 가정해 봅시다. 이걸 하나하나 다루면 머리가 아프겠죠? 
> 
> > [!IMPORTANT] 💡 요인분석을 사용하는 두 가지 이유 (Yama)
> > * **변수 집단화:** 어떤 변수들이 서로 유기적으로 연결되어 있는지 **관찰**하고 묶기 위함입니다. 
> > * **차원 축소:** 유사한 변수를 하나의 요인으로 합쳐서, 나중에 **종속변수와의 관련성**을 더 명확하게 분석하기 위해 사용합니다. 
> 
> > [!LIST] 📝 분석의 흐름
> > * **Input:** 다양하고 해석하기 어려운 **상관성 있는 변수**들의 뭉치 
> > * **Process:** 요인분석을 통한 데이터 다이어트
> > * **Output:** 개념적으로 명확하고 **독립적인 소수 변수**로의 변환 
> 
> 
>
> 자, 그림을 보시면 아시겠지만, 흩어져 있던 변수들이 의미 있는 큰 덩어리로 합쳐지는 과정입니다.  이제 이 기법이 실제 연구에서 어떻게 적용되는지 봅시다.

> [!NOTE] 5~6페이지 – 탐색적 요인분석(EFA)과 분산의 구조
> 
> 실제 연구에서는 최종 분석 전에 변수들을 정리하기 위해 이 단계를 꼭 거칩니다.  특히 **숨겨진 공통요인**을 찾아내는 것이 주된 목적이죠. 
> 
> > [!IMPORTANT] 🔑 탐색적 요인분석(EFA)의 핵심 원리
> > * 측정 변수 간의 상관관계를 통해 **소수의 요인**을 도출합니다. 
> > * **총 분산의 구성:** $$총 분산 = 공통 요인 분산(잠재변수) + 고유 요인 분산(Error)$$ 
> 
> > [!INFO] 🧬 공통분(Communality)이란?
> > 특정 변수가 가진 전체 분산 중에서, 추출된 **공통 요인**에 의해 설명되는 양을 의미합니다.  
> > 이 값이 높을수록 해당 변수가 요인에 잘 반영되었다는 뜻이겠죠?
> 
> 하지만 요인을 추출할 때 주의해야 할 점이 있습니다. 너무 많이 나눠도, 너무 적게 나눠도 문제입니다.

> [!NOTE] 7~8페이지 – 요인 추출의 실패 사례와 메커니즘
> 
> 요인분석도 과유불급입니다. 연구자가 판단을 잘못하면 분석 결과가 산으로 갈 수 있어요. 
> 
> > [!WARNING] ⚠️ 분석 실패의 두 가지 유형
> > * **Overfactoring:** 실제로는 하나로 묶여야 할 요인을 **너무 잘게 쪼개어** 도출한 경우입니다. 
> > * **Underfactoring:** 더 상세히 나눌 수 있음에도 불구하고 **너무 적은 요인**만 뽑아낸 경우입니다. 
> 
> > [!IMPORTANT] 💡 이론 구조 개발의 핵심
> > 요인분석은 **고유 요인(Error)**을 제거하고 오직 **공통 요인**만 추출하려 노력합니다.  
> > 이를 위해 통계적으로는 **축소 상관행렬(Reduced correlation matrix)**이라는 도구를 사용하게 되죠. 
> 
> 자, 이제 요인분석이 무엇을 하려는 기법인지 감이 오시죠? 다음 장(Group 2)에서는 이 과정을 수학적으로 어떻게 표현하는지, 그리고 많은 분이 헷갈려 하는 주성분 분석과의 차이점을 명확히 짚어드리겠습니다.

---

> [!NOTE] 9~10페이지 – 요인분석의 수학적 뼈대: 직교 요인 모형 (Orthogonal Factor Model)
> 
> 자, 이제 요인분석이 내부적으로 어떤 계산 과정을 거치는지 그 뼈대를 살펴봅시다. 통계학적으로 요인분석은 변수들을 선형 결합으로 표현하는 **직교 요인 모형**을 따릅니다.
> 
> > [!INFO] 🧬 기본적인 선형 모형 (Matrix Form)
> > $$X = LF + \epsilon$$
> > * **$X$**: 관측된 $p$개의 변수 벡터입니다.
> > * **$L$**: **요인 부하량(Factor Loading)** 행렬로, 각 변수와 요인 간의 관계 강도를 나타냅니다.
> > * **$F$**: 우리가 찾고자 하는 잠재적인 **공통 요인**입니다.
> > * **$\epsilon$**: 각 변수만이 가진 **고유 요인(Error)**입니다.
> 
> 이 수식을 통해 우리는 개별 변수의 전체 분산을 두 가지 성분으로 쪼갤 수 있습니다.
> 
> > [!IMPORTANT] 💡 분산의 구성: 커뮤날리티 vs 특수 분산
> > $$var(x_i) = h_i^2 (Communality) + \Psi_i (Specific Variance)$$ 
> > * **커뮤날리티($h_i^2$):** $m$개의 공통 요인에 의해 설명되는 부분입니다.
> > * **특수 분산($\Psi_i$):** 공통 요인으로 설명되지 않는 그 변수만의 고유한 변동입니다.
> 
> 앞서 배운 '공통 요인'을 추출한다는 것은 결국 이 **커뮤날리티**를 극대화하는 과정이라고 이해하시면 됩니다.

> [!NOTE] 11페이지 – 요인 추출의 방법론: 주축분해법 vs 최대우도법
> 
> 수학적 모델을 세웠으니 이제 실제 값을 추정해야겠죠? SPSS에서 주로 사용하는 두 가지 핵심 방법을 비교해 봅시다.
> 
> > [!LIST] 📝 주요 추정 방법 비교
> > * **주축분해법(Principal Axis Factoring):** 
> > 	 - **SPSS** 사용 시 가장 권장되는 방법입니다.
> >     - **SMC(Squared Multiple Correlation)**를 초기 커뮤날리티로 사용하여 반복 계산을 통해 최적값을 찾습니다.
> > * **최대우도법(Maximum Likelihood, ML):** 
> > 	- 표본의 상관행렬과 모형의 상관행렬이 최대한 유사해지도록 추정합니다.
> > 	- **정상성 가정**에 민감하고 **많은 표본**이 필요하지만, 적합도 검증($\chi^2$)이 가능하다는 장점이 있습니다.
> 
> 어떤 방법을 선택하느냐에 따라 결과가 달라질 수 있으니 데이터의 특성을 먼저 파악해야 합니다.

> [!NOTE] 12페이지 – SPSS의 함정: 주성분 분석(PCA)과 요인분석의 차이
> 
> 여기서 아주 중요한 주의사항이 하나 나옵니다. SPSS의 기본 설정(Default)에 속지 마세요.
> 
> > [!WARNING] ⚠️ 주성분 분석(PCA)을 지양해야 하는 이유 (Yama)
> > * **오차 무시:** PCA는 데이터에 **에러(Error)가 없다**고 가정합니다. 
> > * **분산 설명 최대화:** 단순히 많은 변수를 소수로 축소하는 데 초점을 맞춥니다.
> > * **행동과학에서의 한계:** 사람의 심리나 행동 데이터는 오차를 무시할 수 없으므로, 엄밀한 의미의 **요인분석**에서는 PCA 사용을 지양해야 합니다.
> 
> 교수님들이 흔히 **"PCA는 불필요한 분석이다"**라고 말씀하시는 이유가 바로 이 **오차 항의 부재** 때문입니다.

> [!NOTE] 13~14페이지 – 주성분 방법의 논리: 분산 설명력의 극대화
> 
> 그럼에도 불구하고 PCA의 논리를 이해하는 것은 기초 체력을 기르는 데 도움이 됩니다.
> 
> > [!INFO] 🧬 주성분(PC) 도출 원리
> > * **총 분산:** 모든 변수의 표본분산의 합입니다.
> > * **제1주성분 [PC(1)]:** 자료의 총 분산을 **가장 많이 설명**할 수 있도록 변수들을 가중 결합한 것입니다.
> > * **제2주성분 [PC(2)]:** 첫 번째 주성분이 설명하지 못한 나머지 분산을 최대한 설명하며, **PC(1)과는 상관성이 없는(직교하는)** 결합입니다.
> 
> > [!IMPORTANT] 💡 가중치 결정의 목적
> > 가능한 한 **적은 수의 요인**으로 전체 데이터의 불확실성(Uncertainty)을 가장 잘 설명하는 것이 핵심입니다.
> 
> 자, 이제 수학적 기초와 분석 도구들의 특징을 정리했습니다. 이제 추출된 요인을 어떻게 더 명확하게 해석할 것인지, **요인 회전**과 **확인적 요인분석**의 세계로 넘어가 봅시다 (Group 3).

---

> [!NOTE] 15~16페이지 – 요인 회전(Rotation): 해석의 마법
> 
> 요인을 추출한 직후의 결과는 보통 해석하기가 매우 난해합니다. 이때 필요한 것이 바로 **요인 회전**입니다.
> 
> > [!INFO] 🧬 단순구조(Simple Structure)
> > 회전의 목적은 수학적으로는 동일한 모델을 유지하면서, 각 변수가 특정 요인에만 강하게 걸리도록 **단순구조**를 만들어 **해석을 용이**하게 하는 데 있습니다.
> 
> > [!IMPORTANT] 💡 회전 방법의 선택 (Yama)
> > 1. **직각회전(Orthogonal):** 요인 간의 **상관관계가 0**이라고 가정합니다. (예: **Varimax**)
> >    - 단, 사회과학이나 의학 데이터에서 요인 간 상관이 전혀 없다는 것은 **논리적으로 무리(Logic nonsense)**가 있을 수 있습니다.
> > 2. **사각회전(Oblique):** 요인 간의 **상관을 인정**합니다. (예: **Promax**, **Direct Oblimin**)
> >    - 현실적인 데이터 분석에서는 사각회전이 훨씬 더 권장됩니다.
> 
> > [!LIST] 📝 행렬의 종류
> > * **패턴행렬(Pattern Matrix):** 요인이 변수에 미치는 영향력(회귀계수)을 나타내며, 사각회전 시 주로 해석합니다.
> > * **구조행렬(Structure Matrix):** 요인과 변수 사이의 단순 상관계수입니다.
> 
> 자, 이 회전된 축을 통해 비로소 우리는 요인에 '이름'을 붙여줄 수 있게 됩니다.

> [!NOTE] 17페이지 – 분석 도구별 권장 절차
> 
> 여러분이 어떤 프로그램을 쓰느냐에 따라 권장되는 분석 루틴이 조금 다릅니다. 이 루틴을 외워두면 실무에서 큰 도움이 됩니다.
> 
> > [!TIP] ⭐️ 프로그램별 Standard (족보)
> > * **SPSS 사용 시:** **주축분해법** 추출 → 스크리 도표/평행분석으로 요인 수 결정 → **사각회전** 적용.
> > * **구조방정식(SEM) 모델링 시:** **최대우도법(ML)** 추출 → 적합도 지수 확인 → **사각회전** 적용.
> 
> 이제 우리가 지금까지 한 '탐색'을 넘어, 이미 알고 있는 이론을 '확인'하는 단계로 가봅시다.

> [!NOTE] 18~19페이지 – 확인적 요인분석(CFA)의 논리
> 
> 탐색적 요인분석(EFA)이 "뭐가 나올지 모르는 상태에서 묶어보는 것"이라면, **확인적 요인분석(CFA)**은 "내가 세운 가설이 맞는지 검증하는 것"입니다.
> 
> > [!IMPORTANT] 🔑 CFA의 핵심 차이점
> > * **제약(Constraint):** 특정 변수는 특정 요인에만 영향을 받는다고 미리 식을 고정합니다.
> > * **오차 상관:** 이론적 근거가 있다면 문항 간 **오차 공분산**을 허용할 수 있습니다.
> > * **주의사항 (Critical):** **동일한 자료**에 대해 EFA를 하고 그 결과로 다시 CFA를 수행하는 것은 통계적으로 **지양**해야 합니다.
> 
> > [!INFO] 🧬 식별을 위한 고정(Scaling)
> > 모델이 돌아가려면 기준이 필요합니다. 보통 **요인계수가 가장 높은 변수**의 계수를 **1**로 고정(Reference variable)하거나, 잠재변수의 분산을 1로 고정합니다.

> [!NOTE] 20페이지 – 모델이 얼마나 잘 맞는가? 적합도 지수(Fit Indices)
> 
> CFA를 돌리고 나면 반드시 이 모델이 실제 데이터를 얼마나 잘 설명하는지 수치로 보여줘야 합니다.
> 
> > [!IMPORTANT] 💡 권장 적합도 판단 기준 (Hu & Bentler, 1999)
> > * **TLI / CFI:** **0.90 이상**이면 괜찮고, **0.95 이상**이면 매우 좋은 모델입니다.
> > * **RMSEA:** **0.05 미만**이면 Close fit(최상), **0.08 미만**이면 양호(Reasonable)한 것으로 봅니다. **0.10**을 넘어가면 수용 불가능합니다.
> > * **SRMR:** **0.08 미만**을 기준으로 삼습니다.
> 
> $\chi^2$(카이제곱) 검정은 너무 엄격해서 표본이 조금만 커도 기각되기 쉽기 때문에, 보통 위 지수들을 종합적으로 보고 모델의 우수성을 판단합니다.

> [!NOTE] 21페이지 – 새로운 변수의 탄생: 요인 점수(Factor Score)
> 
> 자, 요인분석의 마지막 단계입니다. 우리는 수많은 문항을 몇 개의 요인으로 묶었습니다. 이제 이 요인들을 **하나의 숫자**로 만들어서 다음 분석에 써먹어야겠죠?
> 
> > [!INFO] 🧬 요인 점수란?
> > 공통 요인의 추정값으로, 추출된 요인을 새로운 **독립변수**나 **종속변수**로 활용할 수 있게 해주는 값입니다.
> 
> > [!LIST] 📝 점수 산출 방법
> > 1. **가중 최소제곱법 (Bartlett):** 측정 오차를 고려한 가중치를 부여합니다.
> > 2. **회귀 방법 (Regression):** 가장 보편적으로 사용되는 방식입니다.
> 
> 이제 이론은 완벽하게 정리되었습니다. 백문이 불여일견이죠. 다음 장(Group 4)부터는 실제 **피로 척도 데이터**를 가지고 SPSS를 직접 돌려보겠습니다.

---

> [!NOTE] 22~23페이지 – SPSS 실습 예제: 다차원 피로 척도(MFS) 분석
> 
> 자, 이론은 여기까지 하고 이제 직접 데이터를 만져봅시다. 오늘 사용할 데이터는 **피로.sav** 파일입니다. 
> 
> > [!quote] 🩺 실습 케이스: 다차원 피로 척도(MFS)
> > * **목적**: 주관적 피로 증상을 측정하기 위해 개발된 **19문항**의 척도가 과연 몇 개의 요인으로 구분되는지 파악하는 것입니다.
> > * **활용**: 추출된 요인을 새로운 변수로 만들어 추후 분석에 사용하고자 합니다.
> 
> 먼저 메뉴부터 찾아 들어가야겠죠? **분석(A) > 차원 감소 > 요인분석(F)** 순서로 클릭하세요.
> 
> 

> [!NOTE] 24~25페이지 – 변수 선택 및 투입
> 
> 창이 뜨면 왼쪽 변수 목록에서 우리가 분석할 문항들을 골라야 합니다.
> 
> > [!LIST] 📝 변수 선택 단계
> > 1. 성별, 연령 같은 인구학적 변수는 일단 제외합니다.
> > 2. 분석하고자 하는 설문 문항인 **피로1부터 피로19**까지를 모두 선택합니다.
> > 3. 오른쪽의 **변수(V)** 박스로 모든 문항을 이동시킵니다.
> 
> 
> 
> 문항을 다 옮겼다면, 이제 우측의 버튼들을 하나씩 눌러 세부 설정을 해줄 차례입니다.

> [!NOTE] 26~27페이지 – 요인 추출(Extraction)과 회전(Rotation) 설정
> 
> 여기가 가장 중요합니다. 제가 이론 강의 때 강조했던 내용들을 적용하는 단계예요.
> 
> > [!IMPORTANT] 💡 요인 추출(Extraction) 설정
> > * **방법**: 기본값은 **주성분(PCA)** 분석으로 되어 있습니다. (학술적 목적에 따라 주축분해법 등으로 변경 가능합니다.)
> > * **추출 기준**: 보통 **고유값(Eigenvalue) 1**을 기준으로 삼지만, 연구자가 특정 요인 수를 직접 지정할 수도 있습니다.
> > * **출력**: 흐름을 파악하기 위해 **스크리 도표(Scree Plot)**를 체크하는 습관을 들이세요.
> 
> > [!IMPORTANT] 💡 요인 회전(Rotation) 설정
> > * **방법**: 여기서는 직각회전 방식인 **베리맥스(Varimax)**를 선택하겠습니다. 
> > * **목적**: 요인 적재량을 재배치하여 어떤 문항이 어떤 요인에 속하는지 명확히 보기 위함입니다.
> 
> 

> [!NOTE] 28~29페이지 – 요인 점수 저장 및 출력 옵션
> 
> 분석 결과만 보고 끝낼 게 아니라, 이 요인들을 나중에 회귀분석 등에 써먹으려면 점수로 저장해야 합니다.
> 
> > [!LIST] 📝 추가 옵션 설정
> > * **요인 점수**: **'변수로 저장(S)'**을 체크하고 방법은 **'회귀분석'**을 선택합니다. 이렇게 하면 데이터 파일 끝에 새로운 변수가 생깁니다.
> > * **옵션(Options)**: 결과표를 보기 좋게 만들기 위해 **'크기순 정렬'**을 체크하세요. 적재량이 큰 순서대로 문항이 나열되어 훨씬 읽기 편해집니다.
> 
> 

> [!NOTE] 30~31페이지 – 명령문(Syntax) 생성 및 실행
> 
> 확인 버튼을 바로 누르지 말고, **'붙여넣기'**를 눌러보세요. 고수들은 항상 이렇게 합니다.
> 
> > [!TIP] ⭐️ 명령문(Syntax) 활용의 장점 (Yama)
> > * **FACTOR** 명령어로 시작하는 구문이 나타납니다. 
> > * 어떤 변수를 썼는지(/VARIABLES), 회전 방식은 무엇인지(/ROTATION VARIMAX) 한눈에 확인할 수 있고, 나중에 똑같은 분석을 재현할 때 매우 유용합니다.
> 
> > [!LIST] 📝 실행 방법
> > 생성된 명령문 창에서 전체를 드래그한 뒤 상단의 **'실행(녹색 화살표)'** 버튼을 누르면 분석이 시작됩니다.
> 
> 자, 이제 프로그램이 계산을 마쳤을 겁니다. 다음 장(Group 5)으로 넘어가서 쏟아져 나온 표들을 어떻게 해석하고 족보로 만드는지 알아봅시다.

---

> [!NOTE] 32페이지 – 설명된 총분산: 요인 수 결정의 근거
> 
> 자, 분석 결과가 나왔습니다. 가장 먼저 확인해야 할 표는 **'설명된 총분산'**입니다. 우리가 투입한 19개 문항이 몇 개의 요인으로 압축되었는지 보여주죠.
> 
> > [!IMPORTANT] 💡 고유값(Eigenvalue) 기준 결과 (Yama)
> > * **추출된 요인 수:** 고유값 **1**을 기준으로 했을 때, 최종적으로 **3개**의 성분이 도출되었습니다.
> > * **분산 설명력:** 
> > 	* 성분 1: **25.963%** 
> >     * 성분 2: **18.167%** 
> >     * 성분 3: **16.907%** 
> > * **누적 설명력:** 이 3개의 요인이 전체 데이터 분산의 **약 61%**를 설명하고 있습니다. 
> 
> 19개의 문항을 단 3개로 줄였음에도 정보의 **61%**를 유지하고 있다는 건, 아주 효율적인 압축이 일어났다는 뜻입니다. 이제 이 요인들이 구체적으로 어떤 문항들로 구성되었는지 볼까요? 

> [!NOTE] 33페이지 – 성분행렬: 회전 전의 가공되지 않은 상태
> 
> 회전을 하기 전의 **'성분행렬'** 표입니다. 여기서는 각 문항이 어떤 성분에 얼마나 큰 비중(적재값)을 가지는지 보여줍니다.
> 
> > [!WARNING] ⚠️ 회전 전 해석의 난해함
> > * 표를 보면 **피로14, 16, 11** 등이 성분 1에 매우 높은 **요인 적재값(0.7 이상)**을 보이고 있습니다.
> > * 하지만 대부분의 문항이 **성분 1**에 몰려 있거나 여러 성분에 걸쳐 있어, 이 상태로는 요인의 이름을 정하기가 매우 어렵습니다.
> 
> 그래서 우리가 아까 **베리멕스(Varimax)** 회전을 설정한 겁니다. 축을 돌려서 문항들을 각 요인으로 명확히 흩뿌려보겠습니다.

> [!NOTE] 34~35페이지 – 회전된 성분행렬: 변수의 완벽한 재분류
> 
> 드디어 우리가 기다리던 **'회전된 성분행렬'** 결과입니다. 아까 옵션에서 **'크기순 정렬'**을 했기 때문에 해석이 아주 쉽습니다.
> 
> > [!IMPORTANT] 🔑 요인별 문항 구성 결과 (핵심 족보)
> > * **성분 1 (9개 항목):** **피로11~19** 문항들이 묶였습니다. 이 문항들의 내용을 보고 요인의 이름을 정하면 됩니다.
> > * **성분 2 (4개 항목):** **피로1~4** 문항들이 강력하게 결합되었습니다.
> > * **성분 3 (6개 항목):** **피로5~10** 문항들이 하나의 그룹이 되었습니다.
> 
> > [!TIP] ⭐️ 요인 명명(Naming)
> > 이렇게 묶인 문항들의 공통점을 찾아 **'신체적 피로'**, **'정신적 피로'** 등과 같은 이름을 붙여주는 것이 연구자의 다음 과제입니다.
> 
> 이제 이 3개의 요인을 개별 데이터로 저장해서 다음 통계 분석에 활용할 수 있게 되었습니다.

> [!NOTE] 36페이지 – 요인 점수의 생성과 데이터 확인
> 
> 마지막으로 데이터 보기 창을 확인해 봅시다. 우리가 명령했던 대로 새로운 변수들이 생성되어 있을 겁니다.
> 
> > [!LIST] 📝 생성된 요인 점수 변수
> > * **FAC1_1**: 첫 번째 요인에 대한 각 개인별 추정 점수입니다.
> > * **FAC2_1**: 두 번째 요인 점수입니다.
> > * **FAC3_1**: 세 번째 요인 점수입니다.
> 
> > [!INFO] 🧬 요인 점수의 활용
> > 이제 19개의 설문 문항 대신, 이 **3개의 요인 점수** 변수만 가지고 **회귀분석**이나 **분산분석**을 돌리면 됩니다. 데이터가 훨씬 깔끔해졌죠? 
> 
> 고생 많으셨습니다. 요인분석은 처음엔 복잡해 보이지만, **'압축'**과 **'회전'**이라는 두 키워드만 기억하면 여러분도 완벽하게 수행할 수 있습니다.


, ',
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니다.

# 요인 분석

> [!NOTE] 1~2페이지 – 강의 서두: 요인분석(Factor Analysis)의 문을 열며
> 
> 자, 여러분 반갑습니다. 오늘은 다변량 분석의 꽃이라 불리는 **요인분석(Factor Analysis)**에 대해 심도 있게 다뤄보겠습니다.  
> 
> > [!INFO] 🧬 요인분석의 핵심 정의
> > 요인분석은 수많은 변수 간의 **상관관계**를 이용하여, 공통된 특성을 가진 것끼리 묶어주는 기법입니다.  
> > 즉, 데이터의 **복잡성을 압축**하여 소수의 **핵심 요인(Factor)**으로 정보를 요약하는 **다변량 분석**의 핵심이라 할 수 있죠. 
> 
> 왜 우리가 이 복잡한 계산을 해야 할까요? 단순히 숫자를 줄이는 것 이상의 임상적 의미가 있기 때문입니다.

> [!NOTE] 3~4페이지 – 왜 '요인'으로 묶어야 하는가? (데이터의 압축)
> 
> 우리가 수십 개의 설문 문항을 분석한다고 가정해 봅시다. 이걸 하나하나 다루면 머리가 아프겠죠? 
> 
> > [!IMPORTANT] 💡 요인분석을 사용하는 두 가지 이유 (Yama)
> > * **변수 집단화:** 어떤 변수들이 서로 유기적으로 연결되어 있는지 **관찰**하고 묶기 위함입니다. 
> > * **차원 축소:** 유사한 변수를 하나의 요인으로 합쳐서, 나중에 **종속변수와의 관련성**을 더 명확하게 분석하기 위해 사용합니다. 
> 
> > [!LIST] 📝 분석의 흐름
> > * **Input:** 다양하고 해석하기 어려운 **상관성 있는 변수**들의 뭉치 
> > * **Process:** 요인분석을 통한 데이터 다이어트
> > * **Output:** 개념적으로 명확하고 **독립적인 소수 변수**로의 변환 
> 
> 
>
> 자, 그림을 보시면 아시겠지만, 흩어져 있던 변수들이 의미 있는 큰 덩어리로 합쳐지는 과정입니다.  이제 이 기법이 실제 연구에서 어떻게 적용되는지 봅시다.

> [!NOTE] 5~6페이지 – 탐색적 요인분석(EFA)과 분산의 구조
> 
> 실제 연구에서는 최종 분석 전에 변수들을 정리하기 위해 이 단계를 꼭 거칩니다.  특히 **숨겨진 공통요인**을 찾아내는 것이 주된 목적이죠. 
> 
> > [!IMPORTANT] 🔑 탐색적 요인분석(EFA)의 핵심 원리
> > * 측정 변수 간의 상관관계를 통해 **소수의 요인**을 도출합니다. 
> > * **총 분산의 구성:** $$총 분산 = 공통 요인 분산(잠재변수) + 고유 요인 분산(Error)$$ 
> 
> > [!INFO] 🧬 공통분(Communality)이란?
> > 특정 변수가 가진 전체 분산 중에서, 추출된 **공통 요인**에 의해 설명되는 양을 의미합니다.  
> > 이 값이 높을수록 해당 변수가 요인에 잘 반영되었다는 뜻이겠죠?
> 
> 하지만 요인을 추출할 때 주의해야 할 점이 있습니다. 너무 많이 나눠도, 너무 적게 나눠도 문제입니다.

> [!NOTE] 7~8페이지 – 요인 추출의 실패 사례와 메커니즘
> 
> 요인분석도 과유불급입니다. 연구자가 판단을 잘못하면 분석 결과가 산으로 갈 수 있어요. 
> 
> > [!WARNING] ⚠️ 분석 실패의 두 가지 유형
> > * **Overfactoring:** 실제로는 하나로 묶여야 할 요인을 **너무 잘게 쪼개어** 도출한 경우입니다. 
> > * **Underfactoring:** 더 상세히 나눌 수 있음에도 불구하고 **너무 적은 요인**만 뽑아낸 경우입니다. 
> 
> > [!IMPORTANT] 💡 이론 구조 개발의 핵심
> > 요인분석은 **고유 요인(Error)**을 제거하고 오직 **공통 요인**만 추출하려 노력합니다.  
> > 이를 위해 통계적으로는 **축소 상관행렬(Reduced correlation matrix)**이라는 도구를 사용하게 되죠. 
> 
> 자, 이제 요인분석이 무엇을 하려는 기법인지 감이 오시죠? 다음 장(Group 2)에서는 이 과정을 수학적으로 어떻게 표현하는지, 그리고 많은 분이 헷갈려 하는 주성분 분석과의 차이점을 명확히 짚어드리겠습니다.

---

> [!NOTE] 9~10페이지 – 요인분석의 수학적 뼈대: 직교 요인 모형 (Orthogonal Factor Model)
> 
> 자, 이제 요인분석이 내부적으로 어떤 계산 과정을 거치는지 그 뼈대를 살펴봅시다. 통계학적으로 요인분석은 변수들을 선형 결합으로 표현하는 **직교 요인 모형**을 따릅니다.
> 
> > [!INFO] 🧬 기본적인 선형 모형 (Matrix Form)
> > $$X = LF + \epsilon$$
> > * **$X$**: 관측된 $p$개의 변수 벡터입니다.
> > * **$L$**: **요인 부하량(Factor Loading)** 행렬로, 각 변수와 요인 간의 관계 강도를 나타냅니다.
> > * **$F$**: 우리가 찾고자 하는 잠재적인 **공통 요인**입니다.
> > * **$\epsilon$**: 각 변수만이 가진 **고유 요인(Error)**입니다.
> 
> 이 수식을 통해 우리는 개별 변수의 전체 분산을 두 가지 성분으로 쪼갤 수 있습니다.
> 
> > [!IMPORTANT] 💡 분산의 구성: 커뮤날리티 vs 특수 분산
> > $$var(x_i) = h_i^2 (Communality) + \Psi_i (Specific Variance)$$ 
> > * **커뮤날리티($h_i^2$):** $m$개의 공통 요인에 의해 설명되는 부분입니다.
> > * **특수 분산($\Psi_i$):** 공통 요인으로 설명되지 않는 그 변수만의 고유한 변동입니다.
> 
> 앞서 배운 '공통 요인'을 추출한다는 것은 결국 이 **커뮤날리티**를 극대화하는 과정이라고 이해하시면 됩니다.

> [!NOTE] 11페이지 – 요인 추출의 방법론: 주축분해법 vs 최대우도법
> 
> 수학적 모델을 세웠으니 이제 실제 값을 추정해야겠죠? SPSS에서 주로 사용하는 두 가지 핵심 방법을 비교해 봅시다.
> 
> > [!LIST] 📝 주요 추정 방법 비교
> > * **주축분해법(Principal Axis Factoring):** 
> > 	 - **SPSS** 사용 시 가장 권장되는 방법입니다.
> >     - **SMC(Squared Multiple Correlation)**를 초기 커뮤날리티로 사용하여 반복 계산을 통해 최적값을 찾습니다.
> > * **최대우도법(Maximum Likelihood, ML):** 
> > 	- 표본의 상관행렬과 모형의 상관행렬이 최대한 유사해지도록 추정합니다.
> > 	- **정상성 가정**에 민감하고 **많은 표본**이 필요하지만, 적합도 검증($\chi^2$)이 가능하다는 장점이 있습니다.
> 
> 어떤 방법을 선택하느냐에 따라 결과가 달라질 수 있으니 데이터의 특성을 먼저 파악해야 합니다.

> [!NOTE] 12페이지 – SPSS의 함정: 주성분 분석(PCA)과 요인분석의 차이
> 
> 여기서 아주 중요한 주의사항이 하나 나옵니다. SPSS의 기본 설정(Default)에 속지 마세요.
> 
> > [!WARNING] ⚠️ 주성분 분석(PCA)을 지양해야 하는 이유 (Yama)
> > * **오차 무시:** PCA는 데이터에 **에러(Error)가 없다**고 가정합니다. 
> > * **분산 설명 최대화:** 단순히 많은 변수를 소수로 축소하는 데 초점을 맞춥니다.
> > * **행동과학에서의 한계:** 사람의 심리나 행동 데이터는 오차를 무시할 수 없으므로, 엄밀한 의미의 **요인분석**에서는 PCA 사용을 지양해야 합니다.
> 
> 교수님들이 흔히 **"PCA는 불필요한 분석이다"**라고 말씀하시는 이유가 바로 이 **오차 항의 부재** 때문입니다.

> [!NOTE] 13~14페이지 – 주성분 방법의 논리: 분산 설명력의 극대화
> 
> 그럼에도 불구하고 PCA의 논리를 이해하는 것은 기초 체력을 기르는 데 도움이 됩니다.
> 
> > [!INFO] 🧬 주성분(PC) 도출 원리
> > * **총 분산:** 모든 변수의 표본분산의 합입니다.
> > * **제1주성분 [PC(1)]:** 자료의 총 분산을 **가장 많이 설명**할 수 있도록 변수들을 가중 결합한 것입니다.
> > * **제2주성분 [PC(2)]:** 첫 번째 주성분이 설명하지 못한 나머지 분산을 최대한 설명하며, **PC(1)과는 상관성이 없는(직교하는)** 결합입니다.
> 
> > [!IMPORTANT] 💡 가중치 결정의 목적
> > 가능한 한 **적은 수의 요인**으로 전체 데이터의 불확실성(Uncertainty)을 가장 잘 설명하는 것이 핵심입니다.
> 
> 자, 이제 수학적 기초와 분석 도구들의 특징을 정리했습니다. 이제 추출된 요인을 어떻게 더 명확하게 해석할 것인지, **요인 회전**과 **확인적 요인분석**의 세계로 넘어가 봅시다 (Group 3).

---

> [!NOTE] 15~16페이지 – 요인 회전(Rotation): 해석의 마법
> 
> 요인을 추출한 직후의 결과는 보통 해석하기가 매우 난해합니다. 이때 필요한 것이 바로 **요인 회전**입니다.
> 
> > [!INFO] 🧬 단순구조(Simple Structure)
> > 회전의 목적은 수학적으로는 동일한 모델을 유지하면서, 각 변수가 특정 요인에만 강하게 걸리도록 **단순구조**를 만들어 **해석을 용이**하게 하는 데 있습니다.
> 
> > [!IMPORTANT] 💡 회전 방법의 선택 (Yama)
> > 1. **직각회전(Orthogonal):** 요인 간의 **상관관계가 0**이라고 가정합니다. (예: **Varimax**)
> >    - 단, 사회과학이나 의학 데이터에서 요인 간 상관이 전혀 없다는 것은 **논리적으로 무리(Logic nonsense)**가 있을 수 있습니다.
> > 2. **사각회전(Oblique):** 요인 간의 **상관을 인정**합니다. (예: **Promax**, **Direct Oblimin**)
> >    - 현실적인 데이터 분석에서는 사각회전이 훨씬 더 권장됩니다.
> 
> > [!LIST] 📝 행렬의 종류
> > * **패턴행렬(Pattern Matrix):** 요인이 변수에 미치는 영향력(회귀계수)을 나타내며, 사각회전 시 주로 해석합니다.
> > * **구조행렬(Structure Matrix):** 요인과 변수 사이의 단순 상관계수입니다.
> 
> 자, 이 회전된 축을 통해 비로소 우리는 요인에 '이름'을 붙여줄 수 있게 됩니다.

> [!NOTE] 17페이지 – 분석 도구별 권장 절차
> 
> 여러분이 어떤 프로그램을 쓰느냐에 따라 권장되는 분석 루틴이 조금 다릅니다. 이 루틴을 외워두면 실무에서 큰 도움이 됩니다.
> 
> > [!TIP] ⭐️ 프로그램별 Standard (족보)
> > * **SPSS 사용 시:** **주축분해법** 추출 → 스크리 도표/평행분석으로 요인 수 결정 → **사각회전** 적용.
> > * **구조방정식(SEM) 모델링 시:** **최대우도법(ML)** 추출 → 적합도 지수 확인 → **사각회전** 적용.
> 
> 이제 우리가 지금까지 한 '탐색'을 넘어, 이미 알고 있는 이론을 '확인'하는 단계로 가봅시다.

> [!NOTE] 18~19페이지 – 확인적 요인분석(CFA)의 논리
> 
> 탐색적 요인분석(EFA)이 "뭐가 나올지 모르는 상태에서 묶어보는 것"이라면, **확인적 요인분석(CFA)**은 "내가 세운 가설이 맞는지 검증하는 것"입니다.
> 
> > [!IMPORTANT] 🔑 CFA의 핵심 차이점
> > * **제약(Constraint):** 특정 변수는 특정 요인에만 영향을 받는다고 미리 식을 고정합니다.
> > * **오차 상관:** 이론적 근거가 있다면 문항 간 **오차 공분산**을 허용할 수 있습니다.
> > * **주의사항 (Critical):** **동일한 자료**에 대해 EFA를 하고 그 결과로 다시 CFA를 수행하는 것은 통계적으로 **지양**해야 합니다.
> 
> > [!INFO] 🧬 식별을 위한 고정(Scaling)
> > 모델이 돌아가려면 기준이 필요합니다. 보통 **요인계수가 가장 높은 변수**의 계수를 **1**로 고정(Reference variable)하거나, 잠재변수의 분산을 1로 고정합니다.

> [!NOTE] 20페이지 – 모델이 얼마나 잘 맞는가? 적합도 지수(Fit Indices)
> 
> CFA를 돌리고 나면 반드시 이 모델이 실제 데이터를 얼마나 잘 설명하는지 수치로 보여줘야 합니다.
> 
> > [!IMPORTANT] 💡 권장 적합도 판단 기준 (Hu & Bentler, 1999)
> > * **TLI / CFI:** **0.90 이상**이면 괜찮고, **0.95 이상**이면 매우 좋은 모델입니다.
> > * **RMSEA:** **0.05 미만**이면 Close fit(최상), **0.08 미만**이면 양호(Reasonable)한 것으로 봅니다. **0.10**을 넘어가면 수용 불가능합니다.
> > * **SRMR:** **0.08 미만**을 기준으로 삼습니다.
> 
> $\chi^2$(카이제곱) 검정은 너무 엄격해서 표본이 조금만 커도 기각되기 쉽기 때문에, 보통 위 지수들을 종합적으로 보고 모델의 우수성을 판단합니다.

> [!NOTE] 21페이지 – 새로운 변수의 탄생: 요인 점수(Factor Score)
> 
> 자, 요인분석의 마지막 단계입니다. 우리는 수많은 문항을 몇 개의 요인으로 묶었습니다. 이제 이 요인들을 **하나의 숫자**로 만들어서 다음 분석에 써먹어야겠죠?
> 
> > [!INFO] 🧬 요인 점수란?
> > 공통 요인의 추정값으로, 추출된 요인을 새로운 **독립변수**나 **종속변수**로 활용할 수 있게 해주는 값입니다.
> 
> > [!LIST] 📝 점수 산출 방법
> > 1. **가중 최소제곱법 (Bartlett):** 측정 오차를 고려한 가중치를 부여합니다.
> > 2. **회귀 방법 (Regression):** 가장 보편적으로 사용되는 방식입니다.
> 
> 이제 이론은 완벽하게 정리되었습니다. 백문이 불여일견이죠. 다음 장(Group 4)부터는 실제 **피로 척도 데이터**를 가지고 SPSS를 직접 돌려보겠습니다.

---

> [!NOTE] 22~23페이지 – SPSS 실습 예제: 다차원 피로 척도(MFS) 분석
> 
> 자, 이론은 여기까지 하고 이제 직접 데이터를 만져봅시다. 오늘 사용할 데이터는 **피로.sav** 파일입니다. 
> 
> > [!quote] 🩺 실습 케이스: 다차원 피로 척도(MFS)
> > * **목적**: 주관적 피로 증상을 측정하기 위해 개발된 **19문항**의 척도가 과연 몇 개의 요인으로 구분되는지 파악하는 것입니다.
> > * **활용**: 추출된 요인을 새로운 변수로 만들어 추후 분석에 사용하고자 합니다.
> 
> 먼저 메뉴부터 찾아 들어가야겠죠? **분석(A) > 차원 감소 > 요인분석(F)** 순서로 클릭하세요.
> 
> 

> [!NOTE] 24~25페이지 – 변수 선택 및 투입
> 
> 창이 뜨면 왼쪽 변수 목록에서 우리가 분석할 문항들을 골라야 합니다.
> 
> > [!LIST] 📝 변수 선택 단계
> > 1. 성별, 연령 같은 인구학적 변수는 일단 제외합니다.
> > 2. 분석하고자 하는 설문 문항인 **피로1부터 피로19**까지를 모두 선택합니다.
> > 3. 오른쪽의 **변수(V)** 박스로 모든 문항을 이동시킵니다.
> 
> 
> 
> 문항을 다 옮겼다면, 이제 우측의 버튼들을 하나씩 눌러 세부 설정을 해줄 차례입니다.

> [!NOTE] 26~27페이지 – 요인 추출(Extraction)과 회전(Rotation) 설정
> 
> 여기가 가장 중요합니다. 제가 이론 강의 때 강조했던 내용들을 적용하는 단계예요.
> 
> > [!IMPORTANT] 💡 요인 추출(Extraction) 설정
> > * **방법**: 기본값은 **주성분(PCA)** 분석으로 되어 있습니다. (학술적 목적에 따라 주축분해법 등으로 변경 가능합니다.)
> > * **추출 기준**: 보통 **고유값(Eigenvalue) 1**을 기준으로 삼지만, 연구자가 특정 요인 수를 직접 지정할 수도 있습니다.
> > * **출력**: 흐름을 파악하기 위해 **스크리 도표(Scree Plot)**를 체크하는 습관을 들이세요.
> 
> > [!IMPORTANT] 💡 요인 회전(Rotation) 설정
> > * **방법**: 여기서는 직각회전 방식인 **베리맥스(Varimax)**를 선택하겠습니다. 
> > * **목적**: 요인 적재량을 재배치하여 어떤 문항이 어떤 요인에 속하는지 명확히 보기 위함입니다.
> 
> 

> [!NOTE] 28~29페이지 – 요인 점수 저장 및 출력 옵션
> 
> 분석 결과만 보고 끝낼 게 아니라, 이 요인들을 나중에 회귀분석 등에 써먹으려면 점수로 저장해야 합니다.
> 
> > [!LIST] 📝 추가 옵션 설정
> > * **요인 점수**: **'변수로 저장(S)'**을 체크하고 방법은 **'회귀분석'**을 선택합니다. 이렇게 하면 데이터 파일 끝에 새로운 변수가 생깁니다.
> > * **옵션(Options)**: 결과표를 보기 좋게 만들기 위해 **'크기순 정렬'**을 체크하세요. 적재량이 큰 순서대로 문항이 나열되어 훨씬 읽기 편해집니다.
> 
> 

> [!NOTE] 30~31페이지 – 명령문(Syntax) 생성 및 실행
> 
> 확인 버튼을 바로 누르지 말고, **'붙여넣기'**를 눌러보세요. 고수들은 항상 이렇게 합니다.
> 
> > [!TIP] ⭐️ 명령문(Syntax) 활용의 장점 (Yama)
> > * **FACTOR** 명령어로 시작하는 구문이 나타납니다. 
> > * 어떤 변수를 썼는지(/VARIABLES), 회전 방식은 무엇인지(/ROTATION VARIMAX) 한눈에 확인할 수 있고, 나중에 똑같은 분석을 재현할 때 매우 유용합니다.
> 
> > [!LIST] 📝 실행 방법
> > 생성된 명령문 창에서 전체를 드래그한 뒤 상단의 **'실행(녹색 화살표)'** 버튼을 누르면 분석이 시작됩니다.
> 
> 자, 이제 프로그램이 계산을 마쳤을 겁니다. 다음 장(Group 5)으로 넘어가서 쏟아져 나온 표들을 어떻게 해석하고 족보로 만드는지 알아봅시다.

---

> [!NOTE] 32페이지 – 설명된 총분산: 요인 수 결정의 근거
> 
> 자, 분석 결과가 나왔습니다. 가장 먼저 확인해야 할 표는 **'설명된 총분산'**입니다. 우리가 투입한 19개 문항이 몇 개의 요인으로 압축되었는지 보여주죠.
> 
> > [!IMPORTANT] 💡 고유값(Eigenvalue) 기준 결과 (Yama)
> > * **추출된 요인 수:** 고유값 **1**을 기준으로 했을 때, 최종적으로 **3개**의 성분이 도출되었습니다.
> > * **분산 설명력:** 
> > 	* 성분 1: **25.963%** 
> >     * 성분 2: **18.167%** 
> >     * 성분 3: **16.907%** 
> > * **누적 설명력:** 이 3개의 요인이 전체 데이터 분산의 **약 61%**를 설명하고 있습니다. 
> 
> 19개의 문항을 단 3개로 줄였음에도 정보의 **61%**를 유지하고 있다는 건, 아주 효율적인 압축이 일어났다는 뜻입니다. 이제 이 요인들이 구체적으로 어떤 문항들로 구성되었는지 볼까요? 

> [!NOTE] 33페이지 – 성분행렬: 회전 전의 가공되지 않은 상태
> 
> 회전을 하기 전의 **'성분행렬'** 표입니다. 여기서는 각 문항이 어떤 성분에 얼마나 큰 비중(적재값)을 가지는지 보여줍니다.
> 
> > [!WARNING] ⚠️ 회전 전 해석의 난해함
> > * 표를 보면 **피로14, 16, 11** 등이 성분 1에 매우 높은 **요인 적재값(0.7 이상)**을 보이고 있습니다.
> > * 하지만 대부분의 문항이 **성분 1**에 몰려 있거나 여러 성분에 걸쳐 있어, 이 상태로는 요인의 이름을 정하기가 매우 어렵습니다.
> 
> 그래서 우리가 아까 **베리멕스(Varimax)** 회전을 설정한 겁니다. 축을 돌려서 문항들을 각 요인으로 명확히 흩뿌려보겠습니다.

> [!NOTE] 34~35페이지 – 회전된 성분행렬: 변수의 완벽한 재분류
> 
> 드디어 우리가 기다리던 **'회전된 성분행렬'** 결과입니다. 아까 옵션에서 **'크기순 정렬'**을 했기 때문에 해석이 아주 쉽습니다.
> 
> > [!IMPORTANT] 🔑 요인별 문항 구성 결과 (핵심 족보)
> > * **성분 1 (9개 항목):** **피로11~19** 문항들이 묶였습니다. 이 문항들의 내용을 보고 요인의 이름을 정하면 됩니다.
> > * **성분 2 (4개 항목):** **피로1~4** 문항들이 강력하게 결합되었습니다.
> > * **성분 3 (6개 항목):** **피로5~10** 문항들이 하나의 그룹이 되었습니다.
> 
> > [!TIP] ⭐️ 요인 명명(Naming)
> > 이렇게 묶인 문항들의 공통점을 찾아 **'신체적 피로'**, **'정신적 피로'** 등과 같은 이름을 붙여주는 것이 연구자의 다음 과제입니다.
> 
> 이제 이 3개의 요인을 개별 데이터로 저장해서 다음 통계 분석에 활용할 수 있게 되었습니다.

> [!NOTE] 36페이지 – 요인 점수의 생성과 데이터 확인
> 
> 마지막으로 데이터 보기 창을 확인해 봅시다. 우리가 명령했던 대로 새로운 변수들이 생성되어 있을 겁니다.
> 
> > [!LIST] 📝 생성된 요인 점수 변수
> > * **FAC1_1**: 첫 번째 요인에 대한 각 개인별 추정 점수입니다.
> > * **FAC2_1**: 두 번째 요인 점수입니다.
> > * **FAC3_1**: 세 번째 요인 점수입니다.
> 
> > [!INFO] 🧬 요인 점수의 활용
> > 이제 19개의 설문 문항 대신, 이 **3개의 요인 점수** 변수만 가지고 **회귀분석**이나 **분산분석**을 돌리면 됩니다. 데이터가 훨씬 깔끔해졌죠? 
> 
> 고생 많으셨습니다. 요인분석은 처음엔 복잡해 보이지만, **'압축'**과 **'회전'**이라는 두 키워드만 기억하면 여러분도 완벽하게 수행할 수 있습니다.


], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

>[!quote] 공지
>본 자료의 저작권은 **KAISTUDY**에 있습니다.

# 요인 분석

> [!NOTE] 1~2페이지 – 강의 서두: 요인분석(Factor Analysis)의 문을 열며
> 
> 자, 여러분 반갑습니다. 오늘은 다변량 분석의 꽃이라 불리는 **요인분석(Factor Analysis)**에 대해 심도 있게 다뤄보겠습니다.  
> 
> > [!INFO] 🧬 요인분석의 핵심 정의
> > 요인분석은 수많은 변수 간의 **상관관계**를 이용하여, 공통된 특성을 가진 것끼리 묶어주는 기법입니다.  
> > 즉, 데이터의 **복잡성을 압축**하여 소수의 **핵심 요인(Factor)**으로 정보를 요약하는 **다변량 분석**의 핵심이라 할 수 있죠. 
> 
> 왜 우리가 이 복잡한 계산을 해야 할까요? 단순히 숫자를 줄이는 것 이상의 임상적 의미가 있기 때문입니다.

> [!NOTE] 3~4페이지 – 왜 '요인'으로 묶어야 하는가? (데이터의 압축)
> 
> 우리가 수십 개의 설문 문항을 분석한다고 가정해 봅시다. 이걸 하나하나 다루면 머리가 아프겠죠? 
> 
> > [!IMPORTANT] 💡 요인분석을 사용하는 두 가지 이유 (Yama)
> > * **변수 집단화:** 어떤 변수들이 서로 유기적으로 연결되어 있는지 **관찰**하고 묶기 위함입니다. 
> > * **차원 축소:** 유사한 변수를 하나의 요인으로 합쳐서, 나중에 **종속변수와의 관련성**을 더 명확하게 분석하기 위해 사용합니다. 
> 
> > [!LIST] 📝 분석의 흐름
> > * **Input:** 다양하고 해석하기 어려운 **상관성 있는 변수**들의 뭉치 
> > * **Process:** 요인분석을 통한 데이터 다이어트
> > * **Output:** 개념적으로 명확하고 **독립적인 소수 변수**로의 변환 
> 
> 
>
> 자, 그림을 보시면 아시겠지만, 흩어져 있던 변수들이 의미 있는 큰 덩어리로 합쳐지는 과정입니다.  이제 이 기법이 실제 연구에서 어떻게 적용되는지 봅시다.

> [!NOTE] 5~6페이지 – 탐색적 요인분석(EFA)과 분산의 구조
> 
> 실제 연구에서는 최종 분석 전에 변수들을 정리하기 위해 이 단계를 꼭 거칩니다.  특히 **숨겨진 공통요인**을 찾아내는 것이 주된 목적이죠. 
> 
> > [!IMPORTANT] 🔑 탐색적 요인분석(EFA)의 핵심 원리
> > * 측정 변수 간의 상관관계를 통해 **소수의 요인**을 도출합니다. 
> > * **총 분산의 구성:** $$총 분산 = 공통 요인 분산(잠재변수) + 고유 요인 분산(Error)$$ 
> 
> > [!INFO] 🧬 공통분(Communality)이란?
> > 특정 변수가 가진 전체 분산 중에서, 추출된 **공통 요인**에 의해 설명되는 양을 의미합니다.  
> > 이 값이 높을수록 해당 변수가 요인에 잘 반영되었다는 뜻이겠죠?
> 
> 하지만 요인을 추출할 때 주의해야 할 점이 있습니다. 너무 많이 나눠도, 너무 적게 나눠도 문제입니다.

> [!NOTE] 7~8페이지 – 요인 추출의 실패 사례와 메커니즘
> 
> 요인분석도 과유불급입니다. 연구자가 판단을 잘못하면 분석 결과가 산으로 갈 수 있어요. 
> 
> > [!WARNING] ⚠️ 분석 실패의 두 가지 유형
> > * **Overfactoring:** 실제로는 하나로 묶여야 할 요인을 **너무 잘게 쪼개어** 도출한 경우입니다. 
> > * **Underfactoring:** 더 상세히 나눌 수 있음에도 불구하고 **너무 적은 요인**만 뽑아낸 경우입니다. 
> 
> > [!IMPORTANT] 💡 이론 구조 개발의 핵심
> > 요인분석은 **고유 요인(Error)**을 제거하고 오직 **공통 요인**만 추출하려 노력합니다.  
> > 이를 위해 통계적으로는 **축소 상관행렬(Reduced correlation matrix)**이라는 도구를 사용하게 되죠. 
> 
> 자, 이제 요인분석이 무엇을 하려는 기법인지 감이 오시죠? 다음 장(Group 2)에서는 이 과정을 수학적으로 어떻게 표현하는지, 그리고 많은 분이 헷갈려 하는 주성분 분석과의 차이점을 명확히 짚어드리겠습니다.

---

> [!NOTE] 9~10페이지 – 요인분석의 수학적 뼈대: 직교 요인 모형 (Orthogonal Factor Model)
> 
> 자, 이제 요인분석이 내부적으로 어떤 계산 과정을 거치는지 그 뼈대를 살펴봅시다. 통계학적으로 요인분석은 변수들을 선형 결합으로 표현하는 **직교 요인 모형**을 따릅니다.
> 
> > [!INFO] 🧬 기본적인 선형 모형 (Matrix Form)
> > $$X = LF + \epsilon$$
> > * **$X$**: 관측된 $p$개의 변수 벡터입니다.
> > * **$L$**: **요인 부하량(Factor Loading)** 행렬로, 각 변수와 요인 간의 관계 강도를 나타냅니다.
> > * **$F$**: 우리가 찾고자 하는 잠재적인 **공통 요인**입니다.
> > * **$\epsilon$**: 각 변수만이 가진 **고유 요인(Error)**입니다.
> 
> 이 수식을 통해 우리는 개별 변수의 전체 분산을 두 가지 성분으로 쪼갤 수 있습니다.
> 
> > [!IMPORTANT] 💡 분산의 구성: 커뮤날리티 vs 특수 분산
> > $$var(x_i) = h_i^2 (Communality) + \Psi_i (Specific Variance)$$ 
> > * **커뮤날리티($h_i^2$):** $m$개의 공통 요인에 의해 설명되는 부분입니다.
> > * **특수 분산($\Psi_i$):** 공통 요인으로 설명되지 않는 그 변수만의 고유한 변동입니다.
> 
> 앞서 배운 '공통 요인'을 추출한다는 것은 결국 이 **커뮤날리티**를 극대화하는 과정이라고 이해하시면 됩니다.

> [!NOTE] 11페이지 – 요인 추출의 방법론: 주축분해법 vs 최대우도법
> 
> 수학적 모델을 세웠으니 이제 실제 값을 추정해야겠죠? SPSS에서 주로 사용하는 두 가지 핵심 방법을 비교해 봅시다.
> 
> > [!LIST] 📝 주요 추정 방법 비교
> > * **주축분해법(Principal Axis Factoring):** 
> > 	 - **SPSS** 사용 시 가장 권장되는 방법입니다.
> >     - **SMC(Squared Multiple Correlation)**를 초기 커뮤날리티로 사용하여 반복 계산을 통해 최적값을 찾습니다.
> > * **최대우도법(Maximum Likelihood, ML):** 
> > 	- 표본의 상관행렬과 모형의 상관행렬이 최대한 유사해지도록 추정합니다.
> > 	- **정상성 가정**에 민감하고 **많은 표본**이 필요하지만, 적합도 검증($\chi^2$)이 가능하다는 장점이 있습니다.
> 
> 어떤 방법을 선택하느냐에 따라 결과가 달라질 수 있으니 데이터의 특성을 먼저 파악해야 합니다.

> [!NOTE] 12페이지 – SPSS의 함정: 주성분 분석(PCA)과 요인분석의 차이
> 
> 여기서 아주 중요한 주의사항이 하나 나옵니다. SPSS의 기본 설정(Default)에 속지 마세요.
> 
> > [!WARNING] ⚠️ 주성분 분석(PCA)을 지양해야 하는 이유 (Yama)
> > * **오차 무시:** PCA는 데이터에 **에러(Error)가 없다**고 가정합니다. 
> > * **분산 설명 최대화:** 단순히 많은 변수를 소수로 축소하는 데 초점을 맞춥니다.
> > * **행동과학에서의 한계:** 사람의 심리나 행동 데이터는 오차를 무시할 수 없으므로, 엄밀한 의미의 **요인분석**에서는 PCA 사용을 지양해야 합니다.
> 
> 교수님들이 흔히 **"PCA는 불필요한 분석이다"**라고 말씀하시는 이유가 바로 이 **오차 항의 부재** 때문입니다.

> [!NOTE] 13~14페이지 – 주성분 방법의 논리: 분산 설명력의 극대화
> 
> 그럼에도 불구하고 PCA의 논리를 이해하는 것은 기초 체력을 기르는 데 도움이 됩니다.
> 
> > [!INFO] 🧬 주성분(PC) 도출 원리
> > * **총 분산:** 모든 변수의 표본분산의 합입니다.
> > * **제1주성분 [PC(1)]:** 자료의 총 분산을 **가장 많이 설명**할 수 있도록 변수들을 가중 결합한 것입니다.
> > * **제2주성분 [PC(2)]:** 첫 번째 주성분이 설명하지 못한 나머지 분산을 최대한 설명하며, **PC(1)과는 상관성이 없는(직교하는)** 결합입니다.
> 
> > [!IMPORTANT] 💡 가중치 결정의 목적
> > 가능한 한 **적은 수의 요인**으로 전체 데이터의 불확실성(Uncertainty)을 가장 잘 설명하는 것이 핵심입니다.
> 
> 자, 이제 수학적 기초와 분석 도구들의 특징을 정리했습니다. 이제 추출된 요인을 어떻게 더 명확하게 해석할 것인지, **요인 회전**과 **확인적 요인분석**의 세계로 넘어가 봅시다 (Group 3).

---

> [!NOTE] 15~16페이지 – 요인 회전(Rotation): 해석의 마법
> 
> 요인을 추출한 직후의 결과는 보통 해석하기가 매우 난해합니다. 이때 필요한 것이 바로 **요인 회전**입니다.
> 
> > [!INFO] 🧬 단순구조(Simple Structure)
> > 회전의 목적은 수학적으로는 동일한 모델을 유지하면서, 각 변수가 특정 요인에만 강하게 걸리도록 **단순구조**를 만들어 **해석을 용이**하게 하는 데 있습니다.
> 
> > [!IMPORTANT] 💡 회전 방법의 선택 (Yama)
> > 1. **직각회전(Orthogonal):** 요인 간의 **상관관계가 0**이라고 가정합니다. (예: **Varimax**)
> >    - 단, 사회과학이나 의학 데이터에서 요인 간 상관이 전혀 없다는 것은 **논리적으로 무리(Logic nonsense)**가 있을 수 있습니다.
> > 2. **사각회전(Oblique):** 요인 간의 **상관을 인정**합니다. (예: **Promax**, **Direct Oblimin**)
> >    - 현실적인 데이터 분석에서는 사각회전이 훨씬 더 권장됩니다.
> 
> > [!LIST] 📝 행렬의 종류
> > * **패턴행렬(Pattern Matrix):** 요인이 변수에 미치는 영향력(회귀계수)을 나타내며, 사각회전 시 주로 해석합니다.
> > * **구조행렬(Structure Matrix):** 요인과 변수 사이의 단순 상관계수입니다.
> 
> 자, 이 회전된 축을 통해 비로소 우리는 요인에 '이름'을 붙여줄 수 있게 됩니다.

> [!NOTE] 17페이지 – 분석 도구별 권장 절차
> 
> 여러분이 어떤 프로그램을 쓰느냐에 따라 권장되는 분석 루틴이 조금 다릅니다. 이 루틴을 외워두면 실무에서 큰 도움이 됩니다.
> 
> > [!TIP] ⭐️ 프로그램별 Standard (족보)
> > * **SPSS 사용 시:** **주축분해법** 추출 → 스크리 도표/평행분석으로 요인 수 결정 → **사각회전** 적용.
> > * **구조방정식(SEM) 모델링 시:** **최대우도법(ML)** 추출 → 적합도 지수 확인 → **사각회전** 적용.
> 
> 이제 우리가 지금까지 한 '탐색'을 넘어, 이미 알고 있는 이론을 '확인'하는 단계로 가봅시다.

> [!NOTE] 18~19페이지 – 확인적 요인분석(CFA)의 논리
> 
> 탐색적 요인분석(EFA)이 "뭐가 나올지 모르는 상태에서 묶어보는 것"이라면, **확인적 요인분석(CFA)**은 "내가 세운 가설이 맞는지 검증하는 것"입니다.
> 
> > [!IMPORTANT] 🔑 CFA의 핵심 차이점
> > * **제약(Constraint):** 특정 변수는 특정 요인에만 영향을 받는다고 미리 식을 고정합니다.
> > * **오차 상관:** 이론적 근거가 있다면 문항 간 **오차 공분산**을 허용할 수 있습니다.
> > * **주의사항 (Critical):** **동일한 자료**에 대해 EFA를 하고 그 결과로 다시 CFA를 수행하는 것은 통계적으로 **지양**해야 합니다.
> 
> > [!INFO] 🧬 식별을 위한 고정(Scaling)
> > 모델이 돌아가려면 기준이 필요합니다. 보통 **요인계수가 가장 높은 변수**의 계수를 **1**로 고정(Reference variable)하거나, 잠재변수의 분산을 1로 고정합니다.

> [!NOTE] 20페이지 – 모델이 얼마나 잘 맞는가? 적합도 지수(Fit Indices)
> 
> CFA를 돌리고 나면 반드시 이 모델이 실제 데이터를 얼마나 잘 설명하는지 수치로 보여줘야 합니다.
> 
> > [!IMPORTANT] 💡 권장 적합도 판단 기준 (Hu & Bentler, 1999)
> > * **TLI / CFI:** **0.90 이상**이면 괜찮고, **0.95 이상**이면 매우 좋은 모델입니다.
> > * **RMSEA:** **0.05 미만**이면 Close fit(최상), **0.08 미만**이면 양호(Reasonable)한 것으로 봅니다. **0.10**을 넘어가면 수용 불가능합니다.
> > * **SRMR:** **0.08 미만**을 기준으로 삼습니다.
> 
> $\chi^2$(카이제곱) 검정은 너무 엄격해서 표본이 조금만 커도 기각되기 쉽기 때문에, 보통 위 지수들을 종합적으로 보고 모델의 우수성을 판단합니다.

> [!NOTE] 21페이지 – 새로운 변수의 탄생: 요인 점수(Factor Score)
> 
> 자, 요인분석의 마지막 단계입니다. 우리는 수많은 문항을 몇 개의 요인으로 묶었습니다. 이제 이 요인들을 **하나의 숫자**로 만들어서 다음 분석에 써먹어야겠죠?
> 
> > [!INFO] 🧬 요인 점수란?
> > 공통 요인의 추정값으로, 추출된 요인을 새로운 **독립변수**나 **종속변수**로 활용할 수 있게 해주는 값입니다.
> 
> > [!LIST] 📝 점수 산출 방법
> > 1. **가중 최소제곱법 (Bartlett):** 측정 오차를 고려한 가중치를 부여합니다.
> > 2. **회귀 방법 (Regression):** 가장 보편적으로 사용되는 방식입니다.
> 
> 이제 이론은 완벽하게 정리되었습니다. 백문이 불여일견이죠. 다음 장(Group 4)부터는 실제 **피로 척도 데이터**를 가지고 SPSS를 직접 돌려보겠습니다.

---

> [!NOTE] 22~23페이지 – SPSS 실습 예제: 다차원 피로 척도(MFS) 분석
> 
> 자, 이론은 여기까지 하고 이제 직접 데이터를 만져봅시다. 오늘 사용할 데이터는 **피로.sav** 파일입니다. 
> 
> > [!quote] 🩺 실습 케이스: 다차원 피로 척도(MFS)
> > * **목적**: 주관적 피로 증상을 측정하기 위해 개발된 **19문항**의 척도가 과연 몇 개의 요인으로 구분되는지 파악하는 것입니다.
> > * **활용**: 추출된 요인을 새로운 변수로 만들어 추후 분석에 사용하고자 합니다.
> 
> 먼저 메뉴부터 찾아 들어가야겠죠? **분석(A) > 차원 감소 > 요인분석(F)** 순서로 클릭하세요.
> 
> 

> [!NOTE] 24~25페이지 – 변수 선택 및 투입
> 
> 창이 뜨면 왼쪽 변수 목록에서 우리가 분석할 문항들을 골라야 합니다.
> 
> > [!LIST] 📝 변수 선택 단계
> > 1. 성별, 연령 같은 인구학적 변수는 일단 제외합니다.
> > 2. 분석하고자 하는 설문 문항인 **피로1부터 피로19**까지를 모두 선택합니다.
> > 3. 오른쪽의 **변수(V)** 박스로 모든 문항을 이동시킵니다.
> 
> 
> 
> 문항을 다 옮겼다면, 이제 우측의 버튼들을 하나씩 눌러 세부 설정을 해줄 차례입니다.

> [!NOTE] 26~27페이지 – 요인 추출(Extraction)과 회전(Rotation) 설정
> 
> 여기가 가장 중요합니다. 제가 이론 강의 때 강조했던 내용들을 적용하는 단계예요.
> 
> > [!IMPORTANT] 💡 요인 추출(Extraction) 설정
> > * **방법**: 기본값은 **주성분(PCA)** 분석으로 되어 있습니다. (학술적 목적에 따라 주축분해법 등으로 변경 가능합니다.)
> > * **추출 기준**: 보통 **고유값(Eigenvalue) 1**을 기준으로 삼지만, 연구자가 특정 요인 수를 직접 지정할 수도 있습니다.
> > * **출력**: 흐름을 파악하기 위해 **스크리 도표(Scree Plot)**를 체크하는 습관을 들이세요.
> 
> > [!IMPORTANT] 💡 요인 회전(Rotation) 설정
> > * **방법**: 여기서는 직각회전 방식인 **베리맥스(Varimax)**를 선택하겠습니다. 
> > * **목적**: 요인 적재량을 재배치하여 어떤 문항이 어떤 요인에 속하는지 명확히 보기 위함입니다.
> 
> 

> [!NOTE] 28~29페이지 – 요인 점수 저장 및 출력 옵션
> 
> 분석 결과만 보고 끝낼 게 아니라, 이 요인들을 나중에 회귀분석 등에 써먹으려면 점수로 저장해야 합니다.
> 
> > [!LIST] 📝 추가 옵션 설정
> > * **요인 점수**: **'변수로 저장(S)'**을 체크하고 방법은 **'회귀분석'**을 선택합니다. 이렇게 하면 데이터 파일 끝에 새로운 변수가 생깁니다.
> > * **옵션(Options)**: 결과표를 보기 좋게 만들기 위해 **'크기순 정렬'**을 체크하세요. 적재량이 큰 순서대로 문항이 나열되어 훨씬 읽기 편해집니다.
> 
> 

> [!NOTE] 30~31페이지 – 명령문(Syntax) 생성 및 실행
> 
> 확인 버튼을 바로 누르지 말고, **'붙여넣기'**를 눌러보세요. 고수들은 항상 이렇게 합니다.
> 
> > [!TIP] ⭐️ 명령문(Syntax) 활용의 장점 (Yama)
> > * **FACTOR** 명령어로 시작하는 구문이 나타납니다. 
> > * 어떤 변수를 썼는지(/VARIABLES), 회전 방식은 무엇인지(/ROTATION VARIMAX) 한눈에 확인할 수 있고, 나중에 똑같은 분석을 재현할 때 매우 유용합니다.
> 
> > [!LIST] 📝 실행 방법
> > 생성된 명령문 창에서 전체를 드래그한 뒤 상단의 **'실행(녹색 화살표)'** 버튼을 누르면 분석이 시작됩니다.
> 
> 자, 이제 프로그램이 계산을 마쳤을 겁니다. 다음 장(Group 5)으로 넘어가서 쏟아져 나온 표들을 어떻게 해석하고 족보로 만드는지 알아봅시다.

---

> [!NOTE] 32페이지 – 설명된 총분산: 요인 수 결정의 근거
> 
> 자, 분석 결과가 나왔습니다. 가장 먼저 확인해야 할 표는 **'설명된 총분산'**입니다. 우리가 투입한 19개 문항이 몇 개의 요인으로 압축되었는지 보여주죠.
> 
> > [!IMPORTANT] 💡 고유값(Eigenvalue) 기준 결과 (Yama)
> > * **추출된 요인 수:** 고유값 **1**을 기준으로 했을 때, 최종적으로 **3개**의 성분이 도출되었습니다.
> > * **분산 설명력:** 
> > 	* 성분 1: **25.963%** 
> >     * 성분 2: **18.167%** 
> >     * 성분 3: **16.907%** 
> > * **누적 설명력:** 이 3개의 요인이 전체 데이터 분산의 **약 61%**를 설명하고 있습니다. 
> 
> 19개의 문항을 단 3개로 줄였음에도 정보의 **61%**를 유지하고 있다는 건, 아주 효율적인 압축이 일어났다는 뜻입니다. 이제 이 요인들이 구체적으로 어떤 문항들로 구성되었는지 볼까요? 

> [!NOTE] 33페이지 – 성분행렬: 회전 전의 가공되지 않은 상태
> 
> 회전을 하기 전의 **'성분행렬'** 표입니다. 여기서는 각 문항이 어떤 성분에 얼마나 큰 비중(적재값)을 가지는지 보여줍니다.
> 
> > [!WARNING] ⚠️ 회전 전 해석의 난해함
> > * 표를 보면 **피로14, 16, 11** 등이 성분 1에 매우 높은 **요인 적재값(0.7 이상)**을 보이고 있습니다.
> > * 하지만 대부분의 문항이 **성분 1**에 몰려 있거나 여러 성분에 걸쳐 있어, 이 상태로는 요인의 이름을 정하기가 매우 어렵습니다.
> 
> 그래서 우리가 아까 **베리멕스(Varimax)** 회전을 설정한 겁니다. 축을 돌려서 문항들을 각 요인으로 명확히 흩뿌려보겠습니다.

> [!NOTE] 34~35페이지 – 회전된 성분행렬: 변수의 완벽한 재분류
> 
> 드디어 우리가 기다리던 **'회전된 성분행렬'** 결과입니다. 아까 옵션에서 **'크기순 정렬'**을 했기 때문에 해석이 아주 쉽습니다.
> 
> > [!IMPORTANT] 🔑 요인별 문항 구성 결과 (핵심 족보)
> > * **성분 1 (9개 항목):** **피로11~19** 문항들이 묶였습니다. 이 문항들의 내용을 보고 요인의 이름을 정하면 됩니다.
> > * **성분 2 (4개 항목):** **피로1~4** 문항들이 강력하게 결합되었습니다.
> > * **성분 3 (6개 항목):** **피로5~10** 문항들이 하나의 그룹이 되었습니다.
> 
> > [!TIP] ⭐️ 요인 명명(Naming)
> > 이렇게 묶인 문항들의 공통점을 찾아 **'신체적 피로'**, **'정신적 피로'** 등과 같은 이름을 붙여주는 것이 연구자의 다음 과제입니다.
> 
> 이제 이 3개의 요인을 개별 데이터로 저장해서 다음 통계 분석에 활용할 수 있게 되었습니다.

> [!NOTE] 36페이지 – 요인 점수의 생성과 데이터 확인
> 
> 마지막으로 데이터 보기 창을 확인해 봅시다. 우리가 명령했던 대로 새로운 변수들이 생성되어 있을 겁니다.
> 
> > [!LIST] 📝 생성된 요인 점수 변수
> > * **FAC1_1**: 첫 번째 요인에 대한 각 개인별 추정 점수입니다.
> > * **FAC2_1**: 두 번째 요인 점수입니다.
> > * **FAC3_1**: 세 번째 요인 점수입니다.
> 
> > [!INFO] 🧬 요인 점수의 활용
> > 이제 19개의 설문 문항 대신, 이 **3개의 요인 점수** 변수만 가지고 **회귀분석**이나 **분산분석**을 돌리면 됩니다. 데이터가 훨씬 깔끔해졌죠? 
> 
> 고생 많으셨습니다. 요인분석은 처음엔 복잡해 보이지만, **'압축'**과 **'회전'**이라는 두 키워드만 기억하면 여러분도 완벽하게 수행할 수 있습니다.


